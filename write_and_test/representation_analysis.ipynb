{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88872648-fe31-4c1f-9ac3-50b942b3a72a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "%run model_evaluation\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import proplot as pplt\n",
    "import umap\n",
    "\n",
    "# model, obs_rms, kwargs = load_model_and_env('nav_auxiliary_tasks/nav_aux_wall_1', 0)\n",
    "# env = gym.make('NavEnv-v0', **kwargs)\n",
    "\n",
    "save = 'plots/representation_learning/'\n",
    "\n",
    "%run representation_analysis\n",
    "%run model_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06278970-a887-4cc3-8b3d-216d60437d83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_trained_models(ignore_non_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b462d3b5-6154-4598-ac78-8989feee5788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note - these parameters are important for classifier training\n",
    "\n",
    "WINDOW_SIZE = (300, 300)\n",
    "\n",
    "num_grid_slices = 5 # how many grid squares to slice maze into\n",
    "num_grid_points = num_grid_slices**2\n",
    "\n",
    "xs_grid = np.linspace(0, WINDOW_SIZE[0], num_grid_slices, endpoint=False)\n",
    "ys_grid = np.linspace(0, WINDOW_SIZE[1], num_grid_slices, endpoint=False)\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "def activation_testing(model, env, x, y, angle):\n",
    "    \"\"\"\n",
    "    Pass a model and corresponding environment, x, y and angle, then \n",
    "    get the observation and perform a prediction with model to get activations\n",
    "    \n",
    "    returns:\n",
    "        outputs object from model.base.forward\n",
    "    \n",
    "    outputs['activations'] is the activation dict\n",
    "    note that outputs['activations']['shared_activations'] is the same as the \n",
    "        rnn hidden state output\n",
    "    \"\"\"\n",
    "    vis_walls = env.vis_walls\n",
    "    vis_wall_refs = env.vis_wall_refs\n",
    "    \n",
    "    env.character.pos = np.array([x, y])\n",
    "    env.character.angle = angle\n",
    "    env.character.update_rays(vis_walls, vis_wall_refs)\n",
    "    \n",
    "    obs = torch.tensor(env.get_observation(), dtype=torch.float32).view(1, -1)\n",
    "    rnn_hxs = torch.zeros(1, model.recurrent_hidden_state_size, dtype=torch.float32)\n",
    "    masks = torch.zeros(1, 1, dtype=torch.float32)\n",
    "    \n",
    "    outputs = model.base.forward(obs, rnn_hxs, masks, with_activations=True)\n",
    "    outputs['obs'] = obs\n",
    "    return outputs\n",
    "\n",
    "\n",
    "\n",
    "def stack_activations(activation_dict, also_ret_list=False):\n",
    "    '''\n",
    "    Activations passed back from a FlexBase forward() call can be appended, e.g.\n",
    "    all_activations = []\n",
    "    for ...:\n",
    "        all_activations.append(actor_critic.act(..., with_activations=True)['activations'])\n",
    "        \n",
    "    This will result in a list of dictionaries\n",
    "    \n",
    "    This function converts all_activations constructed in this way into a dictionary,\n",
    "    where each value of the dictionary is a tensor of shape\n",
    "    [layer_num, seq_index, activation_size]\n",
    "    \n",
    "    Args:\n",
    "        also_ret_list: If True, will also return activations in a list one-by-one\n",
    "            rather than dict form. Good for matching up with labels and classifier ordering\n",
    "            from train classifiers function\n",
    "    '''\n",
    "    stacked_activations = defaultdict(list)\n",
    "    list_activations = []\n",
    "    keys = activation_dict[0].keys()\n",
    "    \n",
    "    for i in range(len(activation_dict)):\n",
    "        for key in keys:\n",
    "            num_layers = len(activation_dict[i][key])\n",
    "            \n",
    "            if num_layers > 0:\n",
    "                # activation: 1 x num_layers x activation_size\n",
    "                activation = torch.vstack(activation_dict[i][key]).reshape(1, num_layers, -1)\n",
    "                # stacked_activations: list (1 x num_layers x activation_size)\n",
    "                stacked_activations[key].append(activation)\n",
    "    \n",
    "    for key in stacked_activations:\n",
    "        activations = torch.vstack(stacked_activations[key]) # seq_len x num_layers x activation_size\n",
    "        activations = activations.transpose(0, 1) # num_layers x seq_len x activation_size\n",
    "        stacked_activations[key] = activations\n",
    "        \n",
    "        #Generate activations in list form\n",
    "        if also_ret_list:\n",
    "            for i in range(activations.shape[0]):\n",
    "                list_activations.append(activations[i])\n",
    "    \n",
    "    if also_ret_list:\n",
    "        return stacked_activations, list_activations\n",
    "    else:\n",
    "        return stacked_activations\n",
    "\n",
    "\n",
    "def find_grid_index(point=None, x=None, y=None):\n",
    "    if point is not None:\n",
    "        x = point[0]\n",
    "        y = point[1]\n",
    "    elif x is not None and y is not None:\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception('No valid argument combination given')\n",
    "        \n",
    "    x_grid_idx = np.max(np.argwhere(x >= xs_grid))\n",
    "    y_grid_idx = np.max(np.argwhere(y >= ys_grid))\n",
    "    total_grid_idx = x_grid_idx * num_grid_slices + y_grid_idx\n",
    "    return total_grid_idx\n",
    "\n",
    "\n",
    "\n",
    "def train_classifier(x, labels, valid_x=None, valid_labels=None, num_labels=None,\n",
    "                     lr=0.1, epochs=1000, prog=False):\n",
    "    '''\n",
    "    Train an arbitrary classifier\n",
    "        x (tensor): train X data\n",
    "        labels (tensor): train labels\n",
    "        valid_x (tensor, optional): train valid X data\n",
    "        valid_labels (tensor, optional): train valid labels\n",
    "        num_labels (int, optional): number of output labels\n",
    "            for model to output. If not provided, default is\n",
    "            given by the largest label value in labels\n",
    "    '''\n",
    "    if num_labels is None:\n",
    "        num_labels = labels.max().item() + 1\n",
    "    linear = nn.Linear(x.shape[1], num_labels)\n",
    "    optimizer = optim.Adam(linear.parameters(), lr=lr)\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    # optimizer = optim.SGD(linear.parameters(), lr=0.1, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    valid_accuracies = []\n",
    "    if prog:\n",
    "        it = tqdm(range(epochs))\n",
    "    else:\n",
    "        it = range(epochs)\n",
    "        \n",
    "    for i in it:\n",
    "        y = linear(x)\n",
    "        loss = criterion(y, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        accuracies.append(accuracy_score(softmax(y.detach()).argmax(axis=1), labels))\n",
    "\n",
    "        if valid_x is not None and valid_labels is not None:\n",
    "            pred_valid = softmax(linear(valid_x)).argmax(axis=1)\n",
    "            valid_accuracies.append(accuracy_score(pred_valid, valid_labels))\n",
    "            \n",
    "    return linear, losses, accuracies, valid_accuracies\n",
    "\n",
    "\n",
    "def draw_character(pos, angle, size=10, ax=None):\n",
    "    angle1 = angle - 0.3\n",
    "    angle2 = angle + 0.3\n",
    "    point1 = [pos[0], pos[1]]\n",
    "    point2 = [pos[0] - np.cos(angle1)*size, pos[1] - np.sin(angle1)*size]\n",
    "    point3 = [pos[0] - np.cos(angle2)*size, pos[1] - np.sin(angle2)*size]\n",
    "\n",
    "    draw_color = np.array([0.9, 0.9, 0])\n",
    "\n",
    "    poly = plt.Polygon([point1, point2, point3], fc=draw_color)\n",
    "    if ax is None:\n",
    "        plt.gca().add_patch(poly)\n",
    "    else:\n",
    "        ax.add_patch(poly)\n",
    "\n",
    "        \n",
    "def get_activations(model, obs, masks, pos, device=torch.device('cpu')):\n",
    "    eval_recurrent_hidden_states = torch.zeros(\n",
    "        num_processes, model.recurrent_hidden_state_size, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.base(obs, eval_recurrent_hidden_states, \n",
    "                               masks, deterministic=True, with_activations=True)\n",
    "    \n",
    "    #For some reason, the first ~100ish activations are misaligned with the original\n",
    "    #activations if the agent is run with the episodes live, so remove some early misalignment\n",
    "    skip = 0\n",
    "    \n",
    "    activations = outputs['activations']\n",
    "    stacked = {}\n",
    "    for key in activations:\n",
    "        substacked = []\n",
    "        for i in range(len(activations[key])):\n",
    "            activ = activations[key][i][skip:, :]\n",
    "            shape = activ.shape\n",
    "            substacked.append(activ.reshape(1, shape[0], shape[1]))\n",
    "        stacked[key] = torch.vstack(substacked)\n",
    "    pos = pos[skip:]\n",
    "    # angle = angle[skip:]\n",
    "\n",
    "    return stacked, pos\n",
    "    \n",
    "\n",
    "def train_position_classifier(model, obs_rms=None, kwargs=None, model_num=None, \n",
    "                              train_episodes=30, valid_episodes=5, epochs=100, \n",
    "                              seed=0, random_actions=True):\n",
    "    '''\n",
    "    Complete automated training of a position decoder\n",
    "    model (str or Policy): the model to be trained, can either be a\n",
    "        path to trained model from ../trained_models/ppo/ or a policy directly\n",
    "    \n",
    "    model (str):\n",
    "        model_num (int): Need to also pass the trial number to load\n",
    "    model (Policy):\n",
    "        obs_rms, kwargs: These are usually loaded from load_model_and_env\n",
    "            so when a Policy is passed, need to pass these as well\n",
    "    '''\n",
    "    \n",
    "    if model_num is not None and type(model) == str:\n",
    "        model, obs_rms, kwargs = load_model_and_env(model, model_num)\n",
    "    elif obs_rms is not None and kwargs is not None \\\n",
    "        and type(model) == Policy:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('Must pass either model (str) + model_num or model (Policy) + obs_rms + kwargs')\n",
    "    \n",
    "    # Generate activations and positions for training and validation\n",
    "    train_results = perform_ep_collection(model, obs_rms, kwargs,\n",
    "                                     seed=seed, num_episodes=train_episodes, random_actions=random_actions)\n",
    "    stacked, grid_indexes = train_results['stacked'], train_results['grid_indexes']\n",
    "\n",
    "    valid_results = perform_ep_collection(model, obs_rms, kwargs,\n",
    "                                     seed=seed, num_episodes=valid_episodes, random_actions=random_actions)\n",
    "    valid_stacked, valid_grid_indexes = train_results['stacked'], train_results['grid_indexes']\n",
    "    \n",
    "    # Train position decoders on activations\n",
    "    classifiers = {}\n",
    "\n",
    "    all_losses = []\n",
    "    all_accuracies = []\n",
    "    labels = []\n",
    "    valid_accuracies = []\n",
    "    \n",
    "    valid_preds = []\n",
    "\n",
    "    for key in stacked:\n",
    "        # print(key)\n",
    "        num_layers = stacked[key].shape[0]\n",
    "        for i in range(num_layers):            \n",
    "            x = stacked[key][i]\n",
    "            valid_x = valid_stacked[key][i]\n",
    "            \n",
    "            linear, losses, accuracies, _ = train_classifier(x, grid_indexes, epochs=epochs)\n",
    "            classifiers[f'{key}_{i}'] = linear\n",
    "            \n",
    "            labels.append(f'{key}_{i}')\n",
    "            all_losses.append(losses)\n",
    "            all_accuracies.append(accuracies)\n",
    "    \n",
    "            pred_valid = linear(valid_x).argmax(axis=1)\n",
    "        \n",
    "            valid_preds.append(pred_valid)\n",
    "            \n",
    "            accuracy_score(pred_valid, valid_grid_indexes)\n",
    "            valid_accuracies.append(accuracy_score(pred_valid, valid_grid_indexes))\n",
    "    return {\n",
    "        'labels': labels,\n",
    "        'losses': all_losses,\n",
    "        'training_acc': all_accuracies,\n",
    "        'final_valid_acc': valid_accuracies,\n",
    "        'classifiers': classifiers,\n",
    "        \n",
    "        'valid_preds': valid_preds,\n",
    "        'valid_grid_indexes': valid_grid_indexes\n",
    "    }\n",
    "    \n",
    "    \n",
    "def quick_vec_env(obs_rms, env_kwargs={}, env_name='NavEnv-v0', seed=0,\n",
    "                 num_processes=1, eval_log_dir='/tmp/gym/_eval',\n",
    "                 device=torch.device('cpu'), capture_video=False):\n",
    "    eval_envs = make_vec_envs(env_name, seed + num_processes, num_processes,\n",
    "                          None, eval_log_dir, device, True, \n",
    "                          capture_video=capture_video, \n",
    "                          env_kwargs=env_kwargs)\n",
    "\n",
    "    vec_norm = utils.get_vec_normalize(eval_envs)\n",
    "    if vec_norm is not None:\n",
    "        vec_norm.eval()\n",
    "        vec_norm.obs_rms = obs_rms\n",
    "        \n",
    "    return eval_envs\n",
    "\n",
    "    \n",
    "def perform_ep_collection(model, obs_rms=None, kwargs=None, model_num=None, \n",
    "                          num_episodes=1, seed=0, random_actions=False,\n",
    "                         data_callback=nav_data_callback):\n",
    "    '''\n",
    "    Collect activations, positions, etc. for a number of episodes\n",
    "    Used by train_position_classifier to collect activation and pos data\n",
    "    Can also be used to generate single episodes of data to evaluate classifiers etc.\n",
    "    \n",
    "    Same model (str / Policy) parameters as train_position_classifier\n",
    "    '''\n",
    "    if model_num is not None and type(model) == str:\n",
    "        model, obs_rms, kwargs = load_model_and_env(model, model_num)\n",
    "    elif obs_rms is not None and kwargs is not None \\\n",
    "        and type(model) == Policy:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('Must pass either model (str) + model_num or model (Policy) + obs_rms + kwargs')\n",
    "\n",
    "    \n",
    "    # Generate random episodes to train on\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    action_randomizer = lambda step: np.random.choice([0, 1, 2])\n",
    "    \n",
    "    if random_actions:\n",
    "        results = forced_action_evaluate(model, obs_rms, forced_actions=action_randomizer, env_kwargs=kwargs, seed=seed,\n",
    "                                        data_callback=nav_data_callback, num_episodes=num_episodes, with_activations=True)\n",
    "    else:\n",
    "        results = forced_action_evaluate(model, obs_rms, env_kwargs=kwargs, seed=seed,\n",
    "                                        data_callback=nav_data_callback, num_episodes=num_episodes, with_activations=True)\n",
    "\n",
    "    pos = np.vstack(results['data']['pos'])\n",
    "    angle = torch.tensor(np.vstack(results['data']['angle']))\n",
    "    stacked, listed_activ = stack_activations(results['activations'], also_ret_list=True)\n",
    "    grid_indexes = torch.tensor([find_grid_index(p) for p in pos])\n",
    "    \n",
    "    results['pos'] = pos\n",
    "    results['angle'] = angle\n",
    "    results['stacked'], results['listed_activ'] = stacked, listed_activ\n",
    "    results['grid_indexes'] = grid_indexes\n",
    "    \n",
    "    return results\n",
    "    \n",
    "    \n",
    "def split_by_ep(targets, dones):\n",
    "    done_idxs = np.where(np.vstack(dones))[0]\n",
    "    split_targets = []\n",
    "    for i in range(len(done_idxs)):\n",
    "        if i == 0:\n",
    "            done_targets = targets[:done_idxs[i]]\n",
    "        else:\n",
    "            done_targets = targets[done_idxs[i-1]:done_idxs[i]]\n",
    "\n",
    "        split_targets.append(done_targets)\n",
    "    return split_targets\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce05caae-cf59-4675-a260-6e9e8c3f5d56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Train single MLP layer on non-episodic activations\n",
    "\n",
    "Either take a grid of points and rotate angles about the points, then collect observations, or take randomly sampled points and angles. Then train a single layer MLP to detect where the agent is. This may be too challenging, so we may need to attempt to train a classifier to output where on a grid the agent is instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe94750-0537-4c68-8b16-84b6e8f42989",
   "metadata": {},
   "source": [
    "## Generate points (run before sections 1.2+)\n",
    "\n",
    "Here we generate a set of training points for later sections to train with. Can either generate them by grid points or by generating a random set of points and angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbdb7bb-bb09-401e-aadc-a2082cfcfa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generate activations from the network - for a grid of points, rotate\n",
    "around to get visual inputs to the system and get activations from trained model\n",
    "'''\n",
    "\n",
    "WINDOW_SIZE = (300, 300)\n",
    "#Random points\n",
    "num_points = 5000\n",
    "rand_points = 280 * np.random.random((num_points, 2)) + 10\n",
    "rand_angles = 2 * np.pi * np.random.random(num_points)\n",
    "\n",
    "# outputs = activation_testing(model, env, 5, 5, 0)\n",
    "all_activations = []            \n",
    "all_obs = []\n",
    "\n",
    "points = []\n",
    "angles = []\n",
    "pbar = tqdm()\n",
    "with torch.no_grad():\n",
    "    for i in range(num_points):\n",
    "        x = rand_points[i, 0]\n",
    "        y = rand_points[i, 1]\n",
    "        angle = rand_angles[i]\n",
    "\n",
    "        outputs = activation_testing(model, env, x, y, angle)\n",
    "        all_activations.append(outputs['activations'])\n",
    "        all_obs.append(outputs['obs'])\n",
    "\n",
    "        pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "stacked_activations = stack_activations(all_activations)\n",
    "all_obs = torch.vstack(all_obs)\n",
    "\n",
    "\n",
    "\n",
    "# Turn points into trainable data\n",
    "points = np.array(rand_points)\n",
    "angles = np.array(rand_angles)\n",
    "\n",
    "scaled_points = np.zeros(points.shape)\n",
    "scaled_points[:, 0] = points[:, 0]/np.max(points[:, 0])\n",
    "scaled_points[:, 1] = points[:, 1]/np.max(points[:, 1])\n",
    "\n",
    "scaled_angles = angles / np.max(angles)\n",
    "\n",
    "scaled_points = torch.tensor(scaled_points, dtype=torch.float32)\n",
    "scaled_angles = torch.tensor(scaled_angles, dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1cfc44-e541-4d47-84fc-7c51b38c6b54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Generate activations from the network - for a grid of points, rotate\n",
    "around to get visual inputs to the system and get activations from trained model\n",
    "'''\n",
    "\n",
    "# Grid points\n",
    "step_size = 10\n",
    "xs = np.arange(0+step_size, WINDOW_SIZE[0], step_size)\n",
    "ys = np.arange(0+step_size, WINDOW_SIZE[1], step_size)\n",
    "thetas = np.linspace(0, 2*np.pi, 12, endpoint=False)\n",
    "\n",
    "activations = activation_testing(model, env, 5, 5, 0)\n",
    "\n",
    "activation_dict = {}\n",
    "\n",
    "def append_activation_dict(activations, activation_dict):\n",
    "    # Add keys to dict\n",
    "    for key in activations:\n",
    "        act = activations[key]\n",
    "        if key not in activation_dict:\n",
    "            activation_dict[key] = []\n",
    "            if type(act) == list:\n",
    "                for i in range(len(act)):\n",
    "                    activation_dict[key].append([])\n",
    "                \n",
    "    # Append activation vectors to dict\n",
    "    for key in activations:\n",
    "        act = activations[key]\n",
    "        if type(act) == list:\n",
    "            for i in range(len(act)):\n",
    "                activation_dict[key][i].append(act[i].squeeze())\n",
    "        else:\n",
    "            activation_dict[key].append(activations[key].squeeze())\n",
    "            \n",
    "    \n",
    "points = []\n",
    "angles = []\n",
    "pbar = tqdm(total=len(xs)*len(ys)*len(angles))\n",
    "activation_dict = {}\n",
    "with torch.no_grad():\n",
    "    for x in xs:\n",
    "        for y in ys:\n",
    "            for angle in thetas:\n",
    "                points.append([x, y])\n",
    "                angles.append(angle)\n",
    "\n",
    "                activations = activation_testing(model, env, x, y, angle)\n",
    "                append_activation_dict(activations, activation_dict)\n",
    "\n",
    "                pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "# Turn points into trainable data\n",
    "\n",
    "points = np.array(points)\n",
    "angles = np.array(angles)\n",
    "\n",
    "scaled_points = np.zeros(points.shape)\n",
    "scaled_points[:, 0] = points[:, 0]/np.max(points[:, 0])\n",
    "scaled_points[:, 1] = points[:, 1]/np.max(points[:, 1])\n",
    "\n",
    "scaled_angles = angles / np.max(angles)\n",
    "\n",
    "scaled_points = torch.tensor(scaled_points, dtype=torch.float32)\n",
    "scaled_angles = torch.tensor(scaled_angles, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce69b8-1dc4-4fc2-9102-072e91cff5e6",
   "metadata": {},
   "source": [
    "## Train linear model for regression of position\n",
    "\n",
    "This ends up being too difficult for both grid and randomly sampled points. Try instead grid method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d4432c-51b1-421b-87b3-90285d1d1b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train model on activations - try to find a single linear layer that\n",
    "can map activation to position\n",
    "'''\n",
    "\n",
    "def train_linear_model(x, y, valid_x=None, valid_y=None, epochs=100):\n",
    "    linear = nn.Linear(x.shape[1], y.shape[1])\n",
    "    optimizer = optim.Adam(linear.parameters())\n",
    "    mse_loss = nn.MSELoss()\n",
    "    losses = []\n",
    "    for i in range(100):\n",
    "        y_pred = linear(x)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = mse_loss(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    if valid_x is not None and valid_y is not None:\n",
    "        with torch.no_grad():\n",
    "            pred = linear(valid_x) * 300\n",
    "            mse = mse_loss(pred, valid_y)\n",
    "            return linear, mse\n",
    "    \n",
    "    return linear\n",
    "\n",
    "# Generate validation points\n",
    "num_points = 100\n",
    "rand_points = 280 * np.random.random((num_points, 2)) + 10\n",
    "rand_angles = 2 * np.pi * np.random.random(num_points)\n",
    "valid_activations = []\n",
    "valid_obs = []\n",
    "for i in range(num_points):\n",
    "    x = rand_points[i, 0]\n",
    "    y = rand_points[i, 1]\n",
    "    angle = rand_angles[i]\n",
    "    outputs = activation_testing(model, env, x, y, angle)\n",
    "    valid_activations.append(outputs['activations'])\n",
    "    valid_obs.append(outputs['obs'])\n",
    "\n",
    "valid_activations = stack_activations(valid_activations)\n",
    "valid_obs = torch.vstack(valid_obs)\n",
    "valid_y = torch.tensor(rand_points, dtype=torch.float32)\n",
    "\n",
    "results_dict = defaultdict(list)\n",
    "\n",
    "\n",
    "for key in stacked_activations:\n",
    "    num_layers = stacked_activations[key].shape[0]\n",
    "    for i in range(num_layers):\n",
    "        x = stacked_activations[key][i]\n",
    "        linear, mse = train_linear_model(x, scaled_points, \n",
    "                            valid_x=valid_activations[key][i], valid_y=valid_y)\n",
    "        results_dict[f'{key}_{i}'] = mse\n",
    "    \n",
    "    \n",
    "# x = torch.vstack(activation_dict['actor_x'])\n",
    "print(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1704077c-e49c-4ac2-a013-03e699847472",
   "metadata": {},
   "source": [
    "## Train classifier to output which grid of given granularity the agent might be in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673034a6-bfae-4eb5-a893-df9b394f0a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_indexes = [find_grid_index(point) for point in points]\n",
    "grid_indexes = torch.tensor(grid_indexes)\n",
    "\n",
    "\n",
    "# Generate validation points\n",
    "num_points = 100\n",
    "rand_points = 280 * np.random.random((num_points, 2)) + 10\n",
    "rand_angles = 2 * np.pi * np.random.random(num_points)\n",
    "valid_activations = []\n",
    "valid_obs = []\n",
    "for i in range(num_points):\n",
    "    x = rand_points[i, 0]\n",
    "    y = rand_points[i, 1]\n",
    "    angle = rand_angles[i]\n",
    "    outputs = activation_testing(model, env, x, y, angle)\n",
    "    valid_activations.append(outputs['activations'])\n",
    "    valid_obs.append(outputs['obs'])\n",
    "\n",
    "valid_activations = stack_activations(valid_activations)\n",
    "valid_obs = torch.vstack(valid_obs)\n",
    "\n",
    "valid_grid_indexes = [find_grid_index(point) for point in rand_points]\n",
    "valid_grid_indexes = torch.tensor(valid_grid_indexes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feee42e0-e01a-4405-9802-062546da25ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "\n",
    "all_losses = []\n",
    "all_accuracies = []\n",
    "labels = []\n",
    "all_valid_accuracies = []\n",
    "epochs = 2000\n",
    "\n",
    "\n",
    "for key in stacked_activations:\n",
    "    print(key)\n",
    "    num_layers = stacked_activations[key].shape[0]\n",
    "    for i in range(num_layers):\n",
    "        x = stacked_activations[key][i]\n",
    "        linear, losses, accuracies, valid_accuracies = train_classifier(x, grid_indexes, \n",
    "                            valid_x=valid_activations[key][i], \n",
    "                            valid_labels=valid_grid_indexes, epochs=epochs)\n",
    "        results_dict[f'{key}_{i}'] = linear\n",
    "        labels.append(f'{key}_{i}')\n",
    "        all_losses.append(losses)\n",
    "        all_accuracies.append(accuracies)\n",
    "        all_valid_accuracies.append(valid_accuracies)\n",
    "\n",
    "        \n",
    "\n",
    "# Train a classifier from observation alone\n",
    "print('obs')\n",
    "x = all_obs\n",
    "linear, losses, accuracies, valid_accuracies = train_classifier(x, grid_indexes,\n",
    "                                                valid_obs, valid_grid_indexes, epochs=epochs)\n",
    "labels.append('obs')\n",
    "results_dict['obs'] = linear\n",
    "all_losses.append(losses)\n",
    "all_accuracies.append(accuracies)\n",
    "all_valid_accuracies.append(valid_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474cda60-9c9d-4bd6-bdf6-4c10abd835b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = len(labels)\n",
    "fig, ax = plt.subplots(x, 2, figsize=(8, x*3), sharey='col', sharex=True)\n",
    "for i in range(x):\n",
    "    ax[i, 0].plot(all_losses[i])\n",
    "    ax[i, 1].plot(all_accuracies[i], label='Training Accuracy')\n",
    "    ax[i, 1].plot(all_valid_accuracies[i], label='Valid Accuracy')\n",
    "    ax[i, 0].set_ylabel(labels[i], rotation=45, labelpad=40)\n",
    "    \n",
    "ax[0, 0].set_title('Training Losses')\n",
    "ax[0, 1].set_title('Accuracies')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(save+'1_3_classifier_training_curves.jpg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882ec4bb-922b-4c6e-acf6-c99dcb8de8a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linear = results_dict['shared_activations_0']\n",
    "y = linear(valid_activations['shared_activations'][0])\n",
    "pred_labels = y.argmax(axis=1)\n",
    "\n",
    "valid_grid_indexes\n",
    "\n",
    "plt.imshow(confusion_matrix(pred_labels, valid_grid_indexes))\n",
    "plt.title('Confusion matrix on random validation points')\n",
    "plt.xlabel('Predicted grid position')\n",
    "plt.ylabel('Actual grid position')\n",
    "plt.savefig(save + '1_3_classifier_confusion_matrix', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a010eb3-2d1a-42fd-99ee-c76e445313c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train single MLP layer on episodic activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57e7336-3619-40fd-ab3e-00182e631ecc",
   "metadata": {},
   "source": [
    "## Running episodes starting at points on grid\n",
    "\n",
    "Split grid into 9x9 (81 total starting points), facing away from center. Record positions and activations, train classifier to decode position from activations.\n",
    "\n",
    "We note that using episodic activations has much more exploitable structure to perform decoding with, allowing for faster convergence of MLP and higher accuracies. It is likely that this follows the auxiliary task navigation paper, wherein the position of the agent can be decoded much more accurately as the episode progresses.\n",
    "\n",
    "Next\n",
    "* Need to create a validation methodology, since it is no longer accurate to just use random initial points for validation, actually need to follow a trajectory\n",
    "* Would like to determine whether we can do this with a fixed trajectory i.e., actions that are not determined by the policy but either by random or determined by us. See if activations can still be decoded - this allows greater flexibility for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f691260e-b64f-4830-9886-f7bcccb82e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, obs_rms, env = load_model_and_env('nav_auxiliary_tasks/nav_aux_wall_1', \n",
    "                                            0, env_name='NavEnv-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381b5dd-8b5d-4418-ac22-8a1199201c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = (300, 300)\n",
    "step_size = 30\n",
    "xs = np.arange(0+step_size, WINDOW_SIZE[0], step_size)\n",
    "ys = np.arange(0+step_size, WINDOW_SIZE[1], step_size)\n",
    "# thetas = np.linspace(0, 2*np.pi, 12, endpoint=False)\n",
    "points = []\n",
    "angles = []\n",
    "for x in xs:\n",
    "    for y in ys:\n",
    "        point = np.array([x, y])\n",
    "        \n",
    "        # # Face the center\n",
    "        # angle = np.arctan2(150 - x, 150 - y)\n",
    "        \n",
    "        #Face away from center\n",
    "        angle = np.arctan2(x - 150, y - 150)\n",
    "        \n",
    "        points.append(point)\n",
    "        angles.append(angle)\n",
    "\n",
    "all_results = []\n",
    "for i in tqdm(range(len(points))):\n",
    "    point = points[i]\n",
    "    angle = angles[i]\n",
    "    kwargs['fixed_reset'] = [point, angle]\n",
    "    results = evalu(model, obs_rms, n=1, env_kwargs=kwargs, with_activations=True,\n",
    "                    data_callback=nav_data_callback)\n",
    "    all_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f0fcb-6a0e-4a4e-8ae9-e3eea5f1537e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#stitch together positions and activations\n",
    "pos = np.vstack([np.vstack(all_results[i]['data']['pos']) for i in range(len(all_results))])\n",
    "\n",
    "all_activations = []\n",
    "for i in range(len(all_results)):\n",
    "    all_activations += all_results[i]['activations']\n",
    "stacked = stack_activations(all_activations)\n",
    "\n",
    "grid_indexes = torch.tensor([find_grid_index(p) for p in pos])\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(pos.T[0], pos.T[1], alpha=0.2, s=5)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Example of trajectories from fixed starting positions')\n",
    "plt.savefig(save + '2_1_grid_start_trajectories', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d08aa01-01a2-4993-8c11-bf30f23192a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "\n",
    "all_losses = []\n",
    "all_accuracies = []\n",
    "labels = []\n",
    "all_valid_accuracies = []\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "for key in stacked:\n",
    "    print(key)\n",
    "    num_layers = stacked[key].shape[0]\n",
    "    for i in range(num_layers):\n",
    "        x = stacked[key][i]\n",
    "        linear, losses, accuracies, valid_accuracies = train_classifier(x, grid_indexes, \n",
    "                            valid_x=valid_activations[key][i], \n",
    "                            valid_grid_indexes=valid_grid_indexes, epochs=epochs)\n",
    "        results_dict[f'{key}_{i}'] = linear\n",
    "        labels.append(f'{key}_{i}')\n",
    "        all_losses.append(losses)\n",
    "        all_accuracies.append(accuracies)\n",
    "        all_valid_accuracies.append(valid_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fcf71b-8954-48da-80c3-f4a266a1e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = len(labels)\n",
    "fig, ax = plt.subplots(x, 2, figsize=(8, x*3), sharey='col', sharex=True)\n",
    "for i in range(x):\n",
    "    ax[i, 0].plot(all_losses[i])\n",
    "    ax[i, 1].plot(all_accuracies[i], label='Training Accuracy')\n",
    "    # ax[i, 1].plot(all_valid_accuracies[i], label='Valid Accuracy')\n",
    "    ax[i, 0].set_ylabel(labels[i], rotation=45, labelpad=40)\n",
    "    \n",
    "ax[0, 0].set_title('Training Losses')\n",
    "ax[0, 1].set_title('Accuracies')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/representation_learning/1_3_classifier_training_curves.jpg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a7f852-1e3c-47ff-a41f-bc777070e327",
   "metadata": {},
   "source": [
    "## Testing forced action episodes\n",
    "\n",
    "It appears we can very effectively perform the same grid classifier training on episodes that are run with random actions, so the actual actions taken don't seem to directly influence the activation trajectories (indirectly of course). This means that we can control an agent to move in certain trajectories and manipulate the sequence of observations seen to test specific representations learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65551698-a61d-4149-ac55-4391567ad679",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, obs_rms, kwargs = load_model_and_env('nav_auxiliary_tasks/nav_aux_wall_1', 0)\n",
    "\n",
    "action_randomizer = lambda step: np.random.choice([0, 1, 2])\n",
    "results = forced_action_evaluate(model, obs_rms, forced_actions=action_randomizer, env_kwargs=kwargs, \n",
    "                                data_callback=nav_data_callback, num_episodes=50, with_activations=True)\n",
    "\n",
    "pos = np.vstack(results['data']['pos'])\n",
    "angle = torch.tensor(np.vstack(results['data']['angle']))\n",
    "stacked = stack_activations(results['activations'])\n",
    "grid_indexes = torch.tensor([find_grid_index(p) for p in pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9be36-40e8-44c6-b487-a9ef22e32a54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.scatter(pos.T[0], pos.T[1], alpha=0.2, s=8)\n",
    "plt.title('Example of 50 random action trajectories')\n",
    "plt.savefig(save + '2_2_forced_actions_random_trajectories', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b461f492-fb8e-4c9c-9c82-6f49b2300ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train position decoder classifiers\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "all_losses = []\n",
    "all_accuracies = []\n",
    "labels = []\n",
    "all_valid_accuracies = []\n",
    "epochs = 300\n",
    "\n",
    "\n",
    "for key in stacked:\n",
    "    print(key)\n",
    "    num_layers = stacked[key].shape[0]\n",
    "    for i in range(num_layers):\n",
    "        x = stacked[key][i]\n",
    "        linear, losses, accuracies, valid_accuracies = train_classifier(x, grid_indexes, \n",
    "                                                                             epochs=epochs)\n",
    "        results_dict[f'{key}_{i}'] = linear\n",
    "        labels.append(f'{key}_{i}')\n",
    "        all_losses.append(losses)\n",
    "        all_accuracies.append(accuracies)\n",
    "        all_valid_accuracies.append(valid_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f37ced-9124-4c4b-831c-fad5bd31ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = len(labels)\n",
    "fig, ax = plt.subplots(x, 2, figsize=(8, x*3), sharey='col', sharex=True)\n",
    "for i in range(x):\n",
    "    ax[i, 0].plot(all_losses[i])\n",
    "    ax[i, 1].plot(all_accuracies[i], label='Training Accuracy')\n",
    "    # ax[i, 1].plot(all_valid_accuracies[i], label='Valid Accuracy')\n",
    "    ax[i, 0].set_ylabel(labels[i], rotation=45, labelpad=40)\n",
    "    \n",
    "ax[0, 0].set_title('Training Losses')\n",
    "ax[0, 1].set_title('Accuracies')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/representation_learning/1_3_classifier_training_curves.jpg', bbox_inches='tight')\n",
    "plt.savefig(save + '2_2_pos_classifier_random_action', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15fc9c0-3dfa-4f29-b9d2-a4c60f81760e",
   "metadata": {},
   "source": [
    "### Testing to see how quickly in an episode agent position can be decoded accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89024a5e-281f-4c0d-a1e2-fb1d21e37fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_randomizer = lambda step: np.random.choice([0, 1, 2])\n",
    "one_ep = forced_action_evaluate(model, obs_rms, forced_actions=action_randomizer, env_kwargs=kwargs, \n",
    "                                data_callback=nav_data_callback, num_episodes=1, with_activations=True)\n",
    "\n",
    "\n",
    "one_ep_pos = np.vstack(one_ep['data']['pos'])\n",
    "one_ep_angle = np.vstack(one_ep['data']['angle'])\n",
    "one_ep_stacked = stack_activations(one_ep['activations'])\n",
    "\n",
    "#Use the trained classifier as grid-wise position decoder\n",
    "with torch.no_grad():\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    y = results_dict['shared_activations_0'](one_ep_stacked['shared_activations'][0])\n",
    "    probs = softmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72856c8d-eb16-43c5-a062-ebbb4035a241",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [0, 2, 5, 9]\n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 3), sharex=True, sharey=True)\n",
    "\n",
    "for i, step in enumerate(steps):\n",
    "    ax[i].imshow(probs[step].reshape(5,5).rot90(), cmap='Blues', alpha=0.5, extent=(0, 300, 0, 300))\n",
    "    # plt.scatter(one_ep_pos.T[0, :step], one_ep_pos.T[1, :step], alpha=0.2)\n",
    "    draw_character(one_ep_pos[step], one_ep_angle[step], 20, ax=ax[i])\n",
    "    ax[i].set_title(f'Step {step}')\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "\n",
    "plt.savefig(save + '2_2_1_live_episode_decoding', bbox_inches='tight')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4095c16-37c6-4d5a-abea-8f61fb6eb9fa",
   "metadata": {},
   "source": [
    "### Observing data distribution of activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98919c8-27b4-4004-af4f-b9f08d10bdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "\n",
    "embedding = reducer.fit_transform(stacked['shared_activations'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca9e417-9b9a-4e2d-b6d9-b05f0a9821c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(embedding.T[0], embedding.T[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9852ac-bc70-4d9d-92ca-e7902fdc2a6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Testing other representation classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd95595-e531-4808-ae71-95f5d3e1ec57",
   "metadata": {},
   "source": [
    "## Angle classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989e196f-b8de-4955-b987-42d5ebfade9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, obs_rms, kwargs = load_model_and_env('nav_auxiliary_tasks/nav_aux_wall_1', 0)\n",
    "\n",
    "action_randomizer = lambda step: np.random.choice([0, 1, 2])\n",
    "results = forced_action_evaluate(model, obs_rms, forced_actions=action_randomizer, env_kwargs=kwargs, \n",
    "                                data_callback=nav_data_callback, num_episodes=50, with_activations=True)\n",
    "\n",
    "pos = np.vstack(results['data']['pos'])\n",
    "angle = torch.tensor(np.vstack(results['data']['angle']))\n",
    "stacked = stack_activations(results['activations'])\n",
    "grid_indexes = torch.tensor([find_grid_index(p) for p in pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea1b6c0-72e4-48e6-a861-d87ddfa70b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_grid = np.linspace(-np.pi, np.pi, 12)\n",
    "\n",
    "def categorize_angle(angle):\n",
    "    angle_grid_idx = np.max(np.argwhere(angle >= angle_grid))\n",
    "    return angle_grid_idx\n",
    "\n",
    "angle_indexes = [categorize_angle(angle) for angle in results['data']['angle']]\n",
    "angle_indexes = torch.tensor(angle_indexes)\n",
    "\n",
    "all_losses = []\n",
    "all_accuracies = []\n",
    "labels = []\n",
    "\n",
    "for key in stacked:\n",
    "    num_layers = stacked[key].shape[0]\n",
    "    for i in range(num_layers):\n",
    "        x = stacked[key][i]\n",
    "        linear, losses, acc, valid_acc = train_classifier(x, angle_indexes)\n",
    "        all_losses.append(losses)\n",
    "        all_accuracies.append(acc)\n",
    "        labels.append(f'{key}_{i}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81147fa1-2f96-477b-930b-7b2f99542d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [\n",
    "    [0, 1, 1, 0],\n",
    "    [2, 2, 3, 3],\n",
    "    [4, 4, 5, 5]\n",
    "]\n",
    "fig, ax = pplt.subplots(array)\n",
    "ax.format(abc=True, abcloc='ul', \n",
    "          suptitle='Trained Angle Classifier Accuracies',\n",
    "         xlim=(0, 100),\n",
    "         xlabel='Classifier Training Epochs',\n",
    "         ylabel='Classifier Decoding Accuracy',\n",
    "         title=labels)\n",
    "for i in range(5):\n",
    "    ax[i].plot(all_accuracies[i])\n",
    "    \n",
    "fig.save(save + '3_1_angle_classifier_accuracies.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f0dd8d-ef76-426c-a73e-4e14fc43e235",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Comparing different models interpretability levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc051328-6a20-4de9-9dbf-02ef41b98454",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_trained_models(ignore_non_pt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c609a6-ad4e-465f-ba15-88bfac73ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c4_aux_models = ['nav_auxiliary_tasks/nav_c4_auxwall1', #Report proximal wall\n",
    "          'nav_auxiliary_tasks/nav_c4_auxwall3', #Report distal wall\n",
    "          'nav_auxiliary_tasks/nav_c4_auxeuclid2', #Report euclidean distance\n",
    "          'nav_auxiliary_tasks/nav_c4_auxeuclid1', #Report constant 0\n",
    "          'nav_auxiliary_tasks/nav_c4_auxeuclid0', #Basic 4 color no task\n",
    "         ]\n",
    "pproxim_aux_models = [\n",
    "          'nav_poster/nav_pproxim_auxwall1', #Report proximal wall\n",
    "          'nav_poster/nav_pproxim_auxwall2', #Report distal wall\n",
    "          'nav_poster/nav_pproxim_auxeuclid2', #Report euclidean distance\n",
    "          'nav_poster/nav_pproxim_auxeuclid1', #Report constant 0\n",
    "          'nav_poster/nav_pproxim_auxeuclid0', #Basic 4 color no task\n",
    "         ]\n",
    "shared_layer_models = [\n",
    "    'nav_invisible_shared/nav_c4_shared0',\n",
    "    'nav_invisible_shared/nav_c4_shared1',\n",
    "    'nav_invisible_shared/nav_c4_shared2'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6267f16c-f538-4175-b45a-359550a7d287",
   "metadata": {},
   "source": [
    "## c4 aux models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d23024a-ae49-4f1c-b734-a2b539955a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classifier_results = {}\n",
    "num_trials = 5\n",
    "pbar = tqdm(total=len(c4_aux_models)*num_trials)\n",
    "for model in c4_aux_models:\n",
    "    all_classifier_results[model] = []\n",
    "    for i in range(num_trials):\n",
    "        all_classifier_results[model].append(train_position_classifier(model, model_num=i))\n",
    "        pbar.update(1)\n",
    "pbar.close()\n",
    "pickle.dump(all_classifier_results, open(save + '4_1_c4_aux_model_posdecoder_randact.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd17c7-5185-4327-8ec6-cedbd6bc6005",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classifier_results = pickle.load(open(save + '4_1_c4_aux_model_posdecoder_randact.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd8ab0c-442d-4078-975e-d529b1e289b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [\n",
    "    [0, 1, 1, 0],\n",
    "    [2, 2, 3, 3],\n",
    "    [4, 4, 5, 5]\n",
    "]\n",
    "\n",
    "models = list(all_classifier_results)\n",
    "layers = all_classifier_results[models[0]][0]['labels']\n",
    "model_labels = ['', 'East Wall', 'West Wall', 'Euclidean', 'Null', 'None']\n",
    "\n",
    "fig, ax = pplt.subplots(array)\n",
    "ax.format(abc=True, abcloc='ul',\n",
    "          suptitle='Validation Accuracies for Different Auxiliary Models',\n",
    "          ylabel='Accuracy',\n",
    "          ylim=(0, 1),\n",
    "          xformatter=model_labels,\n",
    "          xlim=(-0.5, 4.5),\n",
    "          # xlocator='index',\n",
    "          xrotation=30,\n",
    "          title=layers,\n",
    "          xlabel='Auxiliary Task')\n",
    "\n",
    "for i, layer in enumerate(layers):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    \n",
    "    for j, model in enumerate(models):\n",
    "        model_results = all_classifier_results[model]\n",
    "        for k in range(len(model_results)):\n",
    "            xs.append(j)\n",
    "            ys.append(all_classifier_results[model][k]['final_valid_acc'][i])\n",
    "    \n",
    "    ax[i].scatter(xs, ys)\n",
    "            \n",
    "fig.savefig(save + '4_1_c4_aux_model_classifier_accuracies.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779eb0b5-24b7-4e24-ab8b-b75e8b35e5cd",
   "metadata": {},
   "source": [
    "### Are c4 model positions decodeable between random action and policy actions?\n",
    "\n",
    "Looks like they have similar susceptibility to false classifier training. This is likely also due to class imbalance? Maybe again a limitation of how classifiers are used for this decoding problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c8f3c-cece-42d5-a5a1-a9ac2bb3291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'nav_auxiliary_tasks/nav_c4_auxeuclid0'\n",
    "results = perform_ep_collection(model, model_num=0)\n",
    "\n",
    "classifier_results = train_position_classifier(model, model_num=model_num, random_actions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1220b6e4-09a7-4a1e-b142-91db91ce6fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_ep = perform_ep_collection(model, model_num=0, random_actions=True)\n",
    "\n",
    "one_ep_listed_activ, one_ep_pos, one_ep_angle, one_ep_grid_indexes = (\n",
    "    one_ep['listed_activ'],\n",
    "    one_ep['pos'],\n",
    "    one_ep['angle'],\n",
    "    one_ep['grid_indexes']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c545f-e3bd-4077-ac4b-80f9e6262e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(classifier_results['labels']):\n",
    "    activ = one_ep_listed_activ[i]\n",
    "    classifier = classifier_results['classifiers'][label]\n",
    "    with torch.no_grad():\n",
    "        probs = softmax(classifier(activ))\n",
    "    print(label, accuracy_score(one_ep_grid_indexes, probs.argmax(axis=1)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816d2314-bf4f-4b27-9e9a-56cc2aa81532",
   "metadata": {},
   "source": [
    "## c4 shared layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f12ce-7c63-4ded-b055-9d4f469980f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classifier_results = {}\n",
    "num_trials = 3\n",
    "pbar = tqdm(total=len(shared_layer_models)*num_trials)\n",
    "for model in shared_layer_models:\n",
    "    all_classifier_results[model] = []\n",
    "    for i in range(num_trials):\n",
    "        all_classifier_results[model].append(train_position_classifier(model, model_num=i))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ddcf1-4127-413b-a8c5-3e7180d239c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(nrows=1, ncols=1, refwidth=3)\n",
    "\n",
    "hs = []\n",
    "cycle = pplt.Cycle('default', m=['o', 'x', 'd'])\n",
    "for v, model in enumerate(shared_layer_models):\n",
    "    total_num_shared = model[-1]\n",
    "    \n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(all_classifier_results[model])):\n",
    "        labels = all_classifier_results[model][i]['labels']\n",
    "        accuracies = all_classifier_results[model][i]['final_valid_acc']\n",
    "        for j, label in enumerate(labels):\n",
    "            if 'shared_activation' in label:\n",
    "                layer_num = int(label[-1])\n",
    "                xs.append(layer_num - 0.1 + 0.1*v)\n",
    "                ys.append(accuracies[j])\n",
    "    h = ax.scatter(xs, ys, label=total_num_shared, alpha=0.3, cycle=cycle)\n",
    "    hs.append(h)\n",
    "ax.format(\n",
    "    ylim=(0, 1),\n",
    "    xticks=[0, 1, 2],\n",
    "    xlabel='Shared Layer Level',\n",
    "    ylabel='Accuracy',\n",
    "    title=['Decodeability of Different Levels of Shared Layers']\n",
    ")\n",
    "\n",
    "ax.legend(hs, loc='r', frame=False, ncols=1, label='Total\\nLayers\\nShared')\n",
    "fig.savefig(save + '4_2_shared_layer_accuracies.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d6eb05-7c14-42d3-bfba-cfcdd30db62c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8de5a1ad-8a1d-493f-916a-a02d0dea6ef4",
   "metadata": {},
   "source": [
    "## pproxim aux models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e8fc2-90cc-4fa0-8e0a-f0fb23cc5180",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, obs_rms, kwargs = load_model_and_env('nav_poster/nav_pproxim_auxwall1', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8dfe87-855f-4b61-92e6-c2fc93c52cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_classifier_results = {}\n",
    "num_trials = 5\n",
    "pbar = tqdm(total=len(pproxim_aux_models)*num_trials)\n",
    "for model in pproxim_aux_models:\n",
    "    all_classifier_results[model] = []\n",
    "    for i in range(num_trials):\n",
    "        all_classifier_results[model].append(train_position_classifier(model, model_num=i))\n",
    "        pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "pickle.dump(all_classifier_results, open(save + 'nav_pproxim_position_decoder_results.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712b7518-1c69-4334-906a-5f134c3390ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load plotting data\n",
    "all_classifier_results = pickle.load(open(save+'nav_pproxim_position_decoder_results.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9757d0b-cf93-4f8d-bb10-0b88d6e38e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [\n",
    "    [0, 1, 1, 0],\n",
    "    [2, 2, 3, 3],\n",
    "    [4, 4, 5, 5]\n",
    "]\n",
    "\n",
    "models = list(all_classifier_results)\n",
    "layers = all_classifier_results[models[0]][0]['labels']\n",
    "model_labels = ['', 'East Wall', 'North Wall', 'Euclidean', 'Null', 'None']\n",
    "\n",
    "fig, ax = pplt.subplots(array)\n",
    "ax.format(abc=True, abcloc='ul',\n",
    "          suptitle='Validation Accuracies for Different Auxiliary Models (Proximal Poster)',\n",
    "          ylabel='Accuracy',\n",
    "          ylim=(0, 1),\n",
    "          xformatter=model_labels,\n",
    "          xlim=(-0.5, 4.5),\n",
    "          # xlocator='index',\n",
    "          xrotation=30,\n",
    "          title=layers,\n",
    "          xlabel='Auxiliary Task')\n",
    "\n",
    "for i, layer in enumerate(layers):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    \n",
    "    for j, model in enumerate(models):\n",
    "        model_results = all_classifier_results[model]\n",
    "        for k in range(len(model_results)):\n",
    "            xs.append(j)\n",
    "            ys.append(all_classifier_results[model][k]['final_valid_acc'][i])\n",
    "    \n",
    "    ax[i].scatter(xs, ys)\n",
    "            \n",
    "fig.savefig(save + '4_3_pproxim_aux_model_classifier_accuracies.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0048a0-a7c8-4044-901b-72732655d567",
   "metadata": {},
   "source": [
    "### Exploring more in depth about representations learned\n",
    "\n",
    "Notes\n",
    "* On pproxim task it is important for the classifier to be trained on the same kinds of episodes it is evaluated on. E.g., if random actions are used, the episodes used for validation also need to be random actions. Likewise if the policy actions are used\n",
    "* pproxim agent seems to have interesting representations that are symmetrically encoded, perhaps due to the policy used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f81f52e-388e-4f68-beb3-10595e49850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nav_poster/nav_pproxim_auxwall2'\n",
    "model_num = 0\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, model_num)\n",
    "one_ep = evalu(model, obs_rms, env_kwargs=kwargs, n=1, \n",
    "               data_callback=nav_data_callback, with_activations=True)\n",
    "\n",
    "one_ep_pos = np.vstack(one_ep['data']['pos'])\n",
    "one_ep_angle = np.vstack(one_ep['data']['angle'])\n",
    "one_ep_stacked = stack_activations(one_ep['activations'])\n",
    "one_ep_grid_idxs = [find_grid_index(p) for p in one_ep_pos]\n",
    "\n",
    "\n",
    "activations_names = ['shared_activations', 'actor_activations', 'actor_activations',\n",
    "               'critic_activations', 'critic_activations']\n",
    "activation_idxs = [0, 0, 1, 0, 1]\n",
    "\n",
    "# activation_name = activations_names[0]\n",
    "# activation_idx = activation_idxs[0]\n",
    "# activations = one_ep_stacked[activation_name][activation_idx]\n",
    "# classifier = all_classifier_results[model_name][model_num]['classifiers'][f'{activation_name}_{activation_idx}']\n",
    "# probs = softmax(classifier(activations).detach())\n",
    "# steps = \n",
    "activation_name = activations_names[0]\n",
    "activation_idx = activation_idxs[0]\n",
    "activations = one_ep_stacked[activation_name][activation_idx]\n",
    "classifier = results['classifiers'][f'{activation_name}_{activation_idx}']\n",
    "probs = softmax(classifier(activations).detach())\n",
    "print(accuracy_score(one_ep_grid_idxs, probs.argmax(axis=1)))\n",
    "\n",
    "steps = np.linspace(0, len(one_ep_pos)-2, 4).astype(int)\n",
    "# fig, ax = pplt.subplots(1, 4, figsize=(10, 3), sharex=True, sharey=True)\n",
    "fig, ax = pplt.subplots(nrows=1, ncols=4)\n",
    "ax.format(\n",
    "    suptitle='Position Decoder on Untrained Policy',\n",
    "    title=[f'Step {step}' for step in steps],\n",
    "         xticks=[],\n",
    "         yticks=[],\n",
    "         xlim=[0, 300],\n",
    "         ylim=[0, 300])\n",
    "\n",
    "ax[0].plot([240, 240, 260, 260, 240], [60, 80, 80, 60, 60])\n",
    "ax[0].plot(one_ep_pos.T[0][:-1], one_ep_pos.T[1][:-1])\n",
    "for i, step in enumerate(steps):\n",
    "    ax[i].imshow(probs[step].reshape(5,5).rot90(), cmap='Blues', alpha=0.5, extent=(0, 300, 0, 300))\n",
    "    # plt.scatter(one_ep_pos.T[0, :step], one_ep_pos.T[1, :step], alpha=0.2)\n",
    "    draw_character(one_ep_pos[step], one_ep_angle[step], 20, ax=ax[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf22cc1-6d90-4009-b94c-cbe636719047",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_position_classifier(model_name, model_num=0, random_actions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250d2f36-1b51-4184-aa04-70cec6bd42c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 21\n",
    "action_randomizer = lambda step: np.random.choice([0, 1, 2])\n",
    "# one_ep = forced_action_evaluate(model, obs_rms, forced_actions=action_randomizer, env_kwargs=kwargs, \n",
    "#                                 data_callback=nav_data_callback, num_episodes=1, with_activations=True)\n",
    "one_ep = forced_action_evaluate(model, obs_rms, env_kwargs=kwargs, seed=seed,\n",
    "                                data_callback=poster_data_callback, num_episodes=1, with_activations=True)\n",
    "\n",
    "one_ep_pos = np.vstack(one_ep['data']['pos'])\n",
    "one_ep_angle = np.vstack(one_ep['data']['angle'])\n",
    "one_ep_stacked = stack_activations(one_ep['activations'])\n",
    "one_ep_grid_idxs = [find_grid_index(p) for p in one_ep_pos]\n",
    "\n",
    "print(len(one_ep_pos))\n",
    "for i in range(5):\n",
    "    activation_name = activations_names[i]\n",
    "    activation_idx = activation_idxs[i]\n",
    "    activations = one_ep_stacked[activation_name][activation_idx]\n",
    "    classifier = results['classifiers'][f'{activation_name}_{activation_idx}']\n",
    "    probs = softmax(classifier(activations).detach())\n",
    "    # print(probs.argmax(axis=1))\n",
    "    print(accuracy_score(one_ep_grid_idxs, probs.argmax(axis=1)))\n",
    "    \n",
    "steps = np.linspace(0, len(one_ep_pos)-3, 4).astype(int)\n",
    "# fig, ax = pplt.subplots(1, 4, figsize=(10, 3), sharex=True, sharey=True)\n",
    "fig, ax = pplt.subplots(nrows=1, ncols=4)\n",
    "ax.format(\n",
    "    suptitle='Position Decoder on Untrained Policy',\n",
    "    title=[f'Step {step}' for step in steps],\n",
    "         xticks=[],\n",
    "         yticks=[],\n",
    "         xlim=[0, 300],\n",
    "         ylim=[0, 300])\n",
    "\n",
    "see_poster_idxs = np.argwhere(one_ep['data']['poster_seen'])\n",
    "if len(see_poster_idxs) > 0:\n",
    "    poster_seen_idx = see_poster_idxs[0][0]\n",
    "    ax[0].plot(one_ep_pos.T[0][:poster_seen_idx], one_ep_pos.T[1][:poster_seen_idx],\n",
    "              c='red2')\n",
    "    ax[0].plot(one_ep_pos.T[0][poster_seen_idx:-1], one_ep_pos.T[1][poster_seen_idx:-1],\n",
    "              c='green2')    \n",
    "else:\n",
    "    ax[0].plot(one_ep_pos.T[0][:-1], one_ep_pos.T[1][:-1], c='red2')\n",
    "    \n",
    "ax[0].plot([240, 240, 260, 260, 240], [60, 80, 80, 60, 60])\n",
    "\n",
    "\n",
    "for i, step in enumerate(steps):\n",
    "    ax[i].imshow(probs[step].reshape(5,5).rot90(), cmap='Blues', alpha=0.5, extent=(0, 300, 0, 300))\n",
    "    # plt.scatter(one_ep_pos.T[0, :step], one_ep_pos.T[1, :step], alpha=0.2)\n",
    "    draw_character(one_ep_pos[step], one_ep_angle[step], 20, ax=ax[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95348c63-4f28-46e8-86bc-60517ff81af2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show all steps\n",
    "i = 0\n",
    "activation_name = activations_names[i]\n",
    "activation_idx = activation_idxs[i]\n",
    "activations = one_ep_stacked[activation_name][activation_idx]\n",
    "classifier = results['classifiers'][f'{activation_name}_{activation_idx}']\n",
    "probs = softmax(classifier(activations).detach())\n",
    "\n",
    "\n",
    "\n",
    "nrows = int(np.ceil(len(one_ep_pos) / 4))\n",
    "fig, ax = pplt.subplots(nrows=nrows, ncols=4)\n",
    "for i in range(len(one_ep_pos)-1):\n",
    "    ax[i].imshow(probs[i].reshape(5, 5).rot90(), cmap='Blues', alpha=0.5, extent=(0, 300, 0, 300))\n",
    "    draw_character(one_ep_pos[i], one_ep_angle[i], 20, ax=ax[i])\n",
    "    ax[i].plot([240, 240, 260, 260, 240], [60, 80, 80, 60, 60])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d891d5e-20b8-41e5-ba10-43c148d90a08",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analyzing representation development over training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703fbe33-5bc9-483b-8ed3-95015604d05e",
   "metadata": {},
   "source": [
    "## Random initiated model\n",
    "\n",
    "Here we wanted to test how trainable a classifeir with randomly initiated policy would actually be. Turns out not very much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f037e687-ffe4-4f56-aed1-c4bcdcc66ee1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, _, kwargs = pickle.load(open('../trained_models/ppo/nav_invisible_shared/nav_c4_shared0_env',  'rb'))\n",
    "env = gym.make('NavEnv-v0', **kwargs)\n",
    "\n",
    "model = Policy(env.observation_space.shape,\n",
    "          env.action_space,\n",
    "          base='FlexBase',\n",
    "          base_kwargs={'recurrent': True,\n",
    "                      'num_shared_layers':  0})\n",
    "envs = make_vec_envs('NavEnv-v0', 0, 1, 0.99, '/tmp/gym/',\n",
    "                     torch.device('cpu'), False, env_kwargs=kwargs)\n",
    "obs_rms = getattr(utils.get_vec_normalize(envs), 'obs_rms', None)\n",
    "\n",
    "results = train_position_classifier(model, obs_rms, kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d286de3-866b-4ffd-a494-e63a3382b58c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "array = [\n",
    "    [0, 1, 1, 0],\n",
    "    [2, 2, 3, 3],\n",
    "    [4, 4, 5, 5]\n",
    "]\n",
    "fig, ax = pplt.subplots(array)\n",
    "ax.format(abc=True, abcloc='ul', \n",
    "          suptitle='Training Position Decoder on New Policies',\n",
    "         xlim=(0, 100),\n",
    "         xlabel='Classifier Training Epochs',\n",
    "         ylabel='Classifier Decoding Accuracy',\n",
    "         title=results['labels'])\n",
    "for i in range(5):\n",
    "    ax[i].plot(results['training_acc'][i])\n",
    "    \n",
    "fig.save(save + '5_1_position_decoder_untrainedpolicy_classifier_accuracies.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c160cb52-3209-433c-ad4e-ed113cd122f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_ep = forced_action_evaluate(model, obs_rms, forced_actions=action_randomizer, env_kwargs=kwargs, \n",
    "                                data_callback=nav_data_callback, num_episodes=1, with_activations=True)\n",
    "\n",
    "\n",
    "one_ep_pos = np.vstack(one_ep['data']['pos'])\n",
    "one_ep_angle = np.vstack(one_ep['data']['angle'])\n",
    "one_ep_stacked = stack_activations(one_ep['activations'])\n",
    "classifier = results['classifiers']['shared_activations_0']\n",
    "with torch.no_grad():\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    y = classifier(one_ep_stacked['shared_activations'][0])\n",
    "    probs = softmax(y)\n",
    "\n",
    "\n",
    "steps = [0, 2, 5, 9]\n",
    "# fig, ax = pplt.subplots(1, 4, figsize=(10, 3), sharex=True, sharey=True)\n",
    "fig, ax = pplt.subplots(nrows=1, ncols=4)\n",
    "ax.format(\n",
    "    suptitle='Position Decoder on Untrained Policy',\n",
    "    title=[f'Step {step}' for step in steps],\n",
    "         xticks=[],\n",
    "         yticks=[])\n",
    "\n",
    "for i, step in enumerate(steps):\n",
    "    ax[i].imshow(probs[step].reshape(5,5).rot90(), cmap='Blues', alpha=0.5, extent=(0, 300, 0, 300))\n",
    "    # plt.scatter(one_ep_pos.T[0, :step], one_ep_pos.T[1, :step], alpha=0.2)\n",
    "    draw_character(one_ep_pos[step], one_ep_angle[step], 20, ax=ax[i])\n",
    "\n",
    "plt.savefig(save + '5_1_untrainedpolicy_live_episode_decoding.png')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a05ec57-43ba-4861-9fa5-c98847cf6327",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Shared layer training checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e4332c-8ce1-4977-955f-6b5d5c14c386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = '../trained_models/checkpoint'\n",
    "model_names = ['nav_c4_shared0_t0', 'nav_c4_shared1_t0', 'nav_c4_shared2_t0']\n",
    "env_folder = '../trained_models/ppo/nav_invisible_shared'\n",
    "env_names = [f'{env_folder}/{model.split(\"_t0\")[0]}_env' for model in model_names]\n",
    "\n",
    "checkpoint_results = defaultdict(list)\n",
    "checkpoint_labels = defaultdict(list)\n",
    "\n",
    "total_checkpoints = 10 * 3\n",
    "pbar = tqdm(total=total_checkpoints)\n",
    "for i in range(len(model_names)):\n",
    "    model_name = model_names[i]\n",
    "    env = env_names[i]\n",
    "    \n",
    "    checkpoints = list((Path(folder)/model_name).iterdir())\n",
    "    kwargs = pickle.load(open(env, 'rb'))\n",
    "\n",
    "\n",
    "    for checkpoint in checkpoints:\n",
    "        model, obs_rms = torch.load(checkpoint)\n",
    "        checkpoint_results[model_name].append(train_position_classifier(\n",
    "            model, obs_rms=obs_rms, kwargs=kwargs\n",
    "        ))\n",
    "        checkpoint_labels[model_name].append(int(checkpoints[i].name.split('.pt')[0]))\n",
    "        pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "pickle.dump([checkpoint_results, checkpoint_labels], open(save + '5_2_checkpoint_decoder_data.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df59dc0-4a61-47fb-ad0f-a2d29c84dda2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load data for plot\n",
    "#Might want to use this later for to further test the classifiers\n",
    "#  for other measures of total decodeability\n",
    "checkpoint_results, checkpoint_labels = pickle.load(open(save + '5_2_checkpoint_decoder_data.pickle',  'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaab279-6b08-4525-81d5-323b110b6a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(nrows=1, ncols=3)\n",
    "\n",
    "labels = ['shared_activations_0', 'shared_activations_1', 'shared_activations_2']\n",
    "label_idxs = [0, 1, 2]\n",
    "ignore_first = 100\n",
    "\n",
    "ax.format(\n",
    "    xlabel='Episodes trained',\n",
    "    ylabel='Position decoder accuracy',\n",
    "    title=labels,\n",
    "    suptitle='Representation Decodeability Through Training'\n",
    ")\n",
    "taxs = ax.panel('t', space=0, share=False)\n",
    "taxs.format(title='Model learning curve',\n",
    "           xticks=[390000],\n",
    "           xformatter='%.E',\n",
    "           xlim=[0, 400000])\n",
    "\n",
    "colors = pplt.Cycle('default').by_key()['color']\n",
    "hs = []\n",
    "for i, model_name in enumerate(model_names):\n",
    "    for j in range(i+1):\n",
    "        label = labels[j]\n",
    "        label_idx = label_idxs[j]\n",
    "        xs = []\n",
    "        ys = []\n",
    "        for k in range(len(checkpoint_results[model_name])):\n",
    "            ys.append(checkpoint_results[model_name][k]['final_valid_acc'][label_idx])\n",
    "            xs.append(checkpoint_labels[model_name][k])\n",
    "\n",
    "        xs = [int(checkpoint.name.split('.pt')[0]) for checkpoint in checkpoints]\n",
    "        h = ax[j].plot(xs, ys, c=colors[i], label=i)\n",
    "        \n",
    "        xs2, ys2, min_x, max_x = average_runs(goal_exp_names[i], 'length', ret=True)\n",
    "        ys2 = ys2.mean(axis=0)\n",
    "        # xs2 = xs2 / 400000 * 832\n",
    "        # ys2 = ys2.mean(axis=0) / 200\n",
    "        taxs[j].plot(xs2[ignore_first:], ys2[ignore_first:], c=colors[i])\n",
    "    hs.append(h)\n",
    "\n",
    "fig.legend(hs, loc='r', frame=False, ncols=1, label='Total\\nLayers\\nnShared')\n",
    "fig.savefig(save + '5_2_shared_layer_decodeability_training.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adaa790-ab0e-4041-8358-971898bdc24b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Checking decodeability of deepest layer\n",
    "\n",
    "Decodeability does not seem to improve in the deepest layer as the agent learns to perform the task. So we should confirm first that the deepest layer is not really representing position, then we can start to use this as an exploration of what other deeper features are being learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5455d4-1565-4179-96bd-2c97bde0a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94abaad1-2e8d-4d7c-88c8-79f844689712",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_results['nav_c4_shared2_t0'][0]['classifiers']['shared_activations_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ac8776-074c-4d9e-a29d-fdee7d8d0dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "model = 'nav_invisible_shared/nav_c4_shared2'\n",
    "results = train_position_classifier(model, model_num=0, random_actions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b4c2bc-c878-4226-a44c-005b65a0e673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 2\n",
    "activation_name = 'shared_activations'\n",
    "depth = 2\n",
    "label = f'{activation_name}_{depth}'\n",
    "label_idx = 2\n",
    "\n",
    "one_ep = perform_ep_collection(model, model_num=0, random_actions=False, seed=seed)\n",
    "\n",
    "one_ep_listed_activ, one_ep_pos, one_ep_angle, one_ep_grid_indexes = (\n",
    "    one_ep['listed_activ'],\n",
    "    one_ep['pos'],\n",
    "    one_ep['angle'],\n",
    "    one_ep['grid_indexes']\n",
    ")\n",
    "\n",
    "activations = one_ep_listed_activ[label_idx]\n",
    "# classifier = checkpoint_results['nav_c4_shared2_t0'][-1]['classifiers'][label]\n",
    "classifier = results['classifiers'][label]\n",
    "probs = softmax(classifier(activations).detach())\n",
    "print(len(one_ep_pos))\n",
    "accuracy_score(one_ep_grid_indexes, probs.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425348d4-2115-42e4-9dcd-7076827c7238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show all steps\n",
    "# max_shown = 20\n",
    "\n",
    "# nrows = min(int(np.ceil(len(one_ep_pos) / 4)), int(max_shown / 4))\n",
    "nrows = int(np.ceil(len(one_ep_pos) / 4))\n",
    "fig, ax = pplt.subplots(nrows=nrows, ncols=4)\n",
    "for i in range(len(one_ep_pos)-1):\n",
    "# for i in range(20):\n",
    "    ax[i].imshow(probs[i].reshape(5, 5).rot90(), cmap='Blues', alpha=0.5, extent=(0, 300, 0, 300))\n",
    "    draw_character(one_ep_pos[i], one_ep_angle[i], 20, ax=ax[i])\n",
    "    ax[i].plot([240, 240, 260, 260, 240], [60, 80, 80, 60, 60])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca273ea6-c597-4ef2-b7f8-1d527c33a250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show all steps\n",
    "# max_shown = 20\n",
    "\n",
    "# nrows = min(int(np.ceil(len(one_ep_pos) / 4)), int(max_shown / 4))\n",
    "nrows = int(np.ceil(len(one_ep_pos) / 4))\n",
    "fig, ax = pplt.subplots(nrows=nrows, ncols=4)\n",
    "for i in range(len(one_ep_pos)-1):\n",
    "# for i in range(20):\n",
    "    ax[i].imshow(probs[i].reshape(5, 5).rot90(), cmap='Blues', alpha=0.5, extent=(0, 300, 0, 300))\n",
    "    draw_character(one_ep_pos[i], one_ep_angle[i], 20, ax=ax[i])\n",
    "    ax[i].plot([240, 240, 260, 260, 240], [60, 80, 80, 60, 60])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0215b289-bc72-4d3d-8820-2f0a85594968",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check whether classifier difference of random actions and policy actions are class imbalance issue\n",
    "\n",
    "(Not really completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f53c90b-5005-4d37-a744-fd0faa304237",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'nav_auxiliary_tasks2/nav_c4_auxeuclid1'\n",
    "model_name = 'nav_auxiliary_tasks2/nav_c4_auxeuclid1'\n",
    "\n",
    "randact_eps = perform_ep_collection(model, model_num=1, random_actions=True, num_episodes=30)\n",
    "polact_eps = perform_ep_collection(model, model_num=1, random_actions=False, num_episodes=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e659e644-417d-45de-b90f-14910d7f24b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dist(x, y):\n",
    "    return np.sqrt(np.sum((x - y)**2))\n",
    "\n",
    "def prune_stuck_pos(pos):\n",
    "    # polpos = polpos = np.vstack((polact_eps['pos'], [[0, 0],[300,300]]))\n",
    "    last_pos = np.array([0, 0])\n",
    "    cum_sim = 0\n",
    "    start_sim = 0\n",
    "\n",
    "    all_starts = []\n",
    "    all_ends = []\n",
    "    \n",
    "    min_consec = 50\n",
    "    \n",
    "    # Find episodes where agent got stuck by looking for places where it was in the\n",
    "    # same position for more than min_consec number of timesteps\n",
    "    for i in range(pos.shape[0]):\n",
    "        if dist(last_pos, pos[i]) < 2:\n",
    "            if cum_sim == 0:\n",
    "                start_sim = i\n",
    "            cum_sim += 1\n",
    "        else:\n",
    "            if cum_sim > min_consec:\n",
    "                all_starts.append(start_sim)\n",
    "                all_ends.append(i)\n",
    "\n",
    "            cum_sim = 0\n",
    "\n",
    "        last_pos = pos[i]\n",
    "    \n",
    "    if len(all_starts) == 0:\n",
    "        return pos, ([], [])\n",
    "\n",
    "    \n",
    "    new_pos = np.array([])\n",
    "    # Trim these out of positions\n",
    "    for i in range(len(all_starts)):\n",
    "        if i == 0:\n",
    "            new_pos = pos[0:all_starts[0]]\n",
    "        elif i == len(all_starts) - 1:\n",
    "            new_pos = np.vstack([new_pos, pos[all_ends[i]:]])\n",
    "        else:\n",
    "            new_pos = np.vstack([new_pos, pos[all_ends[i]:all_starts[i+1]]])\n",
    "    return new_pos, (all_starts, all_ends)\n",
    "    \n",
    "\n",
    "\n",
    "def prune_fail_episodes(targets, dones):\n",
    "    max_ep_len = 202\n",
    "    done_idxs = np.where(np.vstack(dones))[0]\n",
    "    diffs = np.diff(done_idxs)\n",
    "    incomplete_idxs = np.where(diffs == max_ep_len)[0]\n",
    "    \n",
    "    pruned_targets = []\n",
    "    \n",
    "    for i in range(len(done_idxs)):\n",
    "        if i == 0:\n",
    "            done_targets = targets[:done_idxs[i]]\n",
    "        else:\n",
    "            done_targets = targets[done_idxs[i-1]:done_idxs[i]]\n",
    "        \n",
    "        if i-1 not in incomplete_idxs:\n",
    "            pruned_targets.append(done_targets)\n",
    "    \n",
    "    return pruned_targets\n",
    "\n",
    "pruned = prune_fail_episodes(polact_eps['pos'], polact_eps['dones'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5afe9a7-8b77-474e-9d3a-d7bb3598d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pos = np.vstack(pruned)\n",
    "fig, ax = pplt.subplots()\n",
    "a = ax.hist2d(new_pos.T[0], new_pos.T[1], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37ef673-8ea3-42c1-9254-b024d059625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "randpos = np.vstack((randact_eps['pos'], [[0, 0],[300,300]])).T\n",
    "polpos = np.vstack((polact_eps['pos'], [[0, 0],[300,300]])).T\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=1, ncols=2)\n",
    "bins = 20\n",
    "ranbins = ax[0].hist2d(randpos[0], randpos[1], bins=bins)\n",
    "polbins = ax[1].hist2d(polpos[0], polpos[1], bins=bins,\n",
    "                      colorbar=True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a24c1d9-2673-4f46-b0a0-e3159275896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "envs = quick_vec_env(obs_rms, kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469dae2f-23e3-4863-b888-e74f68f11114",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('NavEnv-v0', **kwargs)\n",
    "fig, ax = pplt.subplots(ncols=2, share=True)\n",
    "pos = []\n",
    "for i in range(10000):\n",
    "    env.reset()\n",
    "    pos.append(env.character.pos)\n",
    "\n",
    "x = np.vstack(pos).T\n",
    "a = ax[0].hist2d(x[0], x[1], bins=30)\n",
    "env.boxes[-1].draw(ax=ax[0])\n",
    "\n",
    "\n",
    "kwargs2 = kwargs.copy()\n",
    "kwargs2['character_reset_pos'] = 1\n",
    "env = gym.make('NavEnv-v0', **kwargs2)\n",
    "\n",
    "pos = []\n",
    "for i in range(10000):\n",
    "    env.reset()\n",
    "    pos.append(env.character.pos)\n",
    "\n",
    "x = np.vstack(pos).T\n",
    "a = ax[1].hist2d(x[0], x[1], bins=30)\n",
    "env.boxes[-1].draw(ax=ax[1])\n",
    "ax.format(xlim=[0, 300], ylim=[0, 300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8bdda8-e8de-41f5-b647-ab511dd75b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = pickle.load(open('../trained_models/ppo/nav_auxiliary_tasks2/nav_c4_auxeuclid0_env', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d6e746-c3be-4c7a-b152-f1eebc02d6a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Looking for different ways to search representations\n",
    "\n",
    "(Didn't save the utputs of these cells. Mostly were heatmaps of actiations across different trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68293925-861c-4467-a772-9f1910ae0b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e425a84e-c7be-4a9e-bb0e-5d136ca8fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nav_auxiliary_tasks2/nav_c4_auxeuclid1'\n",
    "\n",
    "eps = perform_ep_collection(model_name, model_num=1, \n",
    "                                   random_actions=False, num_episodes=100)\n",
    "reducer = umap.UMAP(random_state=0)\n",
    "reduced = reducer.fit_transform(shared_activs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8141eb-7fa3-4ddb-9587-89d014805034",
   "metadata": {},
   "outputs": [],
   "source": [
    "dones = eps['dones']\n",
    "shared_activs = torch.vstack(\n",
    "    prune_fail_episodes(eps['stacked']['shared_activations'][0], dones))\n",
    "pos = np.vstack(prune_fail_episodes(eps['pos'], dones))\n",
    "angle = np.vstack(prune_fail_episodes(eps['angle'], dones))\n",
    "goal_center = np.array([250., 70.])\n",
    "dists = np.sqrt(((pos - goal_center)**2).sum(axis=1))\n",
    "\n",
    "#time steps during episodes\n",
    "\n",
    "steps = []\n",
    "initial_distances = []\n",
    "initial_angles = []\n",
    "i = 1\n",
    "initial_distance = dist(eps['pos'][0], goal_center)\n",
    "initial_angle = eps['angle'][0].item()\n",
    "for j, done in enumerate(dones):\n",
    "    if done[0] == True:\n",
    "        i = 1\n",
    "        initial_distance = dist(eps['pos'][j], goal_center)\n",
    "        initial_angle = eps['angle'][j].item()\n",
    "    steps.append(i)\n",
    "    initial_distances.append(initial_distance)\n",
    "    initial_angles.append(initial_angle)\n",
    "    i += 1\n",
    "steps = np.array(steps)\n",
    "steps = np.concatenate(prune_fail_episodes(steps, dones))\n",
    "initial_distances = np.array(initial_distances)\n",
    "initial_distances = np.concatenate(prune_fail_episodes(initial_distances, dones))\n",
    "initial_angles = np.array(initial_angles)\n",
    "initial_angles = np.concatenate(prune_fail_episodes(initial_angles, dones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4227dd48-311f-486a-952d-3653a15aa03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(nrows=2, ncols=4)\n",
    "ax.format(\n",
    "    xlabel='UMAP Dimension 1',\n",
    "    ylabel='UMAP Dimension 2',\n",
    "    title=['Angle', 'Dist to Goal', 'Timestep', 'X pos', 'Y pos', \n",
    "           'Initial Distance', 'Initial Angle', '']\n",
    ")\n",
    "ax[0].scatter(reduced.T[0], reduced.T[1], c=angle.T[0], colorbar='t')\n",
    "ax[1].scatter(reduced.T[0], reduced.T[1], c=dists, colorbar='t')\n",
    "ax[2].scatter(reduced.T[0], reduced.T[1], c=steps, colorbar='t')\n",
    "ax[3].scatter(reduced.T[0], reduced.T[1], c=pos.T[0], colorbar='t')\n",
    "ax[4].scatter(reduced.T[0], reduced.T[1], c=pos.T[1], colorbar='t')\n",
    "ax[5].scatter(reduced.T[0], reduced.T[1], c=initial_distances, colorbar='t')\n",
    "ax[6].scatter(reduced.T[0], reduced.T[1], c=initial_angles, colorbar='t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b063ba-47be-46af-b918-9f2e5e2caac0",
   "metadata": {},
   "source": [
    "### Heatmap activation nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3657e96-788e-4d71-a8f6-1b2683be4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(nrows=8, ncols=8)\n",
    "for i in range(64):\n",
    "    ax[i].scatter(pos.T[0], pos.T[1], c=shared_activs[:, i], alpha=0.5)\n",
    "# plt.scatter(pos.T[0], pos.T[1], c=shared_activs[:, 0], alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd5c097-1bcf-4876-8307-b90d9f468ea1",
   "metadata": {},
   "source": [
    "**Here we use starting positions along the outside perimeter of the pool as the agent tends to move towards the goal directly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12e2a17-1ef6-4ac7-9776-4863a664745a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Starting points for the next cell\n",
    "\n",
    "fine_pos = np.linspace(5, 295, 30)\n",
    "starting_pos = []\n",
    "#top and bottom row starts\n",
    "for i in range(len(fine_pos)):\n",
    "    starting_pos.append([fine_pos[i], 295])\n",
    "    starting_pos.append([fine_pos[i], 5])\n",
    "    \n",
    "#left and right column starts\n",
    "for i in range(1, len(fine_pos)-1):\n",
    "    starting_pos.append([5, fine_pos[i]])\n",
    "    starting_pos.append([295, fine_pos[i]])\n",
    "\n",
    "starting_pos = np.array(starting_pos)\n",
    "\n",
    "fig, ax = pplt.subplots()\n",
    "ax.scatter(starting_pos.T[0], starting_pos.T[1])\n",
    "ax.format(title='Manual starting positions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c2c665-2e53-4608-ae7b-f1c1035f38de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Generate activations for episodes starting from edges of the maze\n",
    "\n",
    "model_name = 'nav_auxiliary_tasks2/nav_c4_auxeuclid1'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "\n",
    "all_results = []\n",
    "for i in tqdm(range(len(starting_pos))):\n",
    "    point = starting_pos[i]\n",
    "    angle = None\n",
    "    kwargs['fixed_reset'] = [point, angle]\n",
    "    results = evalu(model, obs_rms, n=1, env_kwargs=kwargs, with_activations=True,\n",
    "                    data_callback=nav_data_callback)\n",
    "    all_results.append(results)\n",
    "\n",
    "\n",
    "stacked_activations = [stack_activations(all_results[i]['activations']) for i in range(len(all_results))]\n",
    "keys = stacked_activations[0].keys()\n",
    "all_stacked_activations = defaultdict(list)\n",
    "for key in keys:\n",
    "    for i in range(len(stacked_activations)):\n",
    "        all_stacked_activations[key].append(stacked_activations[i][key])\n",
    "    all_stacked_activations[key] = torch.cat(all_stacked_activations[key], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ff22b-0cd7-4a4d-a743-f50b444ce9ec",
   "metadata": {},
   "source": [
    "This shows the path that the agent takes when given these starting conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e36f380-af4c-48c7-8382-c0f4782ac9bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fixpos = np.vstack([np.vstack(all_results[i]['data']['pos']) for i in range(len(all_results))])\n",
    "\n",
    "fig, ax = pplt.subplots()\n",
    "ax.scatter(fixpos.T[0], fixpos.T[1], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a927d8-8ae3-4f3d-90bc-5cd8d1e41365",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(nrows=8, ncols=8)\n",
    "for i in range(64):\n",
    "    ax[i].scatter(fixpos.T[0], fixpos.T[1], c=all_stacked_activations['shared_activations'][0, :, i], alpha=0.5)\n",
    "# plt.scatter(pos.T[0], pos.T[1], c=shared_activs[:, 0], alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1e65b5-76b6-4541-bf70-796256adffd4",
   "metadata": {},
   "source": [
    "**Now we take grid steps and random actions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3927642c-8093-4b6e-b4eb-730ba96abe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_points = []\n",
    "for x in fine_pos:\n",
    "    for y in fine_pos:\n",
    "        grid_points.append(np.array([x, y]))\n",
    "grid_points = np.vstack(grid_points)\n",
    "\n",
    "model_name = 'nav_auxiliary_tasks2/nav_c4_auxeuclid1'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "\n",
    "kwargs['max_steps'] = 20\n",
    "action_randomizer = lambda step: np.random.choice([0, 1, 2])\n",
    "\n",
    "all_results = []\n",
    "for i in tqdm(range(len(grid_points))):\n",
    "    point = grid_points[i]\n",
    "    angle = None\n",
    "    kwargs['fixed_reset'] = [point, angle]\n",
    "    results = forced_action_evaluate(model, obs_rms, forced_actions=action_randomizer, env_kwargs=kwargs, \n",
    "                                    data_callback=nav_data_callback, num_episodes=1, with_activations=True\n",
    "                                    )\n",
    "    all_results.append(results)\n",
    "    \n",
    "ignore_first = 5 #ignore first 5 steps of each episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bcfb53-1e49-45a5-aa0c-b87d3a287da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_activations = [stack_activations(all_results[i]['activations']) for i in range(len(all_results))]\n",
    "keys = stacked_activations[0].keys()\n",
    "all_stacked_activations = defaultdict(list)\n",
    "for key in keys:\n",
    "    for i in range(len(stacked_activations)):\n",
    "        if len(all_results[i]['data']['pos']) > ignore_first+1:\n",
    "            all_stacked_activations[key].append(stacked_activations[i][key][:, ignore_first:-1, :])\n",
    "    all_stacked_activations[key] = torch.cat(all_stacked_activations[key], dim=1)\n",
    "    \n",
    "randpos = []\n",
    "for i in range(len(all_results)):\n",
    "    pos_data = all_results[i]['data']['pos']\n",
    "    if len(pos_data) > ignore_first+1:\n",
    "        randpos.append(pos_data[ignore_first:-1])\n",
    "\n",
    "randpos = np.vstack(randpos)\n",
    "\n",
    "fig, ax = pplt.subplots()\n",
    "ax.scatter(randpos.T[0], randpos.T[1], alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff48312-c2bf-4e4f-8237-a2388542a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(nrows=8, ncols=8)\n",
    "for i in range(64):\n",
    "    ax[i].scatter(randpos.T[0], randpos.T[1], c=all_stacked_activations['shared_activations'][0, :, i], alpha=0.1)\n",
    "# plt.scatter(pos.T[0], pos.T[1], c=shared_activs[:, 0], alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea3400c-6730-4b30-bc05-6046b55d34bd",
   "metadata": {},
   "source": [
    "**One more time with more randomzied actions since they were made consistent by the seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8a40f0-599f-49f6-b82e-ef15cb380d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_points = []\n",
    "for x in fine_pos:\n",
    "    for y in fine_pos:\n",
    "        grid_points.append(np.array([x, y]))\n",
    "grid_points = np.vstack(grid_points)\n",
    "\n",
    "model_name = 'nav_auxiliary_tasks2/nav_c4_auxeuclid1'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "\n",
    "kwargs['max_steps'] = 20\n",
    "action_randomizer = lambda step: np.random.choice([0, 1, 2])\n",
    "\n",
    "all_results = []\n",
    "for i in tqdm(range(len(grid_points))):\n",
    "    point = grid_points[i]\n",
    "    angle = None\n",
    "    kwargs['fixed_reset'] = [point, angle]\n",
    "    results = forced_action_evaluate(model, obs_rms, forced_actions=action_randomizer, env_kwargs=kwargs, \n",
    "                                    data_callback=nav_data_callback, num_episodes=1, with_activations=True,\n",
    "                                    seed=i)\n",
    "    all_results.append(results)\n",
    "    \n",
    "ignore_first = 5 #ignore first 5 steps of each episode\n",
    "\n",
    "stacked_activations = [stack_activations(all_results[i]['activations']) for i in range(len(all_results))]\n",
    "keys = stacked_activations[0].keys()\n",
    "all_stacked_activations = defaultdict(list)\n",
    "for key in keys:\n",
    "    for i in range(len(stacked_activations)):\n",
    "        if len(all_results[i]['data']['pos']) > ignore_first+1:\n",
    "            all_stacked_activations[key].append(stacked_activations[i][key][:, ignore_first:-1, :])\n",
    "    all_stacked_activations[key] = torch.cat(all_stacked_activations[key], dim=1)\n",
    "    \n",
    "randpos = []\n",
    "for i in range(len(all_results)):\n",
    "    pos_data = all_results[i]['data']['pos']\n",
    "    if len(pos_data) > ignore_first+1:\n",
    "        randpos.append(pos_data[ignore_first:-1])\n",
    "\n",
    "randpos = np.vstack(randpos)\n",
    "\n",
    "fig, ax = pplt.subplots()\n",
    "ax.scatter(randpos.T[0], randpos.T[1], alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709045c3-283a-4f54-a9b8-96e1e8788596",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(nrows=8, ncols=8)\n",
    "for i in range(64):\n",
    "    ax[i].scatter(randpos.T[0], randpos.T[1], c=all_stacked_activations['shared_activations'][0, :, i], alpha=0.1)\n",
    "# plt.scatter(pos.T[0], pos.T[1], c=shared_activs[:, 0], alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f1e1c4-9f89-414d-b436-95da9a7d341e",
   "metadata": {},
   "source": [
    "**Fixed seed different? Maybe one headed away from goal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f136c16-fb06-41a7-ad09-89d6e434e202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = forced_action_evaluate(model, obs_rms, forced_actions=action_randomizer, env_kwargs=kwargs, \n",
    "                                data_callback=nav_data_callback, num_episodes=1, with_activations=True,\n",
    "                                seed=2)\n",
    "pos = np.vstack(results['data']['pos']).T\n",
    "fig, ax = pplt.subplots()\n",
    "ax.scatter(pos[0], pos[1], c=np.arange(pos.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f7e3c4-7292-498a-bf84-86422c85a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_points = []\n",
    "for x in fine_pos:\n",
    "    for y in fine_pos:\n",
    "        grid_points.append(np.array([x, y]))\n",
    "grid_points = np.vstack(grid_points)\n",
    "\n",
    "model_name = 'nav_auxiliary_tasks2/nav_c4_auxeuclid1'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "\n",
    "kwargs['max_steps'] = 20\n",
    "action_randomizer = lambda step: np.random.choice([0, 1, 2])\n",
    "\n",
    "all_results = []\n",
    "for i in tqdm(range(len(grid_points))):\n",
    "    point = grid_points[i]\n",
    "    angle = None\n",
    "    kwargs['fixed_reset'] = [point, angle]\n",
    "    results = forced_action_evaluate(model, obs_rms, forced_actions=action_randomizer, env_kwargs=kwargs, \n",
    "                                    data_callback=nav_data_callback, num_episodes=1, with_activations=True,\n",
    "                                    seed=2)\n",
    "    all_results.append(results)\n",
    "    \n",
    "ignore_first = 5 #ignore first 5 steps of each episode\n",
    "\n",
    "stacked_activations = [stack_activations(all_results[i]['activations']) for i in range(len(all_results))]\n",
    "keys = stacked_activations[0].keys()\n",
    "all_stacked_activations = defaultdict(list)\n",
    "for key in keys:\n",
    "    for i in range(len(stacked_activations)):\n",
    "        if len(all_results[i]['data']['pos']) > ignore_first+1:\n",
    "            all_stacked_activations[key].append(stacked_activations[i][key][:, ignore_first:-1, :])\n",
    "    all_stacked_activations[key] = torch.cat(all_stacked_activations[key], dim=1)\n",
    "    \n",
    "randpos = []\n",
    "for i in range(len(all_results)):\n",
    "    pos_data = all_results[i]['data']['pos']\n",
    "    if len(pos_data) > ignore_first+1:\n",
    "        randpos.append(pos_data[ignore_first:-1])\n",
    "\n",
    "randpos = np.vstack(randpos)\n",
    "\n",
    "fig, ax = pplt.subplots()\n",
    "ax.scatter(randpos.T[0], randpos.T[1], alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6985fb0d-6a32-4a65-bcb6-232eab7cc647",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(nrows=8, ncols=8)\n",
    "for i in range(64):\n",
    "    ax[i].scatter(randpos.T[0], randpos.T[1], c=all_stacked_activations['shared_activations'][0, :, i], alpha=0.1)\n",
    "# plt.scatter(pos.T[0], pos.T[1], c=shared_activs[:, 0], alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d519ec67-0582-471d-a4cd-cadb422ce832",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Behavior / Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae2cf3-0fcb-4840-8cba-fb0494c4b4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'nav_poster_netstructure/nav_pproxim_width2batch200'\n",
    "# model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "# eps = evalu(model, obs_rms, n=25, env_kwargs=kwargs, data_callback=poster_data_callback, \n",
    "#             with_activations=True, verbose=1)\n",
    "\n",
    "# ep_pos = split_by_ep(np.vstack(eps['data']['pos']), np.vstack(eps['dones']))\n",
    "# ep_angles = split_by_ep(np.vstack(eps['data']['angle']), np.vstack(eps['dones']))\n",
    "# ep_poster_seen = split_by_ep(np.vstack(eps['data']['poster_in_view']), np.vstack(eps['dones']))\n",
    "\n",
    "fig = pplt.figure()\n",
    "ax = fig.subplots(nrows=5, ncols=5, xlim=[0, 300], ylim=[0, 300])\n",
    "ax.format(xticks=[], yticks=[], \n",
    "          suptitle='Proximal Poster Example Trajectories: Width 2',\n",
    "          rc_kw={'suptitle.size': 24})\n",
    "for i in range(len(ax)):\n",
    "    p = ep_pos[i]\n",
    "    a = ep_angles[i]\n",
    "    draw_character(p[0], a[0], ax=ax[i], size=20, color='y')\n",
    "    draw_box(ax=ax[i])\n",
    "    draw_box(corner=np.array([298, 125]), size=[2, 50], c='r', ax=ax[i])\n",
    "\n",
    "    seen_idxs = np.argwhere(ep_poster_seen[i].squeeze()).squeeze()\n",
    "    if len(seen_idxs) > 0:\n",
    "        ax[i].plot(p.T[0, :seen_idxs[0]], p.T[1, :seen_idxs[0]], c='red5')\n",
    "        ax[i].plot(p.T[0, seen_idxs[0]:], p.T[1, seen_idxs[0]:], c='green5')\n",
    "    else:\n",
    "        ax[i].plot(p.T[0], p.T[1], c='red5')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f1a501-a2f6-4419-be7d-78dbaf638b39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "width = 4\n",
    "\n",
    "model_name = f'nav_poster_netstructure/nav_pproxim_width{width}batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "eps = evalu(model, obs_rms, n=25, env_kwargs=kwargs, data_callback=poster_data_callback, \n",
    "            with_activations=True, verbose=1)\n",
    "\n",
    "ep_pos = split_by_ep(np.vstack(eps['data']['pos']), np.vstack(eps['dones']))\n",
    "ep_angles = split_by_ep(np.vstack(eps['data']['angle']), np.vstack(eps['dones']))\n",
    "ep_poster_seen = split_by_ep(np.vstack(eps['data']['poster_seen']), np.vstack(eps['dones']))\n",
    "\n",
    "fig = pplt.figure()\n",
    "ax = fig.subplots(nrows=5, ncols=5, xlim=[0, 300], ylim=[0, 300])\n",
    "ax.format(xticks=[], yticks=[], \n",
    "          suptitle=f'Proximal Poster Example Trajectories: Width {width}',\n",
    "          rc_kw={'suptitle.size': 24})\n",
    "for i in range(len(ax)):\n",
    "    p = ep_pos[i]\n",
    "    a = ep_angles[i]\n",
    "    draw_character(p[0], a[0], ax=ax[i], size=20, color='y')\n",
    "    draw_box(ax=ax[i])\n",
    "    draw_box(corner=np.array([298, 125]), size=[2, 50], c='r', ax=ax[i])\n",
    "\n",
    "    seen_idxs = np.argwhere(ep_poster_seen[i].squeeze()).squeeze()\n",
    "    if not seen_idxs.shape == () and len(seen_idxs) > 0:\n",
    "        ax[i].plot(p.T[0, :seen_idxs[0]], p.T[1, :seen_idxs[0]], c='red5')\n",
    "        ax[i].plot(p.T[0, seen_idxs[0]:], p.T[1, seen_idxs[0]:], c='green5')\n",
    "    else:\n",
    "        ax[i].plot(p.T[0], p.T[1], c='red5')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da92a56-c916-44cd-b6fe-b9e4415da197",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "width = 8\n",
    "\n",
    "model_name = f'nav_poster_netstructure/nav_pproxim_width{width}batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "eps = evalu(model, obs_rms, n=25, env_kwargs=kwargs, data_callback=poster_data_callback, \n",
    "            with_activations=True, verbose=1)\n",
    "\n",
    "ep_pos = split_by_ep(np.vstack(eps['data']['pos']), np.vstack(eps['dones']))\n",
    "ep_angles = split_by_ep(np.vstack(eps['data']['angle']), np.vstack(eps['dones']))\n",
    "ep_poster_seen = split_by_ep(np.vstack(eps['data']['poster_seen']), np.vstack(eps['dones']))\n",
    "\n",
    "fig = pplt.figure()\n",
    "ax = fig.subplots(nrows=5, ncols=5, xlim=[0, 300], ylim=[0, 300])\n",
    "ax.format(xticks=[], yticks=[], \n",
    "          suptitle=f'Proximal Poster Example Trajectories: Width {width}',\n",
    "          rc_kw={'suptitle.size': 24})\n",
    "for i in range(len(ax)):\n",
    "    p = ep_pos[i]\n",
    "    a = ep_angles[i]\n",
    "    draw_character(p[0], a[0], ax=ax[i], size=20, color='y')\n",
    "    draw_box(ax=ax[i])\n",
    "    draw_box(corner=np.array([298, 125]), size=[2, 50], c='r', ax=ax[i])\n",
    "\n",
    "    seen_idxs = np.argwhere(ep_poster_seen[i].squeeze()).squeeze()\n",
    "    if not seen_idxs.shape == () and len(seen_idxs) > 0:\n",
    "        ax[i].plot(p.T[0, :seen_idxs[0]], p.T[1, :seen_idxs[0]], c='red5')\n",
    "        ax[i].plot(p.T[0, seen_idxs[0]:], p.T[1, seen_idxs[0]:], c='green5')\n",
    "    else:\n",
    "        ax[i].plot(p.T[0], p.T[1], c='red5')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b76ea1d-ff86-4e3f-b415-1422639813e5",
   "metadata": {},
   "source": [
    "## Pdistal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126c196a-3375-4b5e-b987-09a66f5944a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "width = 8\n",
    "\n",
    "model_name = f'nav_poster_netstructure/nav_pdistal_width{width}batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "eps = evalu(model, obs_rms, n=15, env_kwargs=kwargs, data_callback=poster_data_callback, \n",
    "            with_activations=True, verbose=1)\n",
    "\n",
    "ep_pos = split_by_ep(np.vstack(eps['data']['pos']), np.vstack(eps['dones']))\n",
    "ep_angles = split_by_ep(np.vstack(eps['data']['angle']), np.vstack(eps['dones']))\n",
    "ep_poster_seen = split_by_ep(np.vstack(eps['data']['poster_seen']), np.vstack(eps['dones']))\n",
    "\n",
    "fig = pplt.figure()\n",
    "ax = fig.subplots(nrows=3, ncols=5, xlim=[0, 300], ylim=[0, 300])\n",
    "ax.format(xticks=[], yticks=[], \n",
    "          suptitle=f'Distal Poster Example Trajectories: Width {width}',\n",
    "          rc_kw={'suptitle.size': 24})\n",
    "for i in range(len(ax)):\n",
    "    p = ep_pos[i]\n",
    "    a = ep_angles[i]\n",
    "    draw_character(p[0], a[0], ax=ax[i], size=20, color='y')\n",
    "    draw_box(ax=ax[i])\n",
    "    # draw_box(corner=np.array([298, 125]), size=[2, 50], c='r', ax=ax[i])\n",
    "    draw_box(corner=np.array([125, 298]), size=[50, 2], c='r', ax=ax[i])\n",
    "\n",
    "    draw_box()\n",
    "\n",
    "    seen_idxs = np.argwhere(ep_poster_seen[i].squeeze()).squeeze()\n",
    "    if not seen_idxs.shape == () and len(seen_idxs) > 0:\n",
    "        ax[i].plot(p.T[0, :seen_idxs[0]], p.T[1, :seen_idxs[0]], c='red5')\n",
    "        ax[i].plot(p.T[0, seen_idxs[0]:], p.T[1, seen_idxs[0]:], c='green5')\n",
    "    else:\n",
    "        ax[i].plot(p.T[0], p.T[1], c='red5')\n",
    "    \n",
    "fig.savefig(save + '6_1_pdistal_width8_trajectories.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449c8f14-cc96-4d12-b17d-db770dceba3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "width = 4\n",
    "\n",
    "model_name = f'nav_poster_netstructure/nav_pdistal_width{width}batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "eps = evalu(model, obs_rms, n=15, env_kwargs=kwargs, data_callback=poster_data_callback, \n",
    "            with_activations=True, verbose=1)\n",
    "\n",
    "ep_pos = split_by_ep(np.vstack(eps['data']['pos']), np.vstack(eps['dones']))\n",
    "ep_angles = split_by_ep(np.vstack(eps['data']['angle']), np.vstack(eps['dones']))\n",
    "ep_poster_seen = split_by_ep(np.vstack(eps['data']['poster_seen']), np.vstack(eps['dones']))\n",
    "\n",
    "fig = pplt.figure()\n",
    "ax = fig.subplots(nrows=3, ncols=5, xlim=[0, 300], ylim=[0, 300])\n",
    "ax.format(xticks=[], yticks=[], \n",
    "          suptitle=f'Proximal Poster Example Trajectories: Width {width}',\n",
    "          rc_kw={'suptitle.size': 24})\n",
    "for i in range(len(ax)):\n",
    "    p = ep_pos[i]\n",
    "    a = ep_angles[i]\n",
    "    draw_character(p[0], a[0], ax=ax[i], size=20, color='y')\n",
    "    draw_box(ax=ax[i])\n",
    "    # draw_box(corner=np.array([298, 125]), size=[2, 50], c='r', ax=ax[i])\n",
    "    draw_box(corner=np.array([125, 298]), size=[50, 2], c='r', ax=ax[i])\n",
    "\n",
    "    draw_box()\n",
    "\n",
    "    seen_idxs = np.argwhere(ep_poster_seen[i].squeeze()).squeeze()\n",
    "    if not seen_idxs.shape == () and len(seen_idxs) > 0:\n",
    "        ax[i].plot(p.T[0, :seen_idxs[0]], p.T[1, :seen_idxs[0]], c='red5')\n",
    "        ax[i].plot(p.T[0, seen_idxs[0]:], p.T[1, seen_idxs[0]:], c='green5')\n",
    "    else:\n",
    "        ax[i].plot(p.T[0], p.T[1], c='red5')\n",
    "    \n",
    "fig.savefig(save + '6_1_pdistal_width4_trajectories.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b1ae64-b43e-4d18-80f0-c16ab3ebe443",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "width = 2\n",
    "\n",
    "model_name = f'nav_poster_netstructure/nav_pdistal_width{width}batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "eps = evalu(model, obs_rms, n=15, env_kwargs=kwargs, data_callback=poster_data_callback, \n",
    "            with_activations=True, verbose=1)\n",
    "\n",
    "ep_pos = split_by_ep(np.vstack(eps['data']['pos']), np.vstack(eps['dones']))\n",
    "ep_angles = split_by_ep(np.vstack(eps['data']['angle']), np.vstack(eps['dones']))\n",
    "ep_poster_seen = split_by_ep(np.vstack(eps['data']['poster_seen']), np.vstack(eps['dones']))\n",
    "\n",
    "fig = pplt.figure()\n",
    "ax = fig.subplots(nrows=3, ncols=5, xlim=[0, 300], ylim=[0, 300])\n",
    "ax.format(xticks=[], yticks=[], \n",
    "          suptitle=f'Distal Poster Example Trajectories: Width {width}',\n",
    "          rc_kw={'suptitle.size': 24})\n",
    "for i in range(len(ax)):\n",
    "    p = ep_pos[i]\n",
    "    a = ep_angles[i]\n",
    "    draw_character(p[0], a[0], ax=ax[i], size=20, color='y')\n",
    "    draw_box(ax=ax[i])\n",
    "    # draw_box(corner=np.array([298, 125]), size=[2, 50], c='r', ax=ax[i])\n",
    "    draw_box(corner=np.array([125, 298]), size=[50, 2], c='r', ax=ax[i])\n",
    "\n",
    "    draw_box()\n",
    "\n",
    "    seen_idxs = np.argwhere(ep_poster_seen[i].squeeze()).squeeze()\n",
    "    if not seen_idxs.shape == () and len(seen_idxs) > 0:\n",
    "        ax[i].plot(p.T[0, :seen_idxs[0]], p.T[1, :seen_idxs[0]], c='red5')\n",
    "        ax[i].plot(p.T[0, seen_idxs[0]:], p.T[1, seen_idxs[0]:], c='green5')\n",
    "    else:\n",
    "        ax[i].plot(p.T[0], p.T[1], c='red5')\n",
    "    \n",
    "fig.savefig(save + '6_1_pdistal_width2_trajectories.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7681cae3-49e0-46cf-8843-e02c325542a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "width = 64\n",
    "\n",
    "model_name = f'nav_poster_netstructure/nav_pdistal_width{width}batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "eps = evalu(model, obs_rms, n=25, env_kwargs=kwargs, data_callback=poster_data_callback, \n",
    "            with_activations=True, verbose=1)\n",
    "\n",
    "ep_pos = split_by_ep(np.vstack(eps['data']['pos']), np.vstack(eps['dones']))\n",
    "ep_angles = split_by_ep(np.vstack(eps['data']['angle']), np.vstack(eps['dones']))\n",
    "ep_poster_seen = split_by_ep(np.vstack(eps['data']['poster_seen']), np.vstack(eps['dones']))\n",
    "\n",
    "fig = pplt.figure()\n",
    "ax = fig.subplots(nrows=5, ncols=5, xlim=[0, 300], ylim=[0, 300])\n",
    "ax.format(xticks=[], yticks=[], \n",
    "          suptitle=f'Distal Poster Example Trajectories: Width {width}',\n",
    "          rc_kw={'suptitle.size': 24})\n",
    "for i in range(len(ax)):\n",
    "    p = ep_pos[i]\n",
    "    a = ep_angles[i]\n",
    "    draw_character(p[0], a[0], ax=ax[i], size=20, color='y')\n",
    "    draw_box(ax=ax[i])\n",
    "    # draw_box(corner=np.array([298, 125]), size=[2, 50], c='r', ax=ax[i])\n",
    "    draw_box(corner=np.array([125, 298]), size=[50, 2], c='r', ax=ax[i])\n",
    "\n",
    "    draw_box()\n",
    "\n",
    "    seen_idxs = np.argwhere(ep_poster_seen[i].squeeze()).squeeze()\n",
    "    if not seen_idxs.shape == () and len(seen_idxs) > 0:\n",
    "        ax[i].plot(p.T[0, :seen_idxs[0]], p.T[1, :seen_idxs[0]], c='red5')\n",
    "        ax[i].plot(p.T[0, seen_idxs[0]:], p.T[1, seen_idxs[0]:], c='green5')\n",
    "    else:\n",
    "        ax[i].plot(p.T[0], p.T[1], c='red5')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dfde70-bc05-417f-aaa3-56842555cd77",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Restudying with pdistal, batch200\n",
    "\n",
    "Now including batch200 almost made the training TOO easy. We see complete success in trials now, even with networks as small as 4 nodes per layer, with 2 nodes having clearly distinct behavior (learning a circling policy). \n",
    "\n",
    "The 4 and 8 node networks have qualitatively equivalent behavior from the same initial conditions, indicating that they are consistently converging to the same policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4639235-5188-441c-a4c4-c6496d030a39",
   "metadata": {},
   "source": [
    "## UMAP reduction and averaged node activations\n",
    "\n",
    "Now that we have a model that appears to be trained to convergence and has consistent behavior, we expect the activations to be more regular and easier to decode.\n",
    "\n",
    "Splitting up the UMAP reduction of the shared RNN activation layer shows that there is some clear clustering separating activations representing a state of having seen the poster vs not having seen it. This indicates that the agent has clear differences in representation of the task state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0c04ee-26bd-45b1-8a15-691ba6eb9cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nav_poster_netstructure/nav_pdistal_width4batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "eps = evalu(model, obs_rms, env_kwargs=kwargs, n=500,\n",
    "      data_callback=poster_data_callback, with_activations=True)\n",
    "\n",
    "stacked = stack_activations(eps['activations'])\n",
    "actions = np.vstack(eps['actions']).squeeze()\n",
    "pos = np.vstack(eps['data']['pos'])\n",
    "\n",
    "# reducer = umap.UMAP()\n",
    "# reduced = reducer.fit_transform(stacked['shared_activations'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7718d249-d02e-4e5a-ba8c-f8fbb026e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [\n",
    "    [0, 0, 1, 1, 0, 0],\n",
    "    [0, 2, 2, 3, 3, 0],\n",
    "    [4, 4, 5, 5, 6, 6]\n",
    "]\n",
    "fig, ax = pplt.subplots(array)\n",
    "ax.format(\n",
    "    suptitle='UMAP Reduction for Activations on Width 4 Distal Poster Agent',\n",
    "    title=['Full UMAP', 'Poster Seen', 'Poster Not Seen', 'Action 0 (CW Rotation)', 'Action 1 (Forward)', 'Action 2 (CCW Rotation)'],\n",
    "    xlim=[-12, 20],\n",
    "    ylim=[-11, 16],\n",
    "    xlabel='UMAP Dimension 1',\n",
    "    ylabel='UMAP Dimension 2',\n",
    ")\n",
    "ax[0].scatter(reduced.T[0], reduced.T[1], s=2, alpha=0.2)\n",
    "pts = reduced[np.array(eps['data']['poster_seen'])]\n",
    "ax[1].scatter(pts.T[0], pts.T[1], s=2, alpha=0.2)\n",
    "pts = reduced[~np.array(eps['data']['poster_seen'])]\n",
    "ax[2].scatter(pts.T[0], pts.T[1], s=2, alpha=0.2)\n",
    "\n",
    "for i in range(3):\n",
    "    pts = reduced[actions == i]\n",
    "    ax[i+3].scatter(pts.T[0], pts.T[1], s=2, alpha=0.2)\n",
    "\n",
    "fig.savefig(save + '7_umap_pdistal_width4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7177c38-df6b-41f8-a7b8-0d89ec295bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "activations = stacked['shared_activations'][0].T\n",
    "fig, ax = pplt.subplots(nrows=2, ncols=2)\n",
    "for i in range(4):\n",
    "    ax[i].hist(activations[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6975621a-b2f7-4492-824d-ede9122f00d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "activations = stacked['actor_activations'][0].T\n",
    "fig, ax = pplt.subplots(nrows=2, ncols=2)\n",
    "for i in range(4):\n",
    "    ax[i].hist(activations[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be79dc-179d-43fa-b7a4-a58053108ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [\n",
    "    [0, 1, 1, 0],\n",
    "    [2, 2, 3, 3],\n",
    "    [4, 4, 5, 5]\n",
    "]\n",
    "\n",
    "fig, ax = pplt.subplots(array)\n",
    "ax.format(title=['Trajectories'] + [f'Node {n}' for n in range(1, 5)])\n",
    "ax[0].scatter(pos.T[0], pos.T[1], s=2, alpha=0.2)\n",
    "for i in range(4):\n",
    "    ax[1 + i].scatter(pos.T[0], pos.T[1], c=stacked['shared_activations'][0, :, i],\n",
    "                 alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c637fc53-d849-47ae-af3c-b4f10ca2dd0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dones = eps['dones']\n",
    "\n",
    "activ = stacked['shared_activations'][0, :, :]\n",
    "ep_activ = split_by_ep(activ, dones)\n",
    "ep_pos = split_by_ep(pos, dones)\n",
    "\n",
    "prune_first = 10\n",
    "pruned_ep_activ = [a[prune_first:] for a in ep_activ]\n",
    "pruned_activ = torch.vstack(pruned_ep_activ)\n",
    "pruned_ep_pos = [p[prune_first:] for p in ep_pos]\n",
    "pruned_pos = np.vstack(pruned_ep_pos)\n",
    "\n",
    "array = [\n",
    "    [0, 1, 1, 0],\n",
    "    [2, 2, 3, 3],\n",
    "    [4, 4, 5, 5]\n",
    "]\n",
    "\n",
    "fig, ax = pplt.subplots(array)\n",
    "ax.format(title=['Trajectories'] + [f'Node {n}' for n in range(1, 5)])\n",
    "ax[0].scatter(pos.T[0], pos.T[1], s=2, alpha=0.2)\n",
    "for i in range(4):\n",
    "    ax[1 + i].scatter(pruned_pos.T[0], pruned_pos.T[1], c=pruned_activ[:, i],\n",
    "                 alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7eef9c-25bd-4cb1-a43b-5bb8bc60eb4d",
   "metadata": {},
   "source": [
    "#### Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00146d28-4fae-4a83-bb05-41332f6395d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = pplt.subplots(ncols=3, nrows=4)\n",
    "ax.format(toplabels=['Clipped Heatmap', 'Heatmap', 'Scatter'])\n",
    "\n",
    "for i in range(4):\n",
    "    m = ax[i, 2].scatter(pos.T[0], pos.T[1], c=stacked['shared_activations'][0, :, i], alpha=0.2)\n",
    "    ax[i, 2].colorbar(m)\n",
    "    \n",
    "    a = np.clip(stacked['shared_activations'][0, :, i].numpy(), 0, 1)\n",
    "    # heatmap, _, _ = np.histogram2d(pos.T[0], pos.T[1], weights=a, bins=30)\n",
    "    heatmap = gaussian_smooth(pos, a)\n",
    "    ax[i, 0].imshow(heatmap, extent=(0, 300, 0, 300), cmap='div', vmin=-1, vmax=1)\n",
    "\n",
    "    a = stacked['shared_activations'][0, :, i].numpy()\n",
    "    # heatmap, _, _ = np.histogram2d(pos.T[0], pos.T[1], weights=a, bins=30)\n",
    "    heatmap = gaussian_smooth(pos, a)\n",
    "    ax[i, 1].imshow(heatmap, extent=(0, 300, 0, 300), cmap='div', vmin=-1, vmax=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a079d-4425-4c06-951d-a16213ae246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = pplt.subplots(ncols=3, nrows=4)\n",
    "ax.format(toplabels=['Clipped Heatmap', 'Heatmap', 'Scatter'])\n",
    "\n",
    "for i in range(4):\n",
    "    m = ax[i, 2].scatter(pos.T[0], pos.T[1], c=stacked['shared_activations'][0, :, i], alpha=0.2)\n",
    "    ax[i, 2].colorbar(m)\n",
    "    \n",
    "    a = np.clip(stacked['shared_activations'][0, :, i].numpy(), 0, 1)\n",
    "    # heatmap, _, _ = np.histogram2d(pos.T[0], pos.T[1], weights=a, bins=30)\n",
    "    heatmap = gaussian_smooth(pos, a, sigma=7)\n",
    "    ax[i, 0].imshow(heatmap, extent=(0, 300, 0, 300), cmap='div', vmin=-1, vmax=1)\n",
    "\n",
    "    a = stacked['shared_activations'][0, :, i].numpy()\n",
    "    # heatmap, _, _ = np.histogram2d(pos.T[0], pos.T[1], weights=a, bins=30)\n",
    "    heatmap = gaussian_smooth(pos, a, sigma=7)\n",
    "    ax[i, 1].imshow(heatmap, extent=(0, 300, 0, 300), cmap='div', vmin=-1, vmax=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747cf808-3a47-44ba-a3f0-9e56abfcf192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_smooth(pos, y, extent=(5, 295), num_grid=30, sigma=10):\n",
    "    # a = stacked['shared_activations'][0, :, 0].numpy()\n",
    "    y = np.array(y)\n",
    "    \n",
    "    grid = np.linspace(extent[0], extent[1], num_grid)\n",
    "    xs, ys[::-1] = np.meshgrid(grid, grid)\n",
    "    smoothed = np.zeros(xs.shape)\n",
    "    for i in range(num_grid):\n",
    "        for j in range(num_grid):\n",
    "            p = np.array([xs[i, j], ys[i, j]])\n",
    "            dists = np.sqrt(np.sum((pos - p)**2, axis=1))\n",
    "            g = np.exp(-dists**2 / (2*sigma**2))\n",
    "\n",
    "            smoothed[i, j] = np.sum(a[g > 0.1] * g[g > 0.1]) / np.sum(g[g > 0.1])\n",
    "    return smoothed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab5959f-2965-49ff-9878-5f8647b30e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = pplt.subplots(nrows=2, ncols=3)\n",
    "sigmas = [2, 5, 10, 20, 40, 80]\n",
    "\n",
    "ax.format(title=[f'\\sigma = {sigma}' for sigma in sigmas])\n",
    "for i, sigma in enumerate(sigmas):    \n",
    "    smoothed = gaussian_smooth(pos, stacked['shared_activations'][0, :, 0], sigma=sigma)\n",
    "    ax[i].imshow(smoothed, cmap='div', extent=(0, 300, 0, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7098df99-69d5-4142-a5b8-5ff7f4dcb94b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21414595-a8d5-4b40-a936-4a7a042fb562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a0188a-518c-4db4-96f3-42f2746f26e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(nrows=2, ncols=2)\n",
    "for i in range(4):\n",
    "    ax[i].scatter(pos.T[0], pos.T[1], c=stacked['actor_activations'][1, :, i],\n",
    "                 alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f469e757-e24b-44e8-a4d3-bc5cb8fb7089",
   "metadata": {},
   "source": [
    "### Same for 16 width networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11306b1-3373-4026-8736-ccdd3e761c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nav_poster_netstructure/nav_pdistal_width16batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "eps = evalu(model, obs_rms, env_kwargs=kwargs, n=500,\n",
    "      data_callback=poster_data_callback, with_activations=True)\n",
    "\n",
    "stacked = stack_activations(eps['activations'])\n",
    "actions = np.vstack(eps['actions']).squeeze()\n",
    "pos = np.vstack(eps['data']['pos'])\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "reduced = reducer.fit_transform(stacked['shared_activations'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193b1844-696f-4fa2-b022-70c7418f7d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(pos.T[0], pos.T[1], s=2, alpha=0.2)\n",
    "\n",
    "array = [\n",
    "    [0, 0, 0, 1, 1, 0, 0, 0],\n",
    "]\n",
    "for i in range(4):\n",
    "    a = []\n",
    "    for j in range(1, 5):\n",
    "        a += [1+j+i*4, 1+j+i*4]\n",
    "    array.append(a)\n",
    "\n",
    "# fig, ax = pplt.subplots(nrows=2, ncols=2)\n",
    "# for i in range(4):\n",
    "#     ax[i].scatter(pos.T[0], pos.T[1], c=stacked['shared_activations'][0, :, i],\n",
    "#                  alpha=0.1)\n",
    "fig, ax = pplt.subplots(array)\n",
    "ax[0].scatter(pos.T[0], pos.T[1], s=2, alpha=0.2)\n",
    "for i in range(16):\n",
    "    ax[i+1].scatter(pos.T[0], pos.T[1], c=stacked['shared_activations'][0, :, i],\n",
    "                 alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb23b2e8-1f98-4fc4-bf7c-8bdcf35f6d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "array = [\n",
    "    [0, 0, 1, 1, 0, 0],\n",
    "    [0, 2, 2, 3, 3, 0],\n",
    "    [4, 4, 5, 5, 6, 6]\n",
    "]\n",
    "fig, ax = pplt.subplots(array)\n",
    "ax.format(\n",
    "    suptitle='UMAP Reduction for Activations on Width 4 Distal Poster Agent',\n",
    "    title=['Full UMAP', 'Poster Seen', 'Poster Not Seen', 'Action 0 (CW Rotation)', 'Action 1 (Forward)', 'Action 2 (CCW Rotation)'],\n",
    "    xlim=[-12, 20],\n",
    "    ylim=[-11, 16],\n",
    "    xlabel='UMAP Dimension 1',\n",
    "    ylabel='UMAP Dimension 2',\n",
    ")\n",
    "ax[0].scatter(reduced.T[0], reduced.T[1], s=2, alpha=0.2)\n",
    "pts = reduced[np.array(eps['data']['poster_seen'])]\n",
    "ax[1].scatter(pts.T[0], pts.T[1], s=2, alpha=0.2)\n",
    "pts = reduced[~np.array(eps['data']['poster_seen'])]\n",
    "ax[2].scatter(pts.T[0], pts.T[1], s=2, alpha=0.2)\n",
    "\n",
    "for i in range(3):\n",
    "    pts = reduced[actions == i]\n",
    "    ax[i+3].scatter(pts.T[0], pts.T[1], s=2, alpha=0.2)\n",
    "\n",
    "# fig.savefig(save + '7_umap_pdistal_width4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa51b378-ad02-4238-a891-87ab85821237",
   "metadata": {},
   "source": [
    "### 2 width network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcaa09c-0ad6-48da-800d-360249486535",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nav_poster_netstructure/nav_pdistal_width2batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "eps = evalu(model, obs_rms, env_kwargs=kwargs, n=500,\n",
    "      data_callback=poster_data_callback, with_activations=True)\n",
    "\n",
    "stacked = stack_activations(eps['activations'])\n",
    "actions = np.vstack(eps['actions']).squeeze()\n",
    "pos = np.vstack(eps['data']['pos'])\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "reduced = reducer.fit_transform(stacked['shared_activations'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7b641c-f559-4bbb-b7b0-73c8bc60f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(pos.T[0], pos.T[1], s=2, alpha=0.2)\n",
    "\n",
    "array = [\n",
    "    [0, 1, 1, 0],\n",
    "    [2, 2, 3, 3]\n",
    "]\n",
    "\n",
    "fig, ax = pplt.subplots(array)\n",
    "ax[0].scatter(pos.T[0], pos.T[1], s=2, alpha=0.2)\n",
    "for i in range(2):\n",
    "    ax[i+1].scatter(pos.T[0], pos.T[1], c=stacked['shared_activations'][0, :, i],\n",
    "                 alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d8b4f1-c388-4660-b482-c2fe0046492e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "array = [\n",
    "    [0, 0, 1, 1, 0, 0],\n",
    "    [0, 2, 2, 3, 3, 0],\n",
    "    [4, 4, 5, 5, 6, 6]\n",
    "]\n",
    "fig, ax = pplt.subplots(array)\n",
    "ax.format(\n",
    "    suptitle='UMAP Reduction for Activations on Width 4 Distal Poster Agent',\n",
    "    title=['Full UMAP', 'Poster Seen', 'Poster Not Seen', 'Action 0 (CW Rotation)', 'Action 1 (Forward)', 'Action 2 (CCW Rotation)'],\n",
    "    xlim=[-12, 20],\n",
    "    ylim=[-11, 16],\n",
    "    xlabel='UMAP Dimension 1',\n",
    "    ylabel='UMAP Dimension 2',\n",
    ")\n",
    "ax[0].scatter(reduced.T[0], reduced.T[1], s=2, alpha=0.2)\n",
    "pts = reduced[np.array(eps['data']['poster_seen'])]\n",
    "ax[1].scatter(pts.T[0], pts.T[1], s=2, alpha=0.2)\n",
    "pts = reduced[~np.array(eps['data']['poster_seen'])]\n",
    "ax[2].scatter(pts.T[0], pts.T[1], s=2, alpha=0.2)\n",
    "\n",
    "for i in range(3):\n",
    "    pts = reduced[actions == i]\n",
    "    ax[i+3].scatter(pts.T[0], pts.T[1], s=2, alpha=0.2)\n",
    "\n",
    "# fig.savefig(save + '7_umap_pdistal_width4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e93734-285c-4591-9462-d537f6c29309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "array = [\n",
    "    [0, 0, 1, 1, 0, 0],\n",
    "    [0, 2, 2, 3, 3, 0],\n",
    "    [4, 4, 5, 5, 6, 6]\n",
    "]\n",
    "fig, ax = pplt.subplots(array)\n",
    "ax.format(\n",
    "    suptitle='2D Activations on Width 2 Distal Poster Agent',\n",
    "    title=['Full Activations', 'Poster Seen', 'Poster Not Seen', 'Action 0 (CW Rotation)', 'Action 1 (Forward)', 'Action 2 (CCW Rotation)'],\n",
    "    # xlim=[-12, 20],\n",
    "    # ylim=[-11, 16],\n",
    "    xlabel='UMAP Dimension 1',\n",
    "    ylabel='UMAP Dimension 2',\n",
    ")\n",
    "reduced = stacked['shared_activations'][0]\n",
    "ax[0].scatter(reduced.T[0], reduced.T[1], s=2, alpha=0.2)\n",
    "pts = reduced[np.array(eps['data']['poster_seen'])]\n",
    "ax[1].scatter(pts.T[0], pts.T[1], s=2, alpha=0.2)\n",
    "pts = reduced[~np.array(eps['data']['poster_seen'])]\n",
    "ax[2].scatter(pts.T[0], pts.T[1], s=2, alpha=0.2)\n",
    "\n",
    "for i in range(3):\n",
    "    pts = reduced[actions == i]\n",
    "    ax[i+3].scatter(pts.T[0], pts.T[1], s=2, alpha=0.2)\n",
    "\n",
    "# fig.savefig(save + '7_umap_pdistal_width4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab4693a-cf67-4e49-a6b3-7dee4ca67873",
   "metadata": {},
   "source": [
    "**Individual Activation Patterns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f953f1-e9ab-4420-9493-4d49afde9ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "activations = stacked['shared_activations'][0]\n",
    "rnn_hxs_inputs = []\n",
    "pts = reduced\n",
    "\n",
    "fig, ax = pplt.subplots()\n",
    "ax.scatter(reduced.T[0], reduced.T[1], s=2, alpha=0.2)\n",
    "\n",
    "idxs = np.random.choice(np.arange(reduced.shape[0]), 5)\n",
    "pts = pts[idxs]\n",
    "\n",
    "activation_pts = activations[idxs]\n",
    "ax.scatter(pts.T[0], pts.T[1])\n",
    "\n",
    "rnn_hxs_inputs.append(activation_pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5686aa54-8aca-4d26-a57d-10e3b900f926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make('NavEnv-v0', **kwargs)\n",
    "vis_walls, vis_wall_refs = env.vis_walls, env.vis_wall_refs\n",
    "\n",
    "dones = torch.ones((1, 1))\n",
    "\n",
    "num_nodes = 2\n",
    "num_states = 5\n",
    "states = rnn_hxs_inputs\n",
    "\n",
    "grid = np.linspace(5, 295, 20)\n",
    "grid_pos = []\n",
    "for x in grid:\n",
    "    for y in grid:\n",
    "        grid_pos.append(np.array([x, y]))\n",
    "angles = [np.pi/2, 0., -np.pi/2]\n",
    "\n",
    "wspace1 = [0]*(num_nodes-1)\n",
    "wspace = wspace1 + [10] + wspace1 + [10] + wspace1\n",
    "    \n",
    "fig, ax = pplt.subplots(nrows=num_states, ncols=num_nodes*3,\n",
    "         wspace=wspace)\n",
    "\n",
    "ax.format(xlim=[0, 300], ylim=[0, 300],\n",
    "         toplabels=[f'Node {n}' for n in range(1, num_nodes+1)]*3,\n",
    "         leftlabels=[f'State {n}' for n in range(1, num_states+1)])\n",
    "\n",
    "for n in range(3):\n",
    "    for i in tqdm(range(num_states)):\n",
    "        #i: rnn_hxs state input\n",
    "        angle = angles[n]\n",
    "        rnn_hxs = rnn_hxs_inputs[0][i].view(1, -1)\n",
    "        grid_activations = []\n",
    "\n",
    "        for pos in grid_pos:\n",
    "            env.character.pos = pos\n",
    "            env.character.angle = angle\n",
    "            env.character.update_rays(vis_walls, vis_wall_refs)\n",
    "            obs = torch.tensor(env.get_observation(), dtype=torch.float32).view(1, -1)\n",
    "            with torch.no_grad():\n",
    "                out = model.base(obs, rnn_hxs, dones, deterministic=True, with_activations=True)\n",
    "            grid_activations.append(out['activations'])\n",
    "\n",
    "        grid_stacked = stack_activations(grid_activations)\n",
    "\n",
    "\n",
    "        grid_pos = np.array(grid_pos)\n",
    "        # grid_pos = np.vstack([[[-5, -5],[-5,-5]], grid_pos])\n",
    "        for j in range(num_nodes):\n",
    "            # activ = np.append(grid_stacked['shared_activations'][0,:,j].numpy(), [-0.5, 0.5])\n",
    "            activ = grid_stacked['shared_activations'][0,:,j]\n",
    "            ax[i, j+num_nodes*n].scatter(grid_pos.T[0], grid_pos.T[1], \n",
    "                          c=activ, cmap='div')\n",
    "\n",
    "\n",
    "fig.savefig(save + '7_1_2_width2_node_activations.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb819d3f-b3bb-41b7-b80a-a935cbd19bbe",
   "metadata": {},
   "source": [
    "## See how affected activations are to condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da77e518-99ab-474d-8d4d-1149a0a4cc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "selections = [\n",
    "    np.array(eps['data']['poster_seen']),\n",
    "    ~np.array(eps['data']['poster_seen']),\n",
    "    actions == 0,\n",
    "    actions == 1,\n",
    "    actions == 2\n",
    "]\n",
    "labels = ['Poster Seen', 'Poster Not Seen', \n",
    "          'Action 0 (CW Rotation)', 'Action 1 (Forward)', \n",
    "          'Action 2 (CCW Rotation)']\n",
    "\n",
    "activations = stacked['shared_activations'][0]\n",
    "rnn_hxs_inputs = []\n",
    "\n",
    "\n",
    "fig, ax = pplt.subplots()\n",
    "ax.scatter(reduced.T[0], reduced.T[1], s=2, alpha=0.2)\n",
    "for i, selection in enumerate(selections):\n",
    "    pts = reduced[selections[i]]\n",
    "    idxs = np.random.choice(np.arange(pts.shape[0]), 5)\n",
    "    pts = pts[idxs]\n",
    "    \n",
    "    activation_pts = activations[selections[i]][idxs]\n",
    "    ax.scatter(pts.T[0], pts.T[1], label=labels[i])\n",
    "    \n",
    "    rnn_hxs_inputs.append(activation_pts)\n",
    "    \n",
    "ax.legend(loc='r', ncols=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f81a9e6-8810-4447-8000-9e5eb88609a9",
   "metadata": {},
   "source": [
    "This plot below shows 2 blocks of 4x4 graphs. Each 4x4 graph represents the 4 nodes (columns) and 4 different randomly chosen states from the \"agent has seen poster\" collection of states. The left block shows observations where the agent is facing right, and the right block shows observations where the agent is facing up.\n",
    "\n",
    "Main points\n",
    "* Looking at the left 4x4 block, there is variability in the 2nd and 4th node activations for different input rnn states.\n",
    "    * The variability of the two are able to change independently\n",
    "    * The 4th node seems to encode some notion of distance from the wall\n",
    "* Looking at the right block, the triangular sections of activation indicate that a given node activates when certain vision lines intersect the poster\n",
    "    * Looking at node 1, the node activates strongly when the poster is in the right vision lines\n",
    "    * On the other hand, the left vision lines seem to have an inhibitory effect\n",
    "    * It looks like in the first and fourth hidden states given, the node is activated for the whole map, but that this activation is also influenced by the vision lines in the same way as mentioned above\n",
    "    * Each other node seems to also have some sort of preferential activation with the poster in view. The preferences are also reflected in the left 4x4 block.\n",
    "    * The 4th node is the only one which seems to have state dependent poster activation. Onceagain this is reflected in the left block\n",
    "* Given the sensitivity seen to poster-in-view and distance to wall, it may in fact make more sense to visualize the dependence of activations on vision line inputs\n",
    "    * **We may also think about performing some sort of perturbation of the input observations and see how the nodes respond (!!)**\n",
    "* This is currently still a static view of how nodes respond, but do not take into account dynamics of the RNN state. These dynamics themselves are likely also an important part of the representaation. How do we consider these, and consider them in the context of passing down representation ability to later layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0f34e5-33dd-494c-ac78-d14af2035ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_hxs_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb279c5-e9f8-468d-95b7-ee153659bd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data\n",
    "num_states = 5\n",
    "num_nodes = 4\n",
    "\n",
    "env = gym.make('NavEnv-v0', **kwargs)\n",
    "vis_walls, vis_wall_refs = env.vis_walls, env.vis_wall_refs\n",
    "\n",
    "\n",
    "input_idxs = [0, 1]\n",
    "input_labels = ['Poster Seen', 'Poster Not Seen']\n",
    "dones = torch.ones((1, 1))\n",
    "\n",
    "grid = np.linspace(5, 295, 20)\n",
    "grid_pos = []\n",
    "for x in grid:\n",
    "    for y in grid:\n",
    "        grid_pos.append(np.array([x, y]))\n",
    "grid_pos = np.array(grid_pos)\n",
    "angles = [np.pi/2, -np.pi/2]\n",
    "\n",
    "grid_stacked_activations = {}\n",
    "for label in input_labels:\n",
    "    grid_stacked_activations[label] = {}\n",
    "    for angle in angles:\n",
    "        grid_stacked_activations[label][angle] = []\n",
    "\n",
    "for m, idx in enumerate(input_idxs):\n",
    "    label = input_labels[m]\n",
    "    for n, angle in enumerate(angles): \n",
    "        for i in tqdm(range(num_states)):\n",
    "            rnn_hxs = rnn_hxs_inputs[m][i].view(1, -1)\n",
    "            grid_activations = []\n",
    "\n",
    "            for pos in grid_pos:\n",
    "                env.character.pos = pos\n",
    "                env.character.angle = angle\n",
    "                env.character.update_rays(vis_walls, vis_wall_refs)\n",
    "                obs = torch.tensor(env.get_observation(), dtype=torch.float32).view(1, -1)\n",
    "                with torch.no_grad():\n",
    "                    out = model.base(obs, rnn_hxs, dones, deterministic=True, with_activations=True)\n",
    "                grid_activations.append(out['activations'])\n",
    "\n",
    "            grid_stacked = stack_activations(grid_activations)\n",
    "            grid_stacked_activations[label][angle].append(grid_stacked)\n",
    "\n",
    "            \n",
    "\n",
    "# # Get min and max for each node across states and angles\n",
    "color_lims = {angle: [] for angle in angles}\n",
    "for n, angle in enumerate(angles):\n",
    "    for j in range(num_nodes):\n",
    "        cmin = 1.\n",
    "        cmax = -1.\n",
    "        for m, label in enumerate(input_labels):\n",
    "            activ = grid_stacked_activations[label][angle]\n",
    "            for i in range(num_states):\n",
    "                #Find max and min activations for each node\n",
    "                cmin = min(activ[i]['shared_activations'][0, :, j].min(), cmin)\n",
    "                cmax = max(activ[i]['shared_activations'][0, :, j].max(), cmax)\n",
    "        color_lims[angle].append([cmin.item(), cmax.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af227a26-2476-4844-b017-1f094d0ba7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_lims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa7fba-2386-4470-9aa3-a1502bf08a27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make('NavEnv-v0', **kwargs)\n",
    "vis_walls, vis_wall_refs = env.vis_walls, env.vis_wall_refs\n",
    "\n",
    "dones = torch.ones((1, 1))\n",
    "\n",
    "grid = np.linspace(5, 295, 20)\n",
    "grid_pos = []\n",
    "for x in grid:\n",
    "    for y in grid:\n",
    "        grid_pos.append(np.array([x, y]))\n",
    "angles = [np.pi/2, 0, -np.pi/2]\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=4, ncols=12)\n",
    "# ax.format(toplabels=[f'Node {n}' for n in range(1, 5)],\n",
    "#           leftlabels=[])\n",
    "ax.format(wspace=(0, 0, 0, 10, 0, 0, 0, 10, 0, 0, 0))\n",
    "\n",
    "for n in range(3):\n",
    "    for i in tqdm(range(4)):\n",
    "        #i: rnn_hxs state input\n",
    "        angle = angles[n]\n",
    "        rnn_hxs = rnn_hxs_inputs[0][i].view(1, -1)\n",
    "        grid_activations = []\n",
    "\n",
    "        for pos in grid_pos:\n",
    "            env.character.pos = pos\n",
    "            env.character.angle = angle\n",
    "            env.character.update_rays(vis_walls, vis_wall_refs)\n",
    "            obs = torch.tensor(env.get_observation(), dtype=torch.float32).view(1, -1)\n",
    "            with torch.no_grad():\n",
    "                out = model.base(obs, rnn_hxs, dones, deterministic=True, with_activations=True)\n",
    "            grid_activations.append(out['activations'])\n",
    "\n",
    "        grid_stacked = stack_activations(grid_activations)\n",
    "\n",
    "\n",
    "        grid_pos = np.array(grid_pos)\n",
    "        for j in range(4):\n",
    "            ax[i, j+4*n].scatter(grid_pos.T[0], grid_pos.T[1], \n",
    "                          c=grid_stacked['shared_activations'][0, :, j],\n",
    "                          cmap='div')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62caea47-4901-4852-8059-901783d1b82e",
   "metadata": {},
   "source": [
    "**Poster seen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc13ae-b8ab-4bac-bb99-bdcd1066ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'Poster Seen'\n",
    "\n",
    "wspace1 = [0] * (num_nodes-1)\n",
    "wspace = wspace1 + [10] + wspace1\n",
    "fig, ax = pplt.subplots(nrows=num_states, ncols=num_nodes*2,\n",
    "                        wspace=wspace)\n",
    "ax.format(xlim=[0, 300], ylim=[0, 300],\n",
    "         toplabels=[f'Node {n}' for n in range(1, num_nodes+1)]*2,\n",
    "         leftlabels=[f'State {n}' for n in range(1, num_states+1)])\n",
    "\n",
    "for n, angle in enumerate(angles):\n",
    "    activ = grid_stacked_activations[label][angle]\n",
    "\n",
    "    for i in range(num_states):\n",
    "        for j in range(num_nodes):\n",
    "            activ = grid_stacked_activations[label][angle][i]['shared_activations'][0, :, j]\n",
    "            p = np.vstack([grid_pos, [[1, 1], [1, 1]]])\n",
    "            clim = color_lims[angle][j]\n",
    "            activ = np.append(activ, clim)\n",
    "            ax[i, j+4*n].scatter(p.T[0], p.T[1], c=activ, cmap='div')\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c4782a-e993-4ded-be5c-ae1a3883813f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label = 'Poster Not Seen'\n",
    "\n",
    "wspace1 = [0] * (num_nodes-1)\n",
    "wspace = wspace1 + [10] + wspace1\n",
    "fig, ax = pplt.subplots(nrows=num_states, ncols=num_nodes*2,\n",
    "                        wspace=wspace)\n",
    "ax.format(xlim=[0, 300], ylim=[0, 300],\n",
    "         toplabels=[f'Node {n}' for n in range(1, num_nodes+1)]*2,\n",
    "         leftlabels=[f'State {n}' for n in range(1, num_states+1)])\n",
    "\n",
    "for n, angle in enumerate(angles):\n",
    "    activ = grid_stacked_activations[label][angle]\n",
    "\n",
    "    for i in range(num_states):\n",
    "        for j in range(num_nodes):\n",
    "            activ = grid_stacked_activations[label][angle][i]['shared_activations'][0, :, j]\n",
    "            p = np.vstack([grid_pos, [[1, 1], [1, 1]]])\n",
    "            clim = color_lims[angle][j]\n",
    "            activ = np.append(activ, clim)\n",
    "            ax[i, j+4*n].scatter(p.T[0], p.T[1], c=activ, cmap='div')\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6ff309-af79-402f-aa35-c36694f19f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make('NavEnv-v0', **kwargs)\n",
    "vis_walls, vis_wall_refs = env.vis_walls, env.vis_wall_refs\n",
    "\n",
    "dones = torch.ones((1, 1))\n",
    "\n",
    "grid = np.linspace(5, 295, 20)\n",
    "grid_pos = []\n",
    "for x in grid:\n",
    "    for y in grid:\n",
    "        grid_pos.append(np.array([x, y]))\n",
    "angles = [np.pi/2, -np.pi/2]\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=4, ncols=8,\n",
    "         wspace=(0, 0, 0, 10, 0, 0, 0))\n",
    "# ax.format(toplabels=[f'Node {n}' for n in range(1, 5)],\n",
    "#           leftlabels=[])\n",
    "\n",
    "ax.format(xlim=[0, 300], ylim=[0, 300],\n",
    "         toplabels=[f'Node {n}' for n in range(1, 5)]*2,\n",
    "         leftlabels=[f'State {n}' for n in range(1, 5)])\n",
    "\n",
    "for n in range(2):\n",
    "    for i in tqdm(range(4)):\n",
    "        #i: rnn_hxs state input\n",
    "        angle = angles[n]\n",
    "        rnn_hxs = rnn_hxs_inputs[0][i].view(1, -1)\n",
    "        grid_activations = []\n",
    "\n",
    "        for pos in grid_pos:\n",
    "            env.character.pos = pos\n",
    "            env.character.angle = angle\n",
    "            env.character.update_rays(vis_walls, vis_wall_refs)\n",
    "            obs = torch.tensor(env.get_observation(), dtype=torch.float32).view(1, -1)\n",
    "            with torch.no_grad():\n",
    "                out = model.base(obs, rnn_hxs, dones, deterministic=True, with_activations=True)\n",
    "            grid_activations.append(out['activations'])\n",
    "\n",
    "        grid_stacked = stack_activations(grid_activations)\n",
    "\n",
    "\n",
    "        grid_pos = np.array(grid_pos)\n",
    "        # grid_pos = np.vstack([[[-5, -5],[-5,-5]], grid_pos])\n",
    "        for j in range(4):\n",
    "            # activ = np.append(grid_stacked['shared_activations'][0,:,j].numpy(), [-0.5, 0.5])\n",
    "            activ = grid_stacked['shared_activations'][0,:,j]\n",
    "            ax[i, j+4*n].scatter(grid_pos.T[0], grid_pos.T[1], \n",
    "                          c=activ, cmap='div')\n",
    "\n",
    "\n",
    "fig.savefig(save + '7_2_example_node_activations_poster_seen.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6ecd36-0e0a-4d5c-9556-2a1fb5789d40",
   "metadata": {},
   "source": [
    "**Poster not seen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd0ea47-1695-4a7c-9ea9-a74eff99c4d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make('NavEnv-v0', **kwargs)\n",
    "vis_walls, vis_wall_refs = env.vis_walls, env.vis_wall_refs\n",
    "\n",
    "dones = torch.ones((1, 1))\n",
    "\n",
    "grid = np.linspace(5, 295, 20)\n",
    "grid_pos = []\n",
    "for x in grid:\n",
    "    for y in grid:\n",
    "        grid_pos.append(np.array([x, y]))\n",
    "angles = [np.pi/2, -np.pi/2]\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=4, ncols=8,\n",
    "         wspace=(0, 0, 0, 10, 0, 0, 0,))\n",
    "# ax.format(toplabels=[f'Node {n}' for n in range(1, 5)],\n",
    "#           leftlabels=[])\n",
    "\n",
    "ax.format(xlim=[0, 300], ylim=[0, 300],\n",
    "         toplabels=[f'Node {n}' for n in range(1, 5)]*2,\n",
    "         leftlabels=[f'State {n}' for n in range(1, 5)])\n",
    "\n",
    "for n in range(2):\n",
    "    for i in tqdm(range(4)):\n",
    "        #i: rnn_hxs state input\n",
    "        angle = angles[n]\n",
    "        rnn_hxs = rnn_hxs_inputs[1][i].view(1, -1)\n",
    "        grid_activations = []\n",
    "\n",
    "        for pos in grid_pos:\n",
    "            env.character.pos = pos\n",
    "            env.character.angle = angle\n",
    "            env.character.update_rays(vis_walls, vis_wall_refs)\n",
    "            obs = torch.tensor(env.get_observation(), dtype=torch.float32).view(1, -1)\n",
    "            with torch.no_grad():\n",
    "                out = model.base(obs, rnn_hxs, dones, deterministic=True, with_activations=True)\n",
    "            grid_activations.append(out['activations'])\n",
    "\n",
    "        grid_stacked = stack_activations(grid_activations)\n",
    "\n",
    "\n",
    "        grid_pos = np.array(grid_pos)\n",
    "        # grid_pos = np.vstack([[[-5, -5],[-5,-5]], grid_pos])\n",
    "        for j in range(4):\n",
    "            # activ = np.append(grid_stacked['shared_activations'][0,:,j].numpy(), [-0.5, 0.5])\n",
    "            activ = grid_stacked['shared_activations'][0,:,j]\n",
    "            ax[i, j+4*n].scatter(grid_pos.T[0], grid_pos.T[1], \n",
    "                          c=activ, cmap='div')\n",
    "\n",
    "\n",
    "fig.savefig(save + '7_2_example_node_activations_poster_NOTseen.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b349a0b3-5afc-4a97-b1f0-91f362e86489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55c08dc9-003f-4cb6-ac31-28d374f7da7e",
   "metadata": {},
   "source": [
    "**Due to scaling of colorscale being inconsistent, we will try to plot these activations using max and min of activation scale**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec59d2d-4676-4ecc-b376-3beae5425302",
   "metadata": {},
   "source": [
    "**Actor activations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea390698-8686-4a4c-98ab-048510637b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make('NavEnv-v0', **kwargs)\n",
    "vis_walls, vis_wall_refs = env.vis_walls, env.vis_wall_refs\n",
    "\n",
    "dones = torch.ones((1, 1))\n",
    "\n",
    "grid = np.linspace(5, 295, 20)\n",
    "grid_pos = []\n",
    "for x in grid:\n",
    "    for y in grid:\n",
    "        grid_pos.append(np.array([x, y]))\n",
    "angles = [0, np.pi/2]\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=4, ncols=8)\n",
    "\n",
    "for n in range(2):\n",
    "    for i in tqdm(range(4)):\n",
    "        #i: rnn_hxs state input\n",
    "        angle = angles[n]\n",
    "        rnn_hxs = rnn_hxs_inputs[0][i].view(1, -1)\n",
    "        grid_activations = []\n",
    "\n",
    "        for pos in grid_pos:\n",
    "            env.character.pos = pos\n",
    "            env.character.angle = angle\n",
    "            env.character.update_rays(vis_walls, vis_wall_refs)\n",
    "            obs = torch.tensor(env.get_observation(), dtype=torch.float32).view(1, -1)\n",
    "            with torch.no_grad():\n",
    "                out = model.base(obs, rnn_hxs, dones, deterministic=True, with_activations=True)\n",
    "            grid_activations.append(out['activations'])\n",
    "\n",
    "        grid_stacked = stack_activations(grid_activations)\n",
    "\n",
    "\n",
    "        grid_pos = np.array(grid_pos)\n",
    "        for j in range(4):\n",
    "            ax[i, j+4*n].scatter(grid_pos.T[0], grid_pos.T[1], \n",
    "                          c=grid_stacked['actor_activations'][0, :, j],\n",
    "                          cmap='div')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcf7921-0d30-4f16-a40b-683d4a1dc637",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make('NavEnv-v0', **kwargs)\n",
    "vis_walls, vis_wall_refs = env.vis_walls, env.vis_wall_refs\n",
    "\n",
    "dones = torch.ones((1, 1))\n",
    "\n",
    "grid = np.linspace(5, 295, 20)\n",
    "grid_pos = []\n",
    "for x in grid:\n",
    "    for y in grid:\n",
    "        grid_pos.append(np.array([x, y]))\n",
    "angles = [0, np.pi/2]\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=4, ncols=8)\n",
    "\n",
    "for n in range(2):\n",
    "    for i in tqdm(range(4)):\n",
    "        #i: rnn_hxs state input\n",
    "        angle = angles[n]\n",
    "        rnn_hxs = rnn_hxs_inputs[0][i].view(1, -1)\n",
    "        grid_activations = []\n",
    "\n",
    "        for pos in grid_pos:\n",
    "            env.character.pos = pos\n",
    "            env.character.angle = angle\n",
    "            env.character.update_rays(vis_walls, vis_wall_refs)\n",
    "            obs = torch.tensor(env.get_observation(), dtype=torch.float32).view(1, -1)\n",
    "            with torch.no_grad():\n",
    "                out = model.base(obs, rnn_hxs, dones, deterministic=True, with_activations=True)\n",
    "            grid_activations.append(out['activations'])\n",
    "\n",
    "        grid_stacked = stack_activations(grid_activations)\n",
    "\n",
    "\n",
    "        grid_pos = np.array(grid_pos)\n",
    "        for j in range(4):\n",
    "            ax[i, j+4*n].scatter(grid_pos.T[0], grid_pos.T[1], \n",
    "                          c=grid_stacked['actor_activations'][1, :, j],\n",
    "                          cmap='div')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fc6084-c861-4b86-b3ca-3f304261d782",
   "metadata": {},
   "source": [
    "## Try to fix positive and negative values for activations and see affects on each node\n",
    "\n",
    "For the most part this seems to be able to elucidate the range of activations patterns for a given node (although the artificial RNN states used may not accurately represent any actual state reached by the network)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91e534b-8bc6-481e-8745-6ed98e6e1e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = np.pi/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c642e98e-85fa-420d-8a9e-5a0487a47d25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make('NavEnv-v0', **kwargs)\n",
    "vis_walls, vis_wall_refs = env.vis_walls, env.vis_wall_refs\n",
    "\n",
    "dones = torch.ones((1, 1))\n",
    "\n",
    "grid = np.linspace(5, 295, 20)\n",
    "grid_pos = []\n",
    "for x in grid:\n",
    "    for y in grid:\n",
    "        grid_pos.append(np.array([x, y]))\n",
    "\n",
    "plot_node_num = 0\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=4, ncols=4,\n",
    "                        hspace=(0, 2, 0),\n",
    "                        wspace=(0, 2, 0))\n",
    "ordering = [('+', '+'),  ('+', '-'), ('-', '+'), ('-', '-')]\n",
    "ordering_mults = [(1, 1), (1, -1), (-1, 1), (-1, -1)]\n",
    "ax.format(toplabels=[f'Node 1 {order[0]}\\nNode 2 {order[1]}' for order in ordering],\n",
    "          leftlabels=[f'Node 3 {order[0]}\\nNode 4 {order[1]}' for order in ordering],\n",
    "          xlim=[0, 300], ylim=[0, 300])\n",
    "\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        mults12 = ordering_mults[j]\n",
    "        mults34 = ordering_mults[i]\n",
    "        rnn_hxs = torch.tensor([[0.5*mults12[0], 0.5*mults12[1],\n",
    "                                 0.5*mults34[0], 0.5*mults34[1]]])\n",
    "        \n",
    "        grid_activations = []\n",
    "\n",
    "        for pos in grid_pos:\n",
    "            env.character.pos = pos\n",
    "            env.character.angle = angle\n",
    "            env.character.update_rays(vis_walls, vis_wall_refs)\n",
    "            obs = torch.tensor(env.get_observation(), dtype=torch.float32).view(1, -1)\n",
    "            with torch.no_grad():\n",
    "                out = model.base(obs, rnn_hxs, dones, deterministic=True, with_activations=True)\n",
    "            grid_activations.append(out['activations'])\n",
    "\n",
    "        grid_stacked = stack_activations(grid_activations)\n",
    "        grid_pos = np.array(grid_pos)\n",
    "        plot_activations = grid_stacked['shared_activations'][0, :, plot_node_num]\n",
    "        \n",
    "        #add an arbitrary -1 and 1 point\n",
    "        grid_pos = np.vstack([grid_pos, [[-5,-5],[-5,-5]]])\n",
    "        plot_activations = torch.concat([grid_stacked['shared_activations'][0, :, 0], \n",
    "              torch.tensor([-1, 1])])\n",
    "        \n",
    "        \n",
    "        m = ax[i, j].scatter(grid_pos.T[0], grid_pos.T[1],\n",
    "                         c=plot_activations, cmap='div')\n",
    "\n",
    "fig.colorbar(m, 'r')\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ff7ac-e1a7-4fbd-adce-193e8ec50e6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make('NavEnv-v0', **kwargs)\n",
    "vis_walls, vis_wall_refs = env.vis_walls, env.vis_wall_refs\n",
    "\n",
    "dones = torch.ones((1, 1))\n",
    "\n",
    "grid = np.linspace(5, 295, 20)\n",
    "grid_pos = []\n",
    "for x in grid:\n",
    "    for y in grid:\n",
    "        grid_pos.append(np.array([x, y]))\n",
    "\n",
    "plot_node_num = 1\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=4, ncols=4,\n",
    "                        hspace=(0, 2, 0),\n",
    "                        wspace=(0, 2, 0))\n",
    "ordering = [('+', '+'),  ('+', '-'), ('-', '+'), ('-', '-')]\n",
    "ordering_mults = [(1, 1), (1, -1), (-1, 1), (-1, -1)]\n",
    "ax.format(toplabels=[f'Node 1 {order[0]}\\nNode 2 {order[1]}' for order in ordering],\n",
    "          leftlabels=[f'Node 3 {order[0]}\\nNode 4 {order[1]}' for order in ordering],\n",
    "          xlim=[0, 300], ylim=[0, 300])\n",
    "\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        mults12 = ordering_mults[j]\n",
    "        mults34 = ordering_mults[i]\n",
    "        rnn_hxs = torch.tensor([[0.5*mults12[0], 0.5*mults12[1],\n",
    "                                 0.5*mults34[0], 0.5*mults34[1]]])\n",
    "        # print(rnn_hxs)\n",
    "        grid_activations = []\n",
    "\n",
    "        for pos in grid_pos:\n",
    "            env.character.pos = pos\n",
    "            env.character.angle = angle\n",
    "            env.character.update_rays(vis_walls, vis_wall_refs)\n",
    "            obs = torch.tensor(env.get_observation(), dtype=torch.float32).view(1, -1)\n",
    "            with torch.no_grad():\n",
    "                out = model.base(obs, rnn_hxs, dones, deterministic=True, with_activations=True)\n",
    "            grid_activations.append(out['activations'])\n",
    "\n",
    "        grid_stacked = stack_activations(grid_activations)\n",
    "        grid_pos = np.array(grid_pos)\n",
    "        plot_activations = grid_stacked['shared_activations'][0, :, plot_node_num]\n",
    "        \n",
    "        #add an arbitrary -1 and 1 point\n",
    "        grid_pos = np.vstack([grid_pos, [[-5,-5],[-5,-5]]])\n",
    "        plot_activations = torch.concat([plot_activations, torch.tensor([-1, 1])])\n",
    "        \n",
    "        \n",
    "        m = ax[i, j].scatter(grid_pos.T[0], grid_pos.T[1],\n",
    "                         c=plot_activations, cmap='div')\n",
    "\n",
    "fig.colorbar(m, 'r')\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248865eb-d706-4b63-a210-24e2f757673b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make('NavEnv-v0', **kwargs)\n",
    "vis_walls, vis_wall_refs = env.vis_walls, env.vis_wall_refs\n",
    "\n",
    "dones = torch.ones((1, 1))\n",
    "\n",
    "grid = np.linspace(5, 295, 20)\n",
    "grid_pos = []\n",
    "for x in grid:\n",
    "    for y in grid:\n",
    "        grid_pos.append(np.array([x, y]))\n",
    "\n",
    "plot_node_num = 2\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=4, ncols=4,\n",
    "                        hspace=(0, 2, 0),\n",
    "                        wspace=(0, 2, 0))\n",
    "ordering = [('+', '+'),  ('+', '-'), ('-', '+'), ('-', '-')]\n",
    "ordering_mults = [(1, 1), (1, -1), (-1, 1), (-1, -1)]\n",
    "ax.format(toplabels=[f'Node 1 {order[0]}\\nNode 2 {order[1]}' for order in ordering],\n",
    "          leftlabels=[f'Node 3 {order[0]}\\nNode 4 {order[1]}' for order in ordering],\n",
    "          xlim=[0, 300], ylim=[0, 300])\n",
    "\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        mults12 = ordering_mults[j]\n",
    "        mults34 = ordering_mults[i]\n",
    "        rnn_hxs = torch.tensor([[0.5*mults12[0], 0.5*mults12[1],\n",
    "                                 0.5*mults34[0], 0.5*mults34[1]]])\n",
    "        # print(rnn_hxs)\n",
    "        grid_activations = []\n",
    "\n",
    "        for pos in grid_pos:\n",
    "            env.character.pos = pos\n",
    "            env.character.angle = angle\n",
    "            env.character.update_rays(vis_walls, vis_wall_refs)\n",
    "            obs = torch.tensor(env.get_observation(), dtype=torch.float32).view(1, -1)\n",
    "            with torch.no_grad():\n",
    "                out = model.base(obs, rnn_hxs, dones, deterministic=True, with_activations=True)\n",
    "            grid_activations.append(out['activations'])\n",
    "\n",
    "        grid_stacked = stack_activations(grid_activations)\n",
    "        grid_pos = np.array(grid_pos)\n",
    "        plot_activations = grid_stacked['shared_activations'][0, :, plot_node_num]\n",
    "        \n",
    "        #add an arbitrary -1 and 1 point\n",
    "        grid_pos = np.vstack([grid_pos, [[-5,-5],[-5,-5]]])\n",
    "        plot_activations = torch.concat([plot_activations, torch.tensor([-1, 1])])\n",
    "        \n",
    "        \n",
    "        m = ax[i, j].scatter(grid_pos.T[0], grid_pos.T[1],\n",
    "                         c=plot_activations, cmap='div')\n",
    "\n",
    "fig.colorbar(m, 'r')\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46beca50-95ee-4926-a595-d77ad2a8c108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make('NavEnv-v0', **kwargs)\n",
    "vis_walls, vis_wall_refs = env.vis_walls, env.vis_wall_refs\n",
    "\n",
    "dones = torch.ones((1, 1))\n",
    "\n",
    "grid = np.linspace(5, 295, 20)\n",
    "grid_pos = []\n",
    "for x in grid:\n",
    "    for y in grid:\n",
    "        grid_pos.append(np.array([x, y]))\n",
    "\n",
    "plot_node_num = 3\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=4, ncols=4,\n",
    "                        hspace=(0, 2, 0),\n",
    "                        wspace=(0, 2, 0))\n",
    "ordering = [('+', '+'),  ('+', '-'), ('-', '+'), ('-', '-')]\n",
    "ordering_mults = [(1, 1), (1, -1), (-1, 1), (-1, -1)]\n",
    "ax.format(toplabels=[f'Node 1 {order[0]}\\nNode 2 {order[1]}' for order in ordering],\n",
    "          leftlabels=[f'Node 3 {order[0]}\\nNode 4 {order[1]}' for order in ordering],\n",
    "          xlim=[0, 300], ylim=[0, 300])\n",
    "\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        mults12 = ordering_mults[j]\n",
    "        mults34 = ordering_mults[i]\n",
    "        rnn_hxs = torch.tensor([[0.5*mults12[0], 0.5*mults12[1],\n",
    "                                 0.5*mults34[0], 0.5*mults34[1]]])\n",
    "        # print(rnn_hxs)\n",
    "        grid_activations = []\n",
    "\n",
    "        for pos in grid_pos:\n",
    "            env.character.pos = pos\n",
    "            env.character.angle = angle\n",
    "            env.character.update_rays(vis_walls, vis_wall_refs)\n",
    "            obs = torch.tensor(env.get_observation(), dtype=torch.float32).view(1, -1)\n",
    "            with torch.no_grad():\n",
    "                out = model.base(obs, rnn_hxs, dones, deterministic=True, with_activations=True)\n",
    "            grid_activations.append(out['activations'])\n",
    "\n",
    "        grid_stacked = stack_activations(grid_activations)\n",
    "        grid_pos = np.array(grid_pos)\n",
    "        plot_activations = grid_stacked['shared_activations'][0, :, plot_node_num]\n",
    "        \n",
    "        #add an arbitrary -1 and 1 point\n",
    "        grid_pos = np.vstack([grid_pos, [[-5,-5],[-5,-5]]])\n",
    "        plot_activations = torch.concat([plot_activations, torch.tensor([-1, 1])])\n",
    "        \n",
    "        \n",
    "        m = ax[i, j].scatter(grid_pos.T[0], grid_pos.T[1],\n",
    "                         c=plot_activations, cmap='div')\n",
    "\n",
    "fig.colorbar(m, 'r')\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da48c1c-30c0-487e-a0fe-33dab4ad4c84",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generating trajectories and watching rnn dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a3c71e-a260-4c7f-b18f-513c4246f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nav_poster_netstructure/nav_pdistal_width4batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "eps = evalu(model, obs_rms, env_kwargs=kwargs, n=20,\n",
    "      data_callback=poster_data_callback, with_activations=True)\n",
    "\n",
    "\n",
    "stacked = stack_activations(eps['activations'])\n",
    "activations = stacked['critic_activations'][1, :, :]\n",
    "ep_activations = split_by_ep(activations, eps['dones'])\n",
    "ep_pos = [np.vstack(epos) for epos in \\\n",
    "          split_by_ep(eps['data']['pos'], eps['dones'])]\n",
    "ep_actions = [torch.squeeze(torch.vstack(acts)) for acts in \\\n",
    "              split_by_ep(eps['actions'], eps['dones'])]\n",
    "ep_angles = split_by_ep(eps['data']['angle'], eps['dones'])\n",
    "ep_poster_seen = split_by_ep(eps['data']['poster_seen'], eps['dones'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140d3db7-18f3-4e65-b5d0-6f967c45036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_num = 6\n",
    "\n",
    "fig, ax = pplt.subplots(ncols=2, share=False)\n",
    "rnn_diffs = torch.sqrt(torch.sum(torch.diff(ep_activations[ep_num], dim=0) ** 2, dim=1))\n",
    "# ax[0].plot(rnn_diffs)\n",
    "ps = np.argmax(ep_poster_seen[ep_num])\n",
    "ax[0].plot(np.arange(len(rnn_diffs[:ps])), rnn_diffs[:ps], c='red3')\n",
    "ax[0].plot(np.arange(len(rnn_diffs[ps-1:]))+ps-1, rnn_diffs[ps-1:], c='green3')\n",
    "\n",
    "acts_types = [0, 1, 2]\n",
    "markers = ['>', '^','<']\n",
    "acts = ep_actions[ep_num][:-1].numpy()\n",
    "idxs = np.arange(len(acts))\n",
    "\n",
    "\n",
    "for i, act in enumerate(acts_types):\n",
    "    ix = idxs[acts == act]\n",
    "    ax[0].scatter(ix, np.zeros(len(ix)), marker=markers[i], s=10)\n",
    "    \n",
    "ax[1].format(xlim=[0, 300], ylim=[0, 300])\n",
    "draw_box(ax=ax[1])\n",
    "\n",
    "p = ep_pos[ep_num][:ps].T\n",
    "ax[1].plot(p[0], p[1], c='red3', lw=3)\n",
    "p = ep_pos[ep_num][ps:-1].T\n",
    "ax[1].plot(p[0], p[1], c='green3', lw=3)\n",
    "\n",
    "draw_character(ep_pos[ep_num][0], ep_angles[ep_num][0], ax=ax[1])\n",
    "# ax[1].parametric(p[0], p[1], rnn_diffs)\n",
    "\n",
    "ax[0].format(ylabel='Change in RNN activations per timestep', xlabel='timestep')\n",
    "ax.format(suptitle='Width 4 Trained Agent Trajectory and RNN Activation Changes', \n",
    "          title=['Activation Changes in RNN Layer', 'Trajectory of Agent'])\n",
    "fig.savefig(save + '8_4width_traj_and_rnn_changes.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d338a4ec-2409-4075-8ece-b7cd509b0e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_num = 6\n",
    "\n",
    "array = [\n",
    "    [1, 0],\n",
    "    [2, 4,],\n",
    "    [3, 0,]\n",
    "]\n",
    "\n",
    "fig, ax = pplt.subplots(array, share=False)\n",
    "rnn_diffs = torch.sqrt(torch.sum(torch.diff(ep_activations[ep_num], dim=0) ** 2, dim=1))\n",
    "# ax[0].plot(rnn_diffs)\n",
    "\n",
    "#Position and Heading\n",
    "ax[0].plot(ep_pos[ep_num].T[0], label='X Pos')\n",
    "ax[0].plot(ep_pos[ep_num].T[1], label='Y Pos')\n",
    "ax[0].legend(loc='lr')\n",
    "ax[0].format(xminorlocator=10, xgridminor=True)\n",
    "\n",
    "#Individual Activations Plot\n",
    "for i in range(4):\n",
    "    ax[1].plot(ep_activations[ep_num][:, i], label=f'Node {i+1}')\n",
    "ax[1].legend(loc='b')\n",
    "ax[1].format(xminorlocator=10, xgridminor=True)\n",
    "#Activation Distances Plot\n",
    "ps = np.argmax(ep_poster_seen[ep_num])\n",
    "ax[2].plot(np.arange(len(rnn_diffs[:ps])), rnn_diffs[:ps], c='red3')\n",
    "ax[2].plot(np.arange(len(rnn_diffs[ps-1:]))+ps-1, rnn_diffs[ps-1:], c='green3')\n",
    "\n",
    "acts_types = [0, 1, 2]\n",
    "markers = ['>', '^','<']\n",
    "acts = ep_actions[ep_num][:-1].numpy()\n",
    "idxs = np.arange(len(acts))\n",
    "\n",
    "\n",
    "for i, act in enumerate(acts_types):\n",
    "    ix = idxs[acts == act]\n",
    "    ax[2].scatter(ix, np.zeros(len(ix)), marker=markers[i], s=10)\n",
    "    \n",
    "#Trajectory plot\n",
    "ax[3].format(xlim=[0, 300], ylim=[0, 300])\n",
    "draw_box(ax=ax[3])\n",
    "\n",
    "p = ep_pos[ep_num][:ps].T\n",
    "ax[3].plot(p[0], p[1], c='red3', lw=3)\n",
    "p = ep_pos[ep_num][ps:-1].T\n",
    "ax[3].plot(p[0], p[1], c='green3', lw=3)\n",
    "marker_idxs = np.arange(ep_pos[ep_num].shape[0], step=10)\n",
    "markers = ep_pos[ep_num][marker_idxs]\n",
    "ax[3].scatter(markers.T[0], markers.T[1], marker='x', c=np.arange(len(markers)))\n",
    "\n",
    "draw_character(ep_pos[ep_num][0], ep_angles[ep_num][0], ax=ax[3])\n",
    "# ax[1].parametric(p[0], p[1], rnn_diffs)\n",
    "\n",
    "ax[2].format(ylabel='Change in RNN activations per timestep', xlabel='timestep')\n",
    "ax.format(suptitle='Width 4 Trained Agent Trajectory and RNN Activation Changes', \n",
    "          title=[\n",
    "              'Position and Angle',\n",
    "              'Individual Node Activations',\n",
    "              'Activation Changes in RNN Layer', \n",
    "              'Trajectory of Agent'],\n",
    "         rc_kw={'title.size': 14, 'suptitle.size': 12})\n",
    "fig.savefig(save + '8_4width_traj_and_activations.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7db63cf-3b0e-48be-bffb-95c9f7aa768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_num = 6\n",
    "\n",
    "fig, ax = pplt.subplots(ncols=2, share=False)\n",
    "rnn_diffs = torch.sqrt(torch.sum(torch.diff(ep_activations[ep_num], dim=0) ** 2, dim=1))\n",
    "# ax[0].plot(rnn_diffs)\n",
    "ps = np.argmax(ep_poster_seen[ep_num])\n",
    "ax[0].plot(np.arange(len(rnn_diffs[:ps])), rnn_diffs[:ps], c='red3')\n",
    "ax[0].plot(np.arange(len(rnn_diffs[ps-1:]))+ps-1, rnn_diffs[ps-1:], c='green3')\n",
    "\n",
    "acts_types = [0, 1, 2]\n",
    "markers = ['>', '^','<']\n",
    "acts = ep_actions[ep_num][:-1].numpy()\n",
    "idxs = np.arange(len(acts))\n",
    "\n",
    "\n",
    "for i, act in enumerate(acts_types):\n",
    "    ix = idxs[acts == act]\n",
    "    ax[0].scatter(ix, np.zeros(len(ix)), marker=markers[i], s=10)\n",
    "    \n",
    "ax[1].format(xlim=[0, 300], ylim=[0, 300])\n",
    "draw_box(ax=ax[1])\n",
    "\n",
    "p = ep_pos[ep_num][:ps].T\n",
    "ax[1].plot(p[0], p[1], c='red3', lw=3)\n",
    "p = ep_pos[ep_num][ps:-1].T\n",
    "ax[1].plot(p[0], p[1], c='green3', lw=3)\n",
    "\n",
    "draw_character(ep_pos[ep_num][0], ep_angles[ep_num][0], ax=ax[1])\n",
    "# ax[1].parametric(p[0], p[1], rnn_diffs)\n",
    "\n",
    "ax[0].format(ylabel='Change in RNN activations per timestep', xlabel='timestep')\n",
    "ax.format(suptitle='Width 4 Trained Agent Trajectory and RNN Activation Changes', \n",
    "          title=['Activation Changes in RNN Layer', 'Trajectory of Agent'])\n",
    "fig.savefig(save + '8_4width_traj_and_rnn_changes.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f44d804-62d8-48ff-8b95-ad58c90f1ff5",
   "metadata": {},
   "source": [
    "* Every 40 timesteps the agent is \"told\" which part (5x5 grid) of the pool to be in\n",
    "    * One-hot vector [0, 0, 0, 0,,... 1, 0]\n",
    "* Every timestep spent in that grid gives +1 reward\n",
    "* Poster in north wall\n",
    "* Agent always starts in the middle facing the poster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410681b1-1564-4e1f-b111-d0d664d907da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## General trajectories and distributions of hidden states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6535d30d-9b4e-46e0-a72c-6ebbb70af840",
   "metadata": {},
   "source": [
    "**4 width**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66967087-e9d9-422f-af20-9382d0c091de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_grid_points(points_per_side=20, start=5, end=295, skip_goal=True):\n",
    "    grid = np.linspace(start, end, points_per_side)\n",
    "    grid_points = []\n",
    "    goal_bounds = [[240, 260], [60, 80]]\n",
    "    for x in grid:\n",
    "        for y in grid:\n",
    "            if not (skip_goal and \n",
    "                goal_bounds[0][0] <= x <= goal_bounds[0][1] and \n",
    "                goal_bounds[1][0] <= y <= goal_bounds[1][1]):\n",
    "                grid_points.append([x, y])\n",
    "    \n",
    "    grid_points = np.vstack(grid_points)\n",
    "    return grid_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb5da49-59c8-4450-81cb-ebb0b4ee7c88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_points = make_grid_points()\n",
    "\n",
    "angles = [0., np.pi/2, np.pi, -np.pi/2]\n",
    "\n",
    "model_name = 'nav_poster_netstructure/nav_pdistal_width4batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "\n",
    "all_eps = []\n",
    "all_grid_points = []\n",
    "all_angles = []\n",
    "\n",
    "for angle in angles:\n",
    "    for point in grid_points:\n",
    "        kwargs2 = kwargs.copy()\n",
    "        kwargs2['fixed_reset'] = [point.copy(), angle]\n",
    "        \n",
    "        eps = evalu(model, obs_rms, n=1, env_kwargs=kwargs2, with_activations=True,\n",
    "              data_callback=poster_data_callback)\n",
    "        all_eps.append(eps)\n",
    "        all_grid_points.append(point)\n",
    "        all_angles.append(angle)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b23221-99b1-46be-8323-b7817bacd6be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "starting_pos = []\n",
    "for i in range(len(all_eps)):\n",
    "    starting_pos.append(all_eps[i]['data']['pos'][0])\n",
    "starting_pos = np.vstack(starting_pos)\n",
    "plt.scatter(starting_pos.T[0], starting_pos.T[1], s=3, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3350eb48-0b28-4120-837f-f2e7020156f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(nrows=2, ncols=2)\n",
    "ax.format(suptitle='Trajectories for 4 Width Agent',\n",
    "    title=[f'Starting Angle {angle:.2f}' for angle in angles],\n",
    "         xlim=[0, 300], ylim=[0, 300])\n",
    "for i, angle in enumerate(angles):\n",
    "    for j in range(len(grid_points)):\n",
    "        idx = j + i*len(grid_points)\n",
    "        ep = all_eps[idx]\n",
    "        ep_pos = np.vstack(ep['data']['pos'])\n",
    "        ep_angle = ep['data']['angle']\n",
    "        \n",
    "        ps = np.argmax(ep['data']['poster_seen'])\n",
    "        \n",
    "        draw_character(ep_pos[0], ep_angle[0], size=4, ax=ax[i])\n",
    "        # ax[i].plot(ep_pos.T[0], ep_pos.T[1], c='blue3', alpha=0.2)\n",
    "        ax[i].plot(ep_pos[:ps].T[0], ep_pos[:ps].T[1], c='red3', alpha=0.2)\n",
    "        ax[i].plot(ep_pos[ps:].T[0], ep_pos[ps:].T[1], c='green3', alpha=0.2)\n",
    "        \n",
    "fig.savefig(save + '8_1_4width_trajectories.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016ebb61-94a1-4628-af4c-95c5cc6e8610",
   "metadata": {},
   "source": [
    "**64 width**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b375eb5b-fa6d-4735-9afd-03f654822216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_points = make_grid_points()\n",
    "\n",
    "angles = [0., np.pi/2, np.pi, -np.pi/2]\n",
    "\n",
    "model_name = 'nav_poster_netstructure/nav_pdistal_width64batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "\n",
    "all_eps = []\n",
    "all_grid_points = []\n",
    "all_angles = []\n",
    "\n",
    "for angle in angles:\n",
    "    for point in grid_points:\n",
    "        kwargs2 = kwargs.copy()\n",
    "        kwargs2['fixed_reset'] = [point.copy(), angle]\n",
    "        \n",
    "        eps = evalu(model, obs_rms, n=1, env_kwargs=kwargs2, with_activations=True,\n",
    "              data_callback=poster_data_callback)\n",
    "        all_eps.append(eps)\n",
    "        all_grid_points.append(point)\n",
    "        all_angles.append(angle)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40503444-a536-4d9c-97dd-8ee28b1bbdbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "starting_pos = []\n",
    "for i in range(len(all_eps)):\n",
    "    starting_pos.append(all_eps[i]['data']['pos'][0])\n",
    "starting_pos = np.vstack(starting_pos)\n",
    "plt.scatter(starting_pos.T[0], starting_pos.T[1], s=3, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4940df14-1ccd-4824-8010-e56962c50610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(nrows=2, ncols=2)\n",
    "ax.format(suptitle='Trajectories for 64 Width Agent',\n",
    "    title=[f'Starting Angle {angle:.2f}' for angle in angles],\n",
    "         xlim=[0,300], ylim=[0,300])\n",
    "for i, angle in enumerate(angles):\n",
    "    for j in range(len(grid_points)):\n",
    "        idx = j + i*len(grid_points)\n",
    "        ep = all_eps[idx]\n",
    "        ep_pos = np.vstack(ep['data']['pos'])\n",
    "        ep_angle = ep['data']['angle']\n",
    "        \n",
    "        ps = np.argmax(ep['data']['poster_seen'])\n",
    "        \n",
    "        draw_character(ep_pos[0], ep_angle[0], size=4, ax=ax[i])\n",
    "        # ax[i].plot(ep_pos.T[0], ep_pos.T[1], c='blue3', alpha=0.2)\n",
    "        ax[i].plot(ep_pos[:ps].T[0], ep_pos[:ps].T[1], c='red3', alpha=0.2)\n",
    "        ax[i].plot(ep_pos[ps:].T[0], ep_pos[ps:].T[1], c='green3', alpha=0.2)\n",
    "        \n",
    "fig.savefig(save + '8_1_64width_trajectories.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e339b0a3-1149-462d-859f-e25004640b3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Looking for maximal observation activations\n",
    "\n",
    "This section was not very successful, hard to interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab9996f-7e19-4dd3-87bb-76b2e9a6b626",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Messy working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e122f9f-8a16-4a91-bdf2-ac5bbe0adaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nav_poster_netstructure/nav_pdistal_width4batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec50204-9db7-469a-bf38-d4ec036f9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env = quick_vec_env(obs_rms, kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00e193-7cd2-4e7e-8415-c95d20fc766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d6c111-4dbd-40c5-b593-cccb25c4f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('NavEnv-v0', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0786c5-e094-4eb3-9b81-5b6dceb35dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_obs = env.reset()\n",
    "\n",
    "base_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb4211-1a11-4d1f-88c8-3af9651f9b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_colors = [1/6, 4/6]\n",
    "obs_grid = np.linspace(0, 1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b69f43-f206-4ed3-9b6a-9e190b270a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rays = int(base_obs.shape[0]/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22425b87-3f48-4930-b1a0-2ae5fc146780",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    fake_obs = np.zeros(base_obs.shape)\n",
    "    fake_obs[:num_rays] = obs_colors[0]\n",
    "    fake_obs[num_rays:] = np.random.random(size=num_rays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20097c35-d44e-4317-9e6b-79ce0904b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect some random obs\n",
    "all_obs = []\n",
    "for i in range(1000):\n",
    "    all_obs.append(env.reset())\n",
    "all_obs = np.vstack(all_obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c66a5cb-ed1e-4707-9150-73061cad83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_obs = vec_env._obfilt(all_obs, update=False)\n",
    "# rms_obs = torch.tensor(rms_obs).view(1, rms_obs.shape[0], rms_obs.shape[1])\n",
    "# rnn_hxs = torch.zeros((1, rms_obs.shape[1], 64))\n",
    "# masks = torch.ones((1, rms_obs.shape[1], 1))\n",
    "\n",
    "rms_obs = torch.tensor(rms_obs, dtype=torch.float32).view(rms_obs.shape[0], rms_obs.shape[1])\n",
    "rnn_hxs = torch.zeros((rms_obs.shape[0], 4))\n",
    "masks = torch.ones((rms_obs.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f09847-09d4-473a-9be6-c7a0123e970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.base(rms_obs, rnn_hxs, masks, with_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb09c1-b419-4438-8b7e-6a3b58b7b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97be508-b6f9-42bf-b569-ffe16b1d4b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    res = model.base(rms_obs, rnn_hxs, masks, with_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ef7f1-d9c9-4f52-b866-3a11ac9a13e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_activations = torch.vstack(res['activations']['shared_activations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ead84-c3da-47fe-ad5b-f160b92aea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_poster_obs = all_obs[~(all_obs == 4/6).any(axis=1)]\n",
    "rms_no_poster_obs = vec_env._obfilt(no_poster_obs, update=False)\n",
    "\n",
    "rms_no_poster_obs = torch.tensor(rms_no_poster_obs, \n",
    "    dtype=torch.float32).view(rms_no_poster_obs.shape[0], \n",
    "                              rms_no_poster_obs.shape[1])\n",
    "rnn_hxs = torch.zeros((rms_no_poster_obs.shape[0], 4))\n",
    "masks = torch.ones((rms_no_poster_obs.shape[0], 1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    res = model.base(rms_no_poster_obs, rnn_hxs, masks, with_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daaf7e3-0a4b-4f42-9258-df8b43d3bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_activations = torch.vstack(res['activations']['shared_activations'])\n",
    "shared_activations.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7975a2c8-b9a7-464c-9fee-e6c105bde3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.abs(shared_activations).min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a13c3f-6cb6-46f4-b231-94d3edc2078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjustments = np.linspace(-0.2, 0.2, 5)\n",
    "test_obs = np.full((5, 24), obs)\n",
    "for i, adj in enumerate(adjustments):\n",
    "    test_obs[i, 12] = test_obs[i, 13] + adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61b35f5-d994-4253-84c8-7ba56dbeeef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_obs = vec_env._obfilt(test_obs)\n",
    "test_obs = torch.tensor(test_obs, dtype=torch.float32)\n",
    "\n",
    "rnn_hxs = torch.zeros(5, 4)\n",
    "masks = torch.ones(5, 1)\n",
    "with torch.no_grad():\n",
    "    res2 = model.base(test_obs, rnn_hxs, masks, with_activations=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7146e2-0c86-4dc5-b27c-6219102d5036",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Drawing pictures of maximally activating non-poster observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0653f3-996c-40e9-b2e5-0ac9fe4de294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_obs_to_colors(obs):\n",
    "    val_to_rgba = {\n",
    "        1/6: np.array([1., 0, 0, 1]),\n",
    "        4/6: np.array([1., 1, 0, 1])\n",
    "    }\n",
    "    \n",
    "    num_rays = int(len(obs)/2)\n",
    "    cs = []\n",
    "    \n",
    "    for i in range(num_rays):\n",
    "        c = val_to_rgba[obs[i]].copy()\n",
    "        dist = obs[i+num_rays]\n",
    "        # print(dist)\n",
    "        # print(c)\n",
    "        # c[:-1] = c[:-1]*dist\n",
    "        c[-1] = c[-1]*dist\n",
    "        cs.append(c)\n",
    "    \n",
    "    return cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6740a2-811c-4aa7-b103-5209351e2c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(nrows=2, ncols=4)\n",
    "ax.format(leftlabels=['Min Activation', 'Max Activation'],\n",
    "          toplabels=[f'Node {i}' for i in range(1, 5)])\n",
    "\n",
    "arg_idxs = shared_activations[:, 0].argsort()\n",
    "num_rays = 12\n",
    "\n",
    "for n in range(4):\n",
    "    arg_idxs = shared_activations[:, n].argsort()\n",
    "\n",
    "    for i in range(5):\n",
    "        obs = no_poster_obs[arg_idxs[i]]\n",
    "        c = map_obs_to_colors(obs)\n",
    "        ax[0, n].scatter(np.arange(num_rays), np.full(num_rays, i), c=c, marker='s', s=200)\n",
    "    for i in range(5):\n",
    "        obs = no_poster_obs[arg_idxs[-i]]\n",
    "        c = map_obs_to_colors(obs)\n",
    "        ax[1, n].scatter(np.arange(num_rays), np.full(num_rays, i), c=c, marker='s', s=200)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7c07ee-2eee-4752-b115-b7b68ff96f91",
   "metadata": {},
   "source": [
    "# Grid Loc Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc3b11f-ce7d-4581-a291-b5f7e4fe3e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nav_gridloc_width/nav_gridloc_width16batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "eps = evalu(model, obs_rms, env_kwargs=kwargs, n=500,\n",
    "            data_callback=poster_data_callback, with_activations=True, verbose=True)\n",
    "\n",
    "stacked = stack_activations(eps['activations'])\n",
    "actions = np.vstack(eps['actions']).squeeze()\n",
    "pos = np.vstack(eps['data']['pos'])\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "reduced = reducer.fit_transform(stacked['shared_activations'][0])\n",
    "\n",
    "plt.scatter(reduced.T[0], reduced.T[1], s=2, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e3399-3801-4b30-9a1d-10b4d04de9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(pos.T[0], pos.T[1], s=2, alpha=0.2)\n",
    "\n",
    "array = [\n",
    "    [0, 0, 0, 1, 1, 0, 0, 0],\n",
    "]\n",
    "for i in range(4):\n",
    "    a = []\n",
    "    for j in range(1, 5):\n",
    "        a += [1+j+i*4, 1+j+i*4]\n",
    "    array.append(a)\n",
    "\n",
    "fig, ax = pplt.subplots(array)\n",
    "ax.format(title=['Positions'] + [f'RNN Node {i} Activations' for i in range(1,17)],\n",
    "         xlim=[0, 300], ylim=[0, 300])\n",
    "\n",
    "\n",
    "ax[0].scatter(pos.T[0], pos.T[1], s=2, alpha=0.2)\n",
    "for i in range(16):\n",
    "    ax[i+1].scatter(pos.T[0], pos.T[1], c=stacked['shared_activations'][0, :, i],\n",
    "                 alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1851c916-867a-4522-b670-523eb6059490",
   "metadata": {},
   "source": [
    "# Playing with SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdfc884-f73b-409f-b46a-4035b95adb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nav_poster_netstructure/nav_pdistal_width64batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "\n",
    "param = list(model.base.actor1.parameters())[0]\n",
    "\n",
    "a = param.detach().numpy()\n",
    "\n",
    "singvals = np.linalg.svd(a)[1]\n",
    "print(singvals)\n",
    "for i in range(len(singvals)):\n",
    "    print(singvals[:i+1].sum() / singvals.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e38de3-6ccb-4823-bdbf-ad2933c444da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
