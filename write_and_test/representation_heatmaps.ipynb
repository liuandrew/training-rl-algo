{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0c2193-70d5-4f60-8a82-f505be5db40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "%run model_evaluation\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import proplot as pplt\n",
    "import umap\n",
    "\n",
    "# model, obs_rms, kwargs = load_model_and_env('nav_auxiliary_tasks/nav_aux_wall_1', 0)\n",
    "# env = gym.make('NavEnv-v0', **kwargs)\n",
    "\n",
    "save = 'plots/representation_learning/'\n",
    "\n",
    "%run representation_analysis\n",
    "%run model_evaluation\n",
    "\n",
    "\n",
    "def gaussian_smooth(pos, y, extent=(5, 295), num_grid=30, sigma=10,\n",
    "                    ret_hasval=False):\n",
    "    # a = stacked['shared_activations'][0, :, 0].numpy()\n",
    "    y = np.array(y)\n",
    "    \n",
    "    grid = np.linspace(extent[0], extent[1], num_grid)\n",
    "    xs, ys = np.meshgrid(grid, grid)\n",
    "    ys = ys[::-1]\n",
    "    smoothed = np.zeros(xs.shape)\n",
    "    hasval = np.zeros(xs.shape)\n",
    "    for i in range(num_grid):\n",
    "        for j in range(num_grid):\n",
    "            p = np.array([xs[i, j], ys[i, j]])\n",
    "            dists = np.sqrt(np.sum((pos - p)**2, axis=1))\n",
    "            g = np.exp(-dists**2 / (2*sigma**2))\n",
    "            \n",
    "            if len(g[g > 0.1]) < 1:\n",
    "                val = 0\n",
    "            else:\n",
    "                val = np.sum(y[g > 0.1] * g[g > 0.1]) / np.sum(g[g > 0.1])\n",
    "                hasval[i, j] = 1\n",
    "\n",
    "            smoothed[i, j] = val\n",
    "    if ret_hasval:\n",
    "        return smoothed, hasval\n",
    "    else:\n",
    "        return smoothed\n",
    "\n",
    "\n",
    "def clean_eps(eps, prune_first=5, activations_key='shared_activations',\n",
    "             activations_layer=0, clip=False,\n",
    "             save_inview=True, save_seen=True):\n",
    "    '''Clean up an eps data dictionary collected from evalu for heatmapping'''\n",
    "    dones = eps['dones'].copy()\n",
    "    pos = np.vstack(eps['data']['pos'])\n",
    "    stacked = stack_activations(eps['activations'])\n",
    "    angles = eps['data']['angle']\n",
    "    \n",
    "    activ = stacked[activations_key][activations_layer, :, :].numpy()\n",
    "    pinview = np.array(eps['data']['poster_in_view'])\n",
    "    pseen = np.array(eps['data']['poster_seen'])\n",
    "    \n",
    "    ep_activ = split_by_ep(activ, dones)\n",
    "    ep_pos = split_by_ep(pos, dones)\n",
    "    ep_pinview = split_by_ep(pinview, dones)\n",
    "    ep_angle = split_by_ep(angles, dones)\n",
    "    ep_pseen = split_by_ep(pseen, dones)\n",
    "    \n",
    "    if prune_first and prune_first > 0:\n",
    "        prune_first = 5\n",
    "        pruned_ep_activ = [a[prune_first:] for a in ep_activ]\n",
    "        pruned_activ = np.vstack(pruned_ep_activ)\n",
    "        pruned_ep_pos = [p[prune_first:] for p in ep_pos]\n",
    "        pruned_pos = np.vstack(pruned_ep_pos)\n",
    "        pruned_ep_pinview = [p[prune_first:] for p in ep_pinview]\n",
    "        pruned_pinview = np.concatenate(pruned_ep_pinview)\n",
    "        pruned_ep_angles = [p[prune_first:] for p in ep_angle]\n",
    "        pruned_angles = np.concatenate(pruned_ep_angles)\n",
    "        pruned_ep_pseen = [p[prune_first:] for p in ep_pseen]\n",
    "        pruned_pseen = np.concatenate(pruned_ep_pseen)\n",
    "        \n",
    "        pos = pruned_pos\n",
    "        activ = pruned_activ\n",
    "        pinview = pruned_pinview\n",
    "        angles = pruned_angles\n",
    "        pseen = pruned_pseen\n",
    "    \n",
    "    if clip:\n",
    "        activ = np.clip(activ, 0, 1)\n",
    "    \n",
    "    result_dict = {\n",
    "        'pos': pos,\n",
    "        'activ': activ,\n",
    "        'pinview': pinview,\n",
    "        'pseen': pseen,\n",
    "        'angles': angles,\n",
    "    }\n",
    "    \n",
    "    if save_inview:\n",
    "        result_dict.update({\n",
    "            'pos_inview': pos[pinview],\n",
    "            'pos_notinview': pos[~pinview],\n",
    "            'activ_inview': activ[pinview],\n",
    "            'activ_notinview': activ[~pinview],\n",
    "            'angles_inview': angles[pinview],\n",
    "            'angles_notinview': angles[~pinview],\n",
    "        })\n",
    "    if save_seen:\n",
    "        result_dict.update({'pos_seen': pos[pseen],\n",
    "        'pos_notseen': pos[~pseen],\n",
    "        'activ_seen': activ[pseen],\n",
    "        'activ_notseen': activ[~pseen],\n",
    "        'angles_seen': angles[pseen],\n",
    "        'angles_notseen': angles[~pseen],\n",
    "        })\n",
    "    \n",
    "    return result_dict\n",
    "    \n",
    "    \n",
    "def stack_all_ep(all_ep):\n",
    "    '''\n",
    "    When making a list of results from multiple evalu calls,\n",
    "    this function can be called to put the relevant data into a single dict to be\n",
    "    passed to clean_eps for processing\n",
    "    '''\n",
    "    dones = np.concatenate([ep['dones'] for ep in all_ep])\n",
    "    pos = np.vstack([ep['data']['pos'] for ep in all_ep])\n",
    "    angles = np.concatenate([ep['data']['angle'] for ep in all_ep])\n",
    "    pseen = np.concatenate([ep['data']['poster_seen'] for ep in all_ep])\n",
    "    pinview = np.concatenate([ep['data']['poster_in_view'] for ep in all_ep])\n",
    "    activations = []\n",
    "    for ep in all_ep:\n",
    "        activations += ep['activations']\n",
    "\n",
    "    eps = {\n",
    "        'dones': dones,\n",
    "        'activations': activations,\n",
    "        'data': {\n",
    "            'pos': pos,\n",
    "            'angle': angles,\n",
    "            'poster_seen': pseen,\n",
    "            'poster_in_view': pinview\n",
    "        }\n",
    "    }\n",
    "    return eps\n",
    "    \n",
    "\n",
    "    \n",
    "def split_by_angle(target, angles):\n",
    "    splits = {\n",
    "        0: [-np.pi/4, np.pi/4],\n",
    "        1: [np.pi/4, 3*np.pi/4],\n",
    "        3: [-3*np.pi/4, -np.pi/4],\n",
    "        2: None #this will use else statement otherwise bounds are annoying\n",
    "    }\n",
    "    all_trues = np.zeros(angles.shape) == 1\n",
    "    result = {}\n",
    "    \n",
    "    for s in [0, 1, 3]:\n",
    "        split = splits[s]\n",
    "        split_idxs = (split[0] <= angles) & (angles <= split[1])\n",
    "        all_trues = all_trues | split_idxs\n",
    "        \n",
    "        result[s] = target[split_idxs]\n",
    "    #finally, the ones that didn't fit into any of the other quadrants\n",
    "    result[2] = target[~all_trues]\n",
    "    \n",
    "    return result\n",
    "    \n",
    "    \n",
    "# def filter_all_ep_directness(all_ep, bound=0.9):\n",
    "    \n",
    "    \n",
    "def compute_directness(all_ep=None, ep=None):\n",
    "    '''\n",
    "    Compute the directness of paths taken either from an all_ep (split up\n",
    "    eps generated from appending evalu() calls) or from a single ep\n",
    "    '''\n",
    "    goal_loc = np.array([250, 70])\n",
    "\n",
    "    if all_ep is not None:\n",
    "        directnesses = []\n",
    "        for i in range(len(all_ep)):\n",
    "            p = np.vstack(all_ep[i]['data']['pos'])\n",
    "            d = p - goal_loc\n",
    "            d = np.sqrt(np.sum(d**2, axis=1))\n",
    "            dist_changes = np.diff(d)\n",
    "            directness = np.sum(dist_changes[:-1] < 0) / np.sum(dist_changes[:-1] != 0)\n",
    "            directnesses.append(directness)\n",
    "        return np.array(directnesses)\n",
    "    elif ep is not None:\n",
    "        p = np.vstack(ep['data']['pos'])\n",
    "        d = p - goal_loc\n",
    "        d = np.sqrt(np.sum(d**2, axis=1))\n",
    "        dist_changes = np.diff(d)\n",
    "        directness = np.sum(dist_changes[:-1] < 0) / np.sum(dist_changes[:-1] != 0)\n",
    "        return directness\n",
    "    else:\n",
    "        raise Exception('No proper parameters given')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17906adf-6a1a-4938-89da-dbc74db437c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Running Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e8d6b3-d40a-4445-9bb7-ffc60543521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nav_poster_netstructure/nav_pdistal_width4batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "eps = evalu(model, obs_rms, env_kwargs=kwargs, n=500,\n",
    "      data_callback=poster_data_callback, with_activations=True)\n",
    "\n",
    "stacked = stack_activations(eps['activations'])\n",
    "actions = np.vstack(eps['actions']).squeeze()\n",
    "pos = np.vstack(eps['data']['pos'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8b6250-522d-45f8-a5bf-82c090981d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = pplt.subplots(nrows=2, ncols=3)\n",
    "sigmas = [2, 5, 10, 20, 40, 80]\n",
    "\n",
    "ax.format(title=[f'\\sigma = {sigma}' for sigma in sigmas])\n",
    "for i, sigma in enumerate(sigmas):    \n",
    "    smoothed = gaussian_smooth(pos, stacked['shared_activations'][0, :, 0], sigma=sigma)\n",
    "    ax[i].imshow(smoothed, cmap='div', extent=(0, 300, 0, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183863ea-52e5-4af8-b90f-7b2cc6b34c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = pplt.subplots(ncols=3, nrows=4)\n",
    "ax.format(toplabels=['Clipped Heatmap', 'Heatmap', 'Scatter'])\n",
    "\n",
    "for i in range(4):\n",
    "    m = ax[i, 2].scatter(pos.T[0], pos.T[1], c=stacked['shared_activations'][0, :, i], alpha=0.2)\n",
    "    ax[i, 2].colorbar(m)\n",
    "    \n",
    "    a = np.clip(stacked['shared_activations'][0, :, i].numpy(), 0, 1)\n",
    "    # heatmap, _, _ = np.histogram2d(pos.T[0], pos.T[1], weights=a, bins=30)\n",
    "    heatmap = gaussian_smooth(pos, a)\n",
    "    ax[i, 0].imshow(heatmap, extent=(0, 300, 0, 300), cmap='div', vmin=-1, vmax=1)\n",
    "\n",
    "    a = stacked['shared_activations'][0, :, i].numpy()\n",
    "    # heatmap, _, _ = np.histogram2d(pos.T[0], pos.T[1], weights=a, bins=30)\n",
    "    heatmap = gaussian_smooth(pos, a)\n",
    "    ax[i, 1].imshow(heatmap, extent=(0, 300, 0, 300), cmap='div', vmin=-1, vmax=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b66ae50-84db-49c9-b6fb-480a3ec1ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = pplt.subplots(ncols=4, nrows=4)\n",
    "ax.format(toplabels=['Clip -> Heatmap', 'Heatmap', 'Heatmap -> Clip', 'Scatter'])\n",
    "\n",
    "for i in range(4):\n",
    "    m = ax[i, 3].scatter(pos.T[0], pos.T[1], c=stacked['shared_activations'][0, :, i], alpha=0.2)\n",
    "    ax[i, 3].colorbar(m)\n",
    "    \n",
    "    a = np.clip(stacked['shared_activations'][0, :, i].numpy(), 0, 1)\n",
    "    # heatmap, _, _ = np.histogram2d(pos.T[0], pos.T[1], weights=a, bins=30)\n",
    "    heatmap = gaussian_smooth(pos, a, sigma=15)\n",
    "    ax[i, 0].imshow(heatmap, extent=(0, 300, 0, 300), cmap='div', vmin=-1, vmax=1)\n",
    "\n",
    "    a = stacked['shared_activations'][0, :, i].numpy()\n",
    "    # heatmap, _, _ = np.histogram2d(pos.T[0], pos.T[1], weights=a, bins=30)\n",
    "    heatmap = gaussian_smooth(pos, a, sigma=15)\n",
    "    ax[i, 1].imshow(heatmap, extent=(0, 300, 0, 300), cmap='div', vmin=-1, vmax=1)\n",
    "\n",
    "    ax[i, 2].imshow(np.clip(heatmap, 0, 1), extent=(0, 300, 0, 300), cmap='div', vmin=-1, vmax=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b4b3aa-ecc8-40a1-8ce4-fa3f903db8d1",
   "metadata": {},
   "source": [
    "## Split by whether poster is in view\n",
    "\n",
    "Note, run data collection in above section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f920115b-cd15-4d66-a0b4-c72c39972674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pinview = np.array(eps['data']['poster_in_view'])\n",
    "\n",
    "activ = stacked['shared_activations'][0]\n",
    "\n",
    "#split into poster in view and poster not in view, from scatter first\n",
    "activ_inview = activ[pinview]\n",
    "activ_notinview = activ[~pinview]\n",
    "pos_inview = pos[pinview]\n",
    "pos_notinview = pos[~pinview]\n",
    "\n",
    "fig, ax = pplt.subplots(ncols=3, nrows=4)\n",
    "ax.format(toplabels=['Poster in View', 'Poster not in View', 'Combined'])\n",
    "\n",
    "for i in range(4):\n",
    "    # pass\n",
    "    ax[i, 0].scatter(pos_inview.T[0], pos_inview.T[1], c=activ_inview[:, i], alpha=0.2)\n",
    "    ax[i, 1].scatter(pos_notinview.T[0], pos_notinview.T[1], c=activ_notinview[:, i], alpha=0.2)\n",
    "    ax[i, 2].scatter(pos.T[0], pos.T[1], c=activ[:, i], alpha=0.2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc42d1b-d989-4c93-a7ab-1304fb047ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Prune first n timesteps as well as split between poster in view and not\n",
    "dones = eps['dones']\n",
    "activ = stacked['shared_activations'][0, :, :]\n",
    "pinview = np.array(eps['data']['poster_in_view'])\n",
    "\n",
    "ep_activ = split_by_ep(activ, dones)\n",
    "ep_pos = split_by_ep(pos, dones)\n",
    "ep_pinview = split_by_ep(pinview, dones)\n",
    "\n",
    "prune_first = 5\n",
    "pruned_ep_activ = [a[prune_first:] for a in ep_activ]\n",
    "pruned_activ = torch.vstack(pruned_ep_activ)\n",
    "pruned_ep_pos = [p[prune_first:] for p in ep_pos]\n",
    "pruned_pos = np.vstack(pruned_ep_pos)\n",
    "pruned_ep_pinview = [p[prune_first:] for p in ep_pinview]\n",
    "pruned_pinview = np.concatenate(pruned_ep_pinview)\n",
    "\n",
    "#split into poster in view and poster not in view, from scatter first\n",
    "activ_inview = pruned_activ[pruned_pinview]\n",
    "activ_notinview = pruned_activ[~pruned_pinview]\n",
    "pos_inview = pruned_pos[pruned_pinview]\n",
    "pos_notinview = pruned_pos[~pruned_pinview]\n",
    "\n",
    "fig, ax = pplt.subplots(ncols=3, nrows=4)\n",
    "ax.format(toplabels=['Poster in View', 'Poster not in View', 'Combined'], \n",
    "         suptitle=f'Scatter Activations on Width 4, First {prune_first} Steps Pruned')\n",
    "\n",
    "for i in range(4):\n",
    "    # pass\n",
    "    ax[i, 0].scatter(pos_inview.T[0], pos_inview.T[1], c=activ_inview[:, i], alpha=0.2)\n",
    "    ax[i, 1].scatter(pos_notinview.T[0], pos_notinview.T[1], c=activ_notinview[:, i], alpha=0.2)\n",
    "    ax[i, 2].scatter(pos.T[0], pos.T[1], c=activ[:, i], alpha=0.2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a455c7-628c-4cad-aa07-23d104c34fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82f128b-f437-4907-a1a1-7ca86846dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = clean_eps(eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b154dab1-d6ba-4d87-b102-215793c0da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = res['pos_notinview']\n",
    "a = res['activ_notinview']\n",
    "\n",
    "fig, ax = pplt.subplots(ncols=2, nrows=4)\n",
    "\n",
    "for i in range(4):\n",
    "    heatmap = gaussian_smooth(p, a[:, i], sigma=6)\n",
    "    ax[i, 0].scatter(p.T[0], p.T[1], c=a[:, i], alpha=0.2)\n",
    "    ax[i, 1].imshow(heatmap, extent=(0, 300, 0, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24df4271-c3ff-4d68-80a3-6195a29cdd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show starting points\n",
    "starting_pts = np.vstack([p[0] for p in ep_pos])\n",
    "fig, ax = pplt.subplots()\n",
    "ax.format(xlim=[0, 300], ylim=[0, 300])\n",
    "ax.scatter(starting_pts.T[0], starting_pts.T[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fce0fc-3653-4c05-9f9f-07dd94553ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "widths = [2, 3, 4, 8, 16, 32, 64]\n",
    "fig_sizes = [(1, 2), (1, 3), (2, 2), (2, 4), (4, 4), (4, 8), (8, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51e8706-ff1b-47bc-83b2-987b4f54a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "num_trials = 3\n",
    "trial = 0\n",
    "width = widths[n]\n",
    "model_name = f'nav_poster_netstructure/nav_pdistal_width{width}batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, trial)\n",
    "\n",
    "eps = evalu(model, obs_rms, env_kwargs=kwargs, n=500,\n",
    "      data_callback=poster_data_callback, with_activations=True)\n",
    "\n",
    "res = clean_eps(eps)\n",
    "p = res['pos_notinview']\n",
    "a = res['activ_notinview']\n",
    "fig_size = fig_sizes[n]\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=fig_size[0], ncols=fig_size[1])\n",
    "\n",
    "for i in range(widths[n]):\n",
    "    heatmap = gaussian_smooth(p, a[:, i], sigma=6)\n",
    "    # ax[i, 0].scatter(p.T[0], p.T[1], c=a[:, i], alpha=0.2)\n",
    "    ax[i].imshow(heatmap, extent=(0, 300, 0, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe791f2-2bdc-406b-8d9d-e5e2e8540b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "trial = 0\n",
    "width = widths[n]\n",
    "fig_size = fig_sizes[n]\n",
    "\n",
    "model_name = f'nav_poster_netstructure/nav_pdistal_width{width}batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, trial)\n",
    "\n",
    "eps = evalu(model, obs_rms, env_kwargs=kwargs, n=500,\n",
    "      data_callback=poster_data_callback, with_activations=True)\n",
    "\n",
    "res = clean_eps(eps)\n",
    "p = res['pos_notinview']\n",
    "a = res['activ_notinview']\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=fig_size[0], ncols=fig_size[1])\n",
    "\n",
    "for i in range(widths[n]):\n",
    "    heatmap = gaussian_smooth(p, a[:, i], sigma=6)\n",
    "    # ax[i, 0].scatter(p.T[0], p.T[1], c=a[:, i], alpha=0.2)\n",
    "    ax[i].imshow(heatmap, extent=(0, 300, 0, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa75f9-f940-427b-ad68-c951aec25d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "trial = 0\n",
    "width = widths[n]\n",
    "fig_size = fig_sizes[n]\n",
    "\n",
    "model_name = f'nav_poster_netstructure/nav_pdistal_width{width}batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, trial)\n",
    "\n",
    "eps = evalu(model, obs_rms, env_kwargs=kwargs, n=500,\n",
    "      data_callback=poster_data_callback, with_activations=True)\n",
    "\n",
    "res = clean_eps(eps)\n",
    "p = res['pos_notinview']\n",
    "a = res['activ_notinview']\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=fig_size[0], ncols=fig_size[1])\n",
    "\n",
    "for i in range(widths[n]):\n",
    "    heatmap = gaussian_smooth(p, a[:, i], sigma=6)\n",
    "    # ax[i, 0].scatter(p.T[0], p.T[1], c=a[:, i], alpha=0.2)\n",
    "    ax[i].imshow(heatmap, extent=(0, 300, 0, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b7628-448c-4be5-aea6-a3f2e43ab2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "trial = 0\n",
    "width = widths[n]\n",
    "fig_size = fig_sizes[n]\n",
    "\n",
    "model_name = f'nav_poster_netstructure/nav_pdistal_width{width}batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, trial)\n",
    "\n",
    "eps = evalu(model, obs_rms, env_kwargs=kwargs, n=500,\n",
    "      data_callback=poster_data_callback, with_activations=True)\n",
    "\n",
    "res = clean_eps(eps)\n",
    "p = res['pos_notinview']\n",
    "a = res['activ_notinview']\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=fig_size[0], ncols=fig_size[1])\n",
    "\n",
    "for i in range(widths[n]):\n",
    "    heatmap = gaussian_smooth(p, a[:, i], sigma=6)\n",
    "    # ax[i, 0].scatter(p.T[0], p.T[1], c=a[:, i], alpha=0.2)\n",
    "    ax[i].imshow(heatmap, extent=(0, 300, 0, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ba23d-56ea-4869-af01-4367067d2d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "trial = 0\n",
    "width = widths[n]\n",
    "fig_size = fig_sizes[n]\n",
    "\n",
    "model_name = f'nav_poster_netstructure/nav_pdistal_width{width}batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, trial)\n",
    "\n",
    "eps = evalu(model, obs_rms, env_kwargs=kwargs, n=500,\n",
    "      data_callback=poster_data_callback, with_activations=True)\n",
    "\n",
    "res = clean_eps(eps)\n",
    "p = res['pos_notinview']\n",
    "a = res['activ_notinview']\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=fig_size[0], ncols=fig_size[1])\n",
    "\n",
    "for i in range(widths[n]):\n",
    "    heatmap = gaussian_smooth(p, a[:, i], sigma=6)\n",
    "    # ax[i, 0].scatter(p.T[0], p.T[1], c=a[:, i], alpha=0.2)\n",
    "    ax[i].imshow(heatmap, extent=(0, 300, 0, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0fecfd-6ee2-447e-9e93-6b6765f95ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "trial = 0\n",
    "width = widths[n]\n",
    "fig_size = fig_sizes[n]\n",
    "\n",
    "model_name = f'nav_poster_netstructure/nav_pdistal_width{width}batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, trial)\n",
    "\n",
    "eps = evalu(model, obs_rms, env_kwargs=kwargs, n=500,\n",
    "      data_callback=poster_data_callback, with_activations=True)\n",
    "\n",
    "res = clean_eps(eps)\n",
    "p = res['pos_notinview']\n",
    "a = res['activ_notinview']\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=fig_size[0], ncols=fig_size[1])\n",
    "\n",
    "for i in range(widths[n]):\n",
    "    heatmap = gaussian_smooth(p, a[:, i], sigma=6)\n",
    "    # ax[i, 0].scatter(p.T[0], p.T[1], c=a[:, i], alpha=0.2)\n",
    "    ax[i].imshow(heatmap, extent=(0, 300, 0, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b9dc4b-f2d8-4b7f-9b43-678504557915",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "trial = 0\n",
    "width = widths[n]\n",
    "fig_size = fig_sizes[n]\n",
    "\n",
    "model_name = f'nav_poster_netstructure/nav_pdistal_width{width}batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, trial)\n",
    "\n",
    "eps = evalu(model, obs_rms, env_kwargs=kwargs, n=500,\n",
    "      data_callback=poster_data_callback, with_activations=True)\n",
    "\n",
    "res = clean_eps(eps)\n",
    "p = res['pos_notinview']\n",
    "a = res['activ_notinview']\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=fig_size[0], ncols=fig_size[1])\n",
    "\n",
    "for i in range(widths[n]):\n",
    "    heatmap = gaussian_smooth(p, a[:, i], sigma=6)\n",
    "    # ax[i, 0].scatter(p.T[0], p.T[1], c=a[:, i], alpha=0.2)\n",
    "    ax[i].imshow(heatmap, extent=(0, 300, 0, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac11fda-53f4-4c1e-9a75-b3e07c2cd460",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "trial = 0\n",
    "width = widths[n]\n",
    "fig_size = fig_sizes[n]\n",
    "\n",
    "model_name = f'nav_poster_netstructure/nav_pdistal_width{width}batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, trial)\n",
    "\n",
    "eps = evalu(model, obs_rms, env_kwargs=kwargs, n=500,\n",
    "      data_callback=poster_data_callback, with_activations=True)\n",
    "\n",
    "res = clean_eps(eps, clip=False)\n",
    "p = res['pos']\n",
    "a = res['activ']\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=fig_size[0], ncols=fig_size[1])\n",
    "\n",
    "for i in range(widths[n]):\n",
    "    heatmap = gaussian_smooth(p, a[:, i], sigma=6)\n",
    "    # ax[i, 0].scatter(p.T[0], p.T[1], c=a[:, i], alpha=0.2)\n",
    "    ax[i].imshow(heatmap, extent=(0, 300, 0, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957d34cd-1452-4016-905e-9546a7077d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "trial = 0\n",
    "width = widths[n]\n",
    "fig_size = fig_sizes[n]\n",
    "\n",
    "model_name = f'nav_poster_netstructure/nav_pdistal_width{width}batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, trial)\n",
    "\n",
    "eps = evalu(model, obs_rms, env_kwargs=kwargs, n=200,\n",
    "      data_callback=poster_data_callback, with_activations=True)\n",
    "\n",
    "res = clean_eps(eps, clip=False)\n",
    "p = res['pos']\n",
    "a = res['activ']\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=fig_size[0], ncols=fig_size[1])\n",
    "\n",
    "for i in range(widths[n]):\n",
    "    heatmap = gaussian_smooth(p, a[:, i], sigma=10)\n",
    "    # ax[i, 0].scatter(p.T[0], p.T[1], c=a[:, i], alpha=0.2)\n",
    "    ax[i].imshow(heatmap, extent=(0, 300, 0, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e24d99-b011-41f3-bc14-d6221ecd343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "trial = 0\n",
    "width = 64\n",
    "fig_size = [8, 8]\n",
    "\n",
    "model_name = f'nav_poster_netstructure/nav_pdistal_width{width}batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, trial)\n",
    "\n",
    "all_ep_randinit64 = evalu(model, obs_rms, env_kwargs=kwargs, n=200,\n",
    "      data_callback=poster_data_callback, with_activations=True)\n",
    "\n",
    "res = clean_eps(all_ep_randinit64, clip=False)\n",
    "p = res['pos']\n",
    "a = res['activ']\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=fig_size[0], ncols=fig_size[1])\n",
    "\n",
    "for i in range(64):\n",
    "    heatmap = gaussian_smooth(p, a[:, i], sigma=10)\n",
    "    # ax[i, 0].scatter(p.T[0], p.T[1], c=a[:, i], alpha=0.2)\n",
    "    ax[i].imshow(heatmap, extent=(0, 300, 0, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58dbe6a-f432-4b4f-99ef-eab5d2e89fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "trial = 0\n",
    "width = widths[n]\n",
    "fig_size = fig_sizes[n]\n",
    "\n",
    "model_name = f'nav_poster_netstructure/nav_pdistal_width{width}batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, trial)\n",
    "\n",
    "# eps = evalu(model, obs_rms, env_kwargs=kwargs, n=500,\n",
    "#       data_callback=poster_data_callback, with_activations=True)\n",
    "\n",
    "res = clean_eps(eps)\n",
    "p = res['pos_notinview']\n",
    "a = res['activ_notinview']\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=fig_size[0], ncols=fig_size[1])\n",
    "\n",
    "for i in range(widths[n]):\n",
    "    heatmap = gaussian_smooth(p, a[:, i], sigma=15)\n",
    "    # ax[i, 0].scatter(p.T[0], p.T[1], c=a[:, i], alpha=0.2)\n",
    "    ax[i].imshow(heatmap, extent=(0, 300, 0, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d82ae49-17f6-49e2-8a80-213f8d6ace9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "trial = 0\n",
    "width = widths[n]\n",
    "fig_size = fig_sizes[n]\n",
    "\n",
    "model_name = f'nav_poster_netstructure/nav_pdistal_width{width}batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, trial)\n",
    "\n",
    "# eps = evalu(model, obs_rms, env_kwargs=kwargs, n=500,\n",
    "#       data_callback=poster_data_callback, with_activations=True)\n",
    "\n",
    "res = clean_eps(eps, clip=False)\n",
    "p = res['pos_notinview']\n",
    "a = res['activ_notinview']\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=fig_size[0], ncols=fig_size[1])\n",
    "\n",
    "for i in range(widths[n]):\n",
    "    heatmap = gaussian_smooth(p, a[:, i], sigma=15)\n",
    "    heatmap = np.clip(heatmap, 0, 1)\n",
    "    # ax[i, 0].scatter(p.T[0], p.T[1], c=a[:, i], alpha=0.2)\n",
    "    ax[i].imshow(heatmap, extent=(0, 300, 0, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9fba9b-46ff-4575-a2c5-19243caa7efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "trial = 0\n",
    "width = widths[n]\n",
    "fig_size = fig_sizes[n]\n",
    "\n",
    "model_name = f'nav_poster_netstructure/nav_pdistal_width{width}batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, trial)\n",
    "\n",
    "# eps = evalu(model, obs_rms, env_kwargs=kwargs, n=500,\n",
    "#       data_callback=poster_data_callback, with_activations=True)\n",
    "\n",
    "res = clean_eps(eps, clip=False)\n",
    "p = res['pos']\n",
    "a = res['activ']\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=fig_size[0], ncols=fig_size[1])\n",
    "\n",
    "for i in range(widths[n]):\n",
    "    heatmap = gaussian_smooth(p, a[:, i], sigma=15)\n",
    "    heatmap = np.clip(heatmap, 0, 1)\n",
    "    # ax[i, 0].scatter(p.T[0], p.T[1], c=a[:, i], alpha=0.2)\n",
    "    ax[i].imshow(heatmap, extent=(0, 300, 0, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da93188b-8195-45f1-be47-9eef46a1302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to fill in the outer rim of points that are missing\n",
    "WINDOW_SIZE = (300, 300)\n",
    "step_size = 10.\n",
    "xs = np.arange(0+step_size, WINDOW_SIZE[0], step_size)\n",
    "ys = np.arange(0+step_size, WINDOW_SIZE[1], step_size)\n",
    "# thetas = np.linspace(0, 2*np.pi, 12, endpoint=False)\n",
    "start_points = []\n",
    "start_angles = []\n",
    "for x in xs:\n",
    "    for y in [5., 295.]:\n",
    "        point = np.array([x, y])\n",
    "        angle = np.arctan2(150 - y, 150 - x)\n",
    "        start_points.append(point)\n",
    "        start_angles.append(angle)\n",
    "for y in ys:\n",
    "    for x in [5, 295]:\n",
    "        point = np.array([x, y])\n",
    "        angle = np.arctan2(150 - y, 150 - x)\n",
    "        start_points.append(point)\n",
    "        start_angles.append(angle)\n",
    "        \n",
    "start_points = np.vstack(start_points)\n",
    "# plt.scatter(points.T[0], points.T[1])\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim([-5, 305])\n",
    "ax.set_ylim([-5, 305])\n",
    "for i in range(len(start_points)):\n",
    "    draw_character(start_points[i], start_angles[i], ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce4394-9426-493d-9a81-265baf437287",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_randomizer = lambda step: np.random.choice([0, 1, 2])\n",
    "\n",
    "all_ep = []\n",
    "for i in range(len(points)):\n",
    "    kw = kwargs.copy()\n",
    "    kw['fixed_reset'] = [points[i], angles[i]]\n",
    "    ep = forced_action_evaluate(model, obs_rms, forced_actions=action_randomizer, \n",
    "                                seed=i*5, num_episodes=3, env_kwargs=kw, data_callback=poster_data_callback,\n",
    "                                with_activations=True)\n",
    "    # ep = clean_eps(ep)\n",
    "    all_ep.append(ep)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1202fc0e-9b75-4b16-9d0f-e69797d30517",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ep_cleaned = [clean_eps(ep) for ep in all_ep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1377c1-795c-4eb2-b4ca-fadc00a51dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1215f62a-c783-4719-a8ee-13aa9af0fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "pos = np.vstack([ep['pos'] for ep in all_ep_cleaned])\n",
    "angles = np.concatenate([ep['angles'] for ep in all_ep_cleaned])\n",
    "activ = np.concatenate([ep['activ'][:, i] for ep in all_ep_cleaned])\n",
    "\n",
    "angle_split_activ = split_by_angle(activ, angles)\n",
    "angle_split_pos = split_by_angle(pos, angles)\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=2, ncols=2)\n",
    "for i in range(4):\n",
    "    p = angle_split_pos[i]\n",
    "    a = angle_split_activ[i]\n",
    "    heatmap = gaussian_smooth(p, a)\n",
    "    \n",
    "    ax[i].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc350b0-7af8-4b02-8340-4a8bcea2940f",
   "metadata": {},
   "source": [
    "## Forced action forward only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc0f67-4cea-4cff-8833-ea040ef2b657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8aac0-167c-4500-a9a2-690a91cc7731",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "for i in tqdm(range(4)):\n",
    "    pos = np.vstack([ep['pos'] for ep in all_ep])\n",
    "    activ = np.concatenate([ep['activ'][:, i] for ep in all_ep])\n",
    "    # plt.scatter(pos.T[0], pos.T[1], alpha=0.1, c=activ)\n",
    "    heatmap = gaussian_smooth(pos, activ)\n",
    "    ax[i].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc891c-21b9-47b0-b485-5a0b147ab130",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_randomizer = lambda step: np.random.choice([0, 1, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa7bc85-a3aa-4850-b9fe-59e3dabf8e72",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Further Experiments\n",
    "* Outer rim initial conditions\n",
    "* Random actions\n",
    "* Split by poster in view, poster seen\n",
    "* Borrow actions from another policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f09ee4-9f6f-4e3a-a882-c51a908d50ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a985070-a9c6-48c7-8332-2fea41f03d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_ep = []\n",
    "for i in range(len(start_points)):\n",
    "# for i in range():\n",
    "    kw = kwargs.copy()\n",
    "    kw['fixed_reset'] = [start_points[i].copy(), start_angles[i].copy()]\n",
    "    ep = forced_action_evaluate(model, obs_rms,\n",
    "                                seed=0, num_episodes=1, env_kwargs=kw, data_callback=nav_data_callback,\n",
    "                                with_activations=True)\n",
    "    # ep = clean_eps(ep)\n",
    "    all_ep.append(ep)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68457b3e-3561-433d-bd62-3dc96a3efa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# p = np.vstack(all_ep[0]['data']['pos'])\n",
    "p = np.vstack([ep['data']['pos'] for ep in all_ep])\n",
    "ax.scatter(p.T[0], p.T[1], alpha=0.2)\n",
    "draw_box(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ff4f21-2326-4dc6-8080-6ad5d1537f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_activ = [stack_activations(ep['activations'])['shared_activations'] for ep in all_ep]\n",
    "all_activ = torch.vstack([activ[0, :, :] for activ in all_activ])\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "for i in range(4):\n",
    "    activ = all_activ[:, i]\n",
    "    heatmap = gaussian_smooth(p, activ)\n",
    "    ax[i].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01a7984-b5fc-4192-a381-7c4b67f08fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_actions = [ep['actions'] for ep in all_ep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a6c2e-648a-465b-9bca-91a76eda86e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nav_poster_netstructure/nav_pdistal_width64batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "\n",
    "all_ep_copied = []\n",
    "for i in range(len(start_points)):\n",
    "    action_copier = lambda step: saved_actions[i][step]\n",
    "    \n",
    "    kw = kwargs.copy()\n",
    "    kw['fixed_reset'] = [start_points[i].copy(), start_angles[i].copy()]\n",
    "    ep = forced_action_evaluate(model, obs_rms, forced_actions=action_copier,\n",
    "                                seed=0, num_episodes=1, env_kwargs=kw, data_callback=poster_data_callback,\n",
    "                                with_activations=True)\n",
    "    # ep = clean_eps(ep)\n",
    "    all_ep_copied.append(ep)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7726ccfa-793f-4046-916d-fb755158fe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_activ = [stack_activations(ep['activations'])['shared_activations'] for ep in all_ep_copied]\n",
    "all_activ = torch.vstack([activ[0, :, :] for activ in all_activ])\n",
    "p = np.vstack([ep['data']['pos'] for ep in all_ep_copied])\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=8, ncols=8)\n",
    "\n",
    "for i in range(64):\n",
    "    activ = all_activ[:, i]\n",
    "    heatmap = gaussian_smooth(p, activ)\n",
    "    ax[i].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191076c1-822b-4215-a06b-aac8ff14b768",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = stack_all_ep(all_ep_copied)\n",
    "cleaned = clean_eps(eps)\n",
    "\n",
    "# all_activ = [stack_activations(ep['activations'])['shared_activations'] for ep in all_ep_randact64]\n",
    "# all_activ = torch.vstack([activ[0, :, :] for activ in all_activ])\n",
    "# p = np.vstack([ep['data']['pos'] for ep in all_ep_randact64])\n",
    "\n",
    "all_activ = cleaned['activ_seen']\n",
    "p = cleaned['pos_seen']\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=8, ncols=8)\n",
    "\n",
    "for i in range(64):\n",
    "    activ = all_activ[:, i]\n",
    "    heatmap = gaussian_smooth(p, activ)\n",
    "    ax[i].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298c55e1-a3d2-4108-a8e9-2a745b40b613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8251d77f-f99a-4732-b0ad-63a456d884fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = clean_eps(eps, prune_first=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6acd58-0b95-48d1-889d-374b11a510c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(ncols=3)\n",
    "ax[0].scatter(cleaned['pos'].T[0], cleaned['pos'].T[1], alpha=0.3)\n",
    "p = cleaned['pos_seen']\n",
    "ax[1].scatter(p.T[0], p.T[1], alpha=0.3)\n",
    "p = cleaned['pos_notseen']\n",
    "ax[2].scatter(p.T[0], p.T[1], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cdd6b7-5686-4b23-b7e6-294f98b70849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892cb71d-40fe-4820-93be-34c8261f23c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nav_poster_netstructure/nav_pdistal_width64batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "\n",
    "all_ep64 = []\n",
    "for i in range(len(start_points)):\n",
    "    action_copier = lambda step: saved_actions[i][step]\n",
    "    \n",
    "    kw = kwargs.copy()\n",
    "    kw['fixed_reset'] = [start_points[i].copy(), start_angles[i].copy()]\n",
    "    ep = forced_action_evaluate(model, obs_rms,\n",
    "                                seed=0, num_episodes=1, env_kwargs=kw, data_callback=poster_data_callback,\n",
    "                                with_activations=True)\n",
    "    # ep = clean_eps(ep)\n",
    "    all_ep64.append(ep)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff288ea1-fed4-4b4e-ac35-ca5c3d6fd978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_activ = [stack_activations(ep['activations'])['shared_activations'] for ep in all_ep64]\n",
    "# all_activ = torch.vstack([activ[0, :, :] for activ in all_activ])\n",
    "# p = np.vstack([ep['data']['pos'] for ep in all_ep64])\n",
    "eps = stack_all_ep(all_ep64)\n",
    "cleaned = clean_eps(eps)\n",
    "\n",
    "p = cleaned['pos']\n",
    "all_activ = cleaned['activ']\n",
    "fig, ax = pplt.subplots(nrows=8, ncols=8)\n",
    "\n",
    "for i in range(64):\n",
    "    activ = all_activ[:, i]\n",
    "    heatmap = gaussian_smooth(p, activ)\n",
    "    ax[i].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc52a7d-d174-46ea-9459-bde982968ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nav_poster_netstructure/nav_pdistal_width64batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "\n",
    "all_ep_randact64 = []\n",
    "\n",
    "#randomize actions following action distribution of original policy\n",
    "all_act = torch.vstack([torch.vstack(ep['actions']) for ep in all_ep64])\n",
    "act_probs = [((all_act == i).sum() / len(all_act)).item() for i in range(3)]\n",
    "act_probs = [act_probs[i] / np.sum(act_probs) for i in range(3)]\n",
    "action_randomizer = lambda step: np.random.choice([0, 1, 2], p=act_probs)\n",
    "\n",
    "for i in range(len(start_points)):\n",
    "    kw = kwargs.copy()\n",
    "    kw['fixed_reset'] = [start_points[i].copy(), start_angles[i].copy()]\n",
    "    ep = forced_action_evaluate(model, obs_rms, forced_actions=action_randomizer,\n",
    "                                seed=i, num_episodes=1, env_kwargs=kw, data_callback=poster_data_callback,\n",
    "                                with_activations=True)\n",
    "    # ep = clean_eps(ep)\n",
    "    all_ep_randact64.append(ep)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c766af54-9832-42f3-b88e-a2eed711a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = stack_all_ep(all_ep_randact64)\n",
    "cleaned = clean_eps(eps)\n",
    "\n",
    "# all_activ = [stack_activations(ep['activations'])['shared_activations'] for ep in all_ep_randact64]\n",
    "# all_activ = torch.vstack([activ[0, :, :] for activ in all_activ])\n",
    "# p = np.vstack([ep['data']['pos'] for ep in all_ep_randact64])\n",
    "\n",
    "all_activ = cleaned['activ_seen']\n",
    "p = cleaned['pos_seen']\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=8, ncols=8)\n",
    "\n",
    "for i in range(64):\n",
    "    activ = all_activ[:, i]\n",
    "    heatmap = gaussian_smooth(p, activ)\n",
    "    ax[i].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dd79eb-49c6-4dcf-adfd-0f162b29ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = stack_all_ep(all_ep_randact64)\n",
    "cleaned = clean_eps(eps)\n",
    "\n",
    "# all_activ = [stack_activations(ep['activations'])['shared_activations'] for ep in all_ep_randact64]\n",
    "# all_activ = torch.vstack([activ[0, :, :] for activ in all_activ])\n",
    "# p = np.vstack([ep['data']['pos'] for ep in all_ep_randact64])\n",
    "\n",
    "all_activ = cleaned['activ_notseen']\n",
    "p = cleaned['pos_notseen']\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=8, ncols=8)\n",
    "\n",
    "for i in range(64):\n",
    "    activ = all_activ[:, i]\n",
    "    heatmap = gaussian_smooth(p, activ)\n",
    "    ax[i].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7362db61-adb4-4eb5-a522-19f47c058b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(ncols=3)\n",
    "ax[0].scatter(cleaned['pos'].T[0], cleaned['pos'].T[1], alpha=0.3)\n",
    "p = cleaned['pos_seen']\n",
    "ax[1].scatter(p.T[0], p.T[1], alpha=0.3)\n",
    "p = cleaned['pos_notseen']\n",
    "ax[2].scatter(p.T[0], p.T[1], alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68f324f-992d-40b8-a19f-6a590141a1a2",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "* There doesn't seem to be much use in filtering out when the poster is in view or not - it seems like this gets averaged out from all the other states where the poste is not in view\n",
    "* Random actions really messes with the acivations, it becomes much less clear that nodes have any principled activation pattern\n",
    "    * Splitting by view angle does seem to show some symmetry - which makes sense, in general a node cannot break symmetry effectively without consistent cues... \n",
    "    * **Should think about this idea some more. Why can't the 64 network break the symmetry when given actions from the 4 network? Seems like it is very restricted to effective performance on its existing trajectories.**\n",
    "    * **What would then happen if you give it a partway set of actions that cause hallucination, will it fail due to this out of distribution trajectory?**\n",
    "    * Are there representations that are more resilient and can act in these more out-of-policy scenarios?\n",
    "* Following policy and starting initial conditions about the boundary gives consistent activations, as the agent has conserved behavior\n",
    "* Starting about random initial conditions of course makes the patterns more messy, but some of the same structures can be seen\n",
    "    * This suggests that maybe it might make sense to average activation maps between these types of episodes\n",
    "* Giving the 64 width network trajectories from the 4 width network creates the same \"hallucinations\" as the 4 width has. Does this happen in reverse? If this is the case, we might want to force the same actions in all cases so that we can appropriately compare generated activations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f56aef2-d8f1-4de5-84e2-b4f77541cfe3",
   "metadata": {},
   "source": [
    "# Experiment Summary\n",
    "\n",
    "Generate data with all meaningful experiments simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae50c608-63c1-4a3c-92fe-33449fe2d909",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nav_poster_netstructure/nav_pdistal_width64batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, trial)\n",
    "\n",
    "#1. 200 Random initial condition episodes\n",
    "\n",
    "all_ep_64 = []\n",
    "for i in range(200):\n",
    "    ep = forced_action_evaluate(model, obs_rms, env_kwargs=kwargs, \n",
    "                                num_episodes=1, data_callback=poster_data_callback, seed=i,\n",
    "                                with_activations=True)\n",
    "    all_ep_64.append(ep)\n",
    "eps_64 = stack_all_ep(all_ep_64)\n",
    "\n",
    "#Starting around rim - First generate start points and angles\n",
    "WINDOW_SIZE = (300, 300)\n",
    "step_size = 10.\n",
    "xs = np.arange(0+step_size, WINDOW_SIZE[0], step_size)\n",
    "ys = np.arange(0+step_size, WINDOW_SIZE[1], step_size)\n",
    "# thetas = np.linspace(0, 2*np.pi, 12, endpoint=False)\n",
    "start_points = []\n",
    "start_angles = []\n",
    "for x in xs:\n",
    "    for y in [5., 295.]:\n",
    "        point = np.array([x, y])\n",
    "        angle = np.arctan2(150 - y, 150 - x)\n",
    "        start_points.append(point)\n",
    "        start_angles.append(angle)\n",
    "for y in ys:\n",
    "    for x in [5, 295]:\n",
    "        point = np.array([x, y])\n",
    "        angle = np.arctan2(150 - y, 150 - x)\n",
    "        start_points.append(point)\n",
    "        start_angles.append(angle)\n",
    "        \n",
    "start_points = np.vstack(start_points)\n",
    "\n",
    "# 2. Starting around rim episodes\n",
    "all_ep_rim64 = []\n",
    "for i in range(len(start_points)):\n",
    "    kw = kwargs.copy()\n",
    "    kw['fixed_reset'] = [start_points[i].copy(), start_angles[i].copy()]\n",
    "    ep = forced_action_evaluate(model, obs_rms, seed=0, num_episodes=1, \n",
    "                                env_kwargs=kw, data_callback=poster_data_callback,\n",
    "                                with_activations=True)\n",
    "    all_ep_rim64.append(ep)\n",
    "eps_rim64 = stack_all_ep(all_ep_rim64)\n",
    "\n",
    "\n",
    "saved_actions_rim64 = [ep['actions'] for ep in all_ep_rim64]\n",
    "saved_actions_64 = [ep['actions'] for ep in all_ep_64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1dcf7f-7b91-449a-846f-5da222d16b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put both sets of activations and total averaged onto same plot\n",
    "array = []\n",
    "for i in range(8):\n",
    "    l1 = list(np.arange(8)+1 + i*8)\n",
    "    l2 = list(np.arange(8)+65 + i*8)\n",
    "    array.append(l1 + l2)\n",
    "for i in range(8):\n",
    "    l1 = [0]*4 + list(np.arange(8)+129 + i*8) + [0]*4\n",
    "    array.append(l1)\n",
    "    \n",
    "fig, ax = pplt.subplots(array, hspace=[0,0,0,0,0,0,0,10,0,0,0,0,0,0,0,],\n",
    "                       wspace=[0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,])\n",
    "\n",
    "\n",
    "cleaned = clean_eps(eps_64)\n",
    "p1 = cleaned['pos']\n",
    "a1 = cleaned['activ']\n",
    "\n",
    "cleaned = clean_eps(eps_rim64)\n",
    "p2 = cleaned['pos']\n",
    "a2 = cleaned['activ']\n",
    "\n",
    "p3 = np.vstack([p1, p2])\n",
    "a3 = np.vstack([a1, a2])\n",
    "\n",
    "\n",
    "for i in range(64):\n",
    "    heatmap = gaussian_smooth(p1, a1[:, i])\n",
    "    ax[i].imshow(heatmap, extent=(5, 295, 5, 295))\n",
    "for i in range(64):\n",
    "    heatmap = gaussian_smooth(p2, a2[:, i])\n",
    "    ax[i+64].imshow(heatmap, extent=(5, 295, 5, 295))\n",
    "for i in range(64):\n",
    "    heatmap = gaussian_smooth(p3, a3[:, i])\n",
    "    ax[i+128].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8b0355-f4f2-4909-9f6c-1bdbc0da5682",
   "metadata": {},
   "source": [
    "# 64 -> 4 forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6491394-85b9-48ee-b818-89e5f8b0861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nav_poster_netstructure/nav_pdistal_width4batch200'\n",
    "model, obs_rms, kwargs = load_model_and_env(model_name, trial)\n",
    "\n",
    "#1. 200 Random initial condition episodes (copied 64 actions)\n",
    "all_ep_copy4 = []\n",
    "for i in range(200):\n",
    "    copied_actions = lambda step: saved_actions_64[i][step]\n",
    "    ep = forced_action_evaluate(model, obs_rms, env_kwargs=kwargs, \n",
    "                                num_episodes=1, data_callback=poster_data_callback, seed=i,\n",
    "                                with_activations=True, forced_actions=copied_actions)\n",
    "    all_ep_copy4.append(ep)\n",
    "eps_copy4 = stack_all_ep(all_ep_copy4)\n",
    "\n",
    "# 2. Starting around rim episodes (copied 64 actions)\n",
    "all_ep_rimcopy4 = []\n",
    "for i in range(len(start_points)):\n",
    "    kw = kwargs.copy()\n",
    "    copied_actions = lambda step: saved_actions_rim64[i][step]\n",
    "\n",
    "    kw['fixed_reset'] = [start_points[i].copy(), start_angles[i].copy()]\n",
    "    ep = forced_action_evaluate(model, obs_rms, seed=0, num_episodes=1, \n",
    "                                env_kwargs=kw, data_callback=poster_data_callback,\n",
    "                                with_activations=True, forced_actions=copied_actions)\n",
    "    all_ep_rimcopy4.append(ep)\n",
    "eps_rimcopy4 = stack_all_ep(all_ep_rimcopy4)\n",
    "\n",
    "\n",
    "# 3. 200 Random initial condition episodes (copied 64 actions)\n",
    "all_ep_4 = []\n",
    "for i in range(200):\n",
    "    ep = forced_action_evaluate(model, obs_rms, env_kwargs=kwargs, \n",
    "                                num_episodes=1, data_callback=poster_data_callback, seed=i,\n",
    "                                with_activations=True)\n",
    "    all_ep_4.append(ep)\n",
    "eps_4 = stack_all_ep(all_ep_4)\n",
    "\n",
    "# 4. Starting around rim episodes (copied 64 actions)\n",
    "all_ep_rim4 = []\n",
    "for i in range(len(start_points)):\n",
    "    kw = kwargs.copy()\n",
    "    kw['fixed_reset'] = [start_points[i].copy(), start_angles[i].copy()]\n",
    "    ep = forced_action_evaluate(model, obs_rms, seed=0, num_episodes=1, \n",
    "                                env_kwargs=kw, data_callback=poster_data_callback,\n",
    "                                with_activations=True)\n",
    "    all_ep_rim4.append(ep)\n",
    "eps_rim4 = stack_all_ep(all_ep_rim4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e70a4bf-5526-4762-b46e-5356479c58cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4 -> 64 Forcing\n",
    "\n",
    "model_name64 = 'nav_poster_netstructure/nav_pdistal_width64batch200'\n",
    "model64, obs_rms64, kwargs = load_model_and_env(model_name64, trial)\n",
    "\n",
    "saved_actions_rim4 = [ep['actions'] for ep in all_ep_rim4]\n",
    "saved_actions_4 = [ep['actions'] for ep in all_ep_4]\n",
    "\n",
    "\n",
    "# 5. 200 Random initial condition episodes (copied 64 actions)\n",
    "all_ep_copy64 = []\n",
    "for i in range(200):\n",
    "    copied_actions = lambda step: saved_actions_4[i][step]\n",
    "    ep = forced_action_evaluate(model64, obs_rms64, env_kwargs=kwargs, \n",
    "                                num_episodes=1, data_callback=poster_data_callback, seed=i,\n",
    "                                with_activations=True, forced_actions=copied_actions)\n",
    "    all_ep_copy64.append(ep)\n",
    "eps_copy64 = stack_all_ep(all_ep_copy64)\n",
    "\n",
    "# 6. Starting around rim episodes (copied 64 actions)\n",
    "all_ep_rimcopy64 = []\n",
    "for i in range(len(start_points)):\n",
    "    kw = kwargs.copy()\n",
    "    copied_actions = lambda step: saved_actions_rim4[i][step]\n",
    "\n",
    "    kw['fixed_reset'] = [start_points[i].copy(), start_angles[i].copy()]\n",
    "    ep = forced_action_evaluate(model64, obs_rms64, seed=0, num_episodes=1, \n",
    "                                env_kwargs=kw, data_callback=poster_data_callback,\n",
    "                                with_activations=True, forced_actions=copied_actions)\n",
    "    all_ep_rimcopy64.append(ep)\n",
    "eps_rimcopy64 = stack_all_ep(all_ep_rimcopy64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99742b8-706b-453e-b249-210afac4a3d5",
   "metadata": {},
   "source": [
    "## Hallucinations\n",
    "\n",
    "Note that sometimes a cell which primarily with goal specificity will \"hallucinate\" when moving in a path to a corner without the goal. Interestingly, not all cells to this in the 64 cell case, but many do. The ones that don't are actually far more rare, but those are probably the interesting ones that are actually learning something more specific and able to incorporate information better.\n",
    "\n",
    "The 4 width network takes far more paths that induce these hallucinations. If we take the pathways from the 64 width network and feed them to the 4 width, we reduce the hallucinations. We can eliminate them completely by filtering out episodes where the path taken is not direct\n",
    "\n",
    "Questions: \n",
    "* Why are certain nodes less prone to hallucinations?\n",
    "    * Could simply be that there is agreement between activation near the platform and near the hallucination area (blue-blue or red-red)\n",
    "    * We could probably classify this by the difference of hallucinating activations separated vs activations with those paths removed\n",
    "* What does knowing about these hallucinations tell us?\n",
    "    * Maybe it tells us something about why the paths taken influence activations?\n",
    "    * **In relation to what we can do to classify the types of node representations... This tel             ls us that the representations are highly dependent on paths taken. Maybe it only makes sense to classify with specific pathways - but now it is harder to name what these certain cells are doing? Maybe we need a multi-classifying system, with different combinations of classification along different pathways?**\n",
    "* Can we modify the paths taken to eliminate the hallucinations? \n",
    "* Can we kick activations in a way as to \"convince\" the agent that the platform is not there?\n",
    "\n",
    "Maybe instead it makes sense to classify a nodes propensity for hallucination as it instead having a bias towards representing something about where the network thinks it is in relation to the goal. Nodes with a resistance to hallucination are really more static features instead. **We could question whether some representations are better for learning other tasks or not**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0eac94-dead-4324-a778-42aa8a077412",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = pplt.subplots(nrows=2, ncols=4, wspace=(0, 5, 0), hspace=0)\n",
    "\n",
    "cleaned = clean_eps(eps_rimcopy4)\n",
    "p = cleaned['pos']\n",
    "a = cleaned['activ']\n",
    "for n in range(4):\n",
    "    i = n // 2    \n",
    "    j = n % 2\n",
    "    heatmap = gaussian_smooth(p, a[:,n])\n",
    "    ax[i, j].imshow(heatmap, extent=(5, 295, 5, 295))\n",
    "    \n",
    "cleaned = clean_eps(eps_rim4)\n",
    "p = cleaned['pos']\n",
    "a = cleaned['activ']    \n",
    "for n in range(4):\n",
    "    i = n // 2\n",
    "    j = (n % 2) + 2\n",
    "    heatmap = gaussian_smooth(p, a[:,n])\n",
    "    ax[i, j].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c26d6-9eac-4bb7-b535-89e876f30e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = pplt.subplots(nrows=2, ncols=4, wspace=(0, 5, 0), hspace=0)\n",
    "\n",
    "cleaned = clean_eps(eps_rimcopy4, activations_key='actor_activations', activations_layer=0)\n",
    "p = cleaned['pos']\n",
    "a = cleaned['activ']\n",
    "for n in range(4):\n",
    "    i = n // 2    \n",
    "    j = n % 2\n",
    "    heatmap = gaussian_smooth(p, a[:,n])\n",
    "    ax[i, j].imshow(heatmap, extent=(5, 295, 5, 295))\n",
    "    \n",
    "cleaned = clean_eps(eps_rim4, activations_key='actor_activations', activations_layer=0)\n",
    "p = cleaned['pos']\n",
    "a = cleaned['activ']    \n",
    "for n in range(4):\n",
    "    i = n // 2\n",
    "    j = (n % 2) + 2\n",
    "    heatmap = gaussian_smooth(p, a[:,n])\n",
    "    ax[i, j].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1e6eaa-a9c4-40cc-bfbf-9eb3134678c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = pplt.subplots(nrows=2, ncols=4, wspace=(0, 5, 0), hspace=0)\n",
    "\n",
    "cleaned = clean_eps(eps_rimcopy4, activations_key='actor_activations', activations_layer=1)\n",
    "p = cleaned['pos']\n",
    "a = cleaned['activ']\n",
    "for n in range(4):\n",
    "    i = n // 2    \n",
    "    j = n % 2\n",
    "    heatmap = gaussian_smooth(p, a[:,n])\n",
    "    ax[i, j].imshow(heatmap, extent=(5, 295, 5, 295))\n",
    "    \n",
    "cleaned = clean_eps(eps_rim4, activations_key='actor_activations', activations_layer=1)\n",
    "p = cleaned['pos']\n",
    "a = cleaned['activ']    \n",
    "for n in range(4):\n",
    "    i = n // 2\n",
    "    j = (n % 2) + 2\n",
    "    heatmap = gaussian_smooth(p, a[:,n])\n",
    "    ax[i, j].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b58bd2c-4289-4889-8c27-24913034e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = clean_eps(eps_copy4)\n",
    "p = cleaned['pos']\n",
    "a = cleaned['activ']\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=2, ncols=2)\n",
    "for i in range(4):\n",
    "    heatmap = gaussian_smooth(p, a[:, i])\n",
    "    ax[i].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db81e8b2-23b7-4ee7-89ed-0e61311c020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = clean_eps(eps_rim64, prune_first=0)\n",
    "p = cleaned['pos']\n",
    "plt.scatter(p.T[0], p.T[1], alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6507b4f9-abec-4472-9967-6feb044882bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute directedness of trajectories from all_ep_rim64. There are 7 trajectories that do not use the direct approach out of 116\n",
    "\n",
    "goal_loc = np.array([250, 70])\n",
    "\n",
    "directnesses = []\n",
    "for i in range(len(all_ep_rim64)):\n",
    "    p = np.vstack(all_ep_rim64[i]['data']['pos'])\n",
    "    d = p - goal_loc\n",
    "    d = np.sqrt(np.sum(d**2, axis=1))\n",
    "    dist_changes = np.diff(d)\n",
    "    directness = np.sum(dist_changes[:-1] < 0) / np.sum(dist_changes[:-1] != 0)\n",
    "    directnesses.append(directness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e14c8-a79f-4fbc-b392-c9d6946b1fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_idxs = np.argwhere(np.array(directnesses) < 0.9).squeeze()\n",
    "\n",
    "# ep1 = [] #non halluc\n",
    "# ep2 = [] #halluc\n",
    "# for i in range(len(all_ep_rim64)):\n",
    "#     if i in ep_idxs:\n",
    "#         ep2.append(all_ep_rim64[i])\n",
    "#     else:\n",
    "#         ep1.append(all_ep_rim64[i])\n",
    "        \n",
    "        \n",
    "ep1 = [] #non halluc\n",
    "ep2 = [] #halluc\n",
    "for i in range(len(all_ep_rimcopy4)):\n",
    "    if i in ep_idxs:\n",
    "        ep2.append(all_ep_rimcopy4[i])\n",
    "    else:\n",
    "        ep1.append(all_ep_rimcopy4[i])\n",
    "        \n",
    "ep1 = clean_eps(stack_all_ep(ep1), prune_first=0)\n",
    "ep2 = clean_eps(stack_all_ep(ep2), prune_first=0)\n",
    "\n",
    "fig, ax = pplt.subplots(ncols=2, nrows=2)\n",
    "ax[0].scatter(ep1['pos'].T[0], ep1['pos'].T[1], alpha=0.2)\n",
    "ax[1].scatter(ep2['pos'].T[0], ep2['pos'].T[1], alpha=0.2)\n",
    "\n",
    "heatmap = gaussian_smooth(ep1['pos'], ep1['activ'][:, 1])\n",
    "ax[2].imshow(heatmap, extent=(5, 295, 5, 295))\n",
    "heatmap = gaussian_smooth(ep2['pos'], ep2['activ'][:, 1])\n",
    "ax[3].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c36860d-3938-4130-872a-2aad08ab037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = gaussian_smooth(ep1['pos'], ep1['activ'][:, 1])\n",
    "ax[2].imshow(heatmap, extent=(5, 295, 5, 295))\n",
    "heatmap = gaussian_smooth(ep2['pos'], ep2['activ'][:, 1])\n",
    "ax[3].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c2c62-fd4a-4319-af99-f125541e1d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_idxs = np.argwhere(np.array(directnesses) < 0.9).squeeze()\n",
    "\n",
    "ep1 = [] #non halluc\n",
    "ep2 = [] #halluc\n",
    "for i in range(len(all_ep_rim64)):\n",
    "    if i in ep_idxs:\n",
    "        ep2.append(all_ep_rim64[i])\n",
    "    else:\n",
    "        ep1.append(all_ep_rim64[i])\n",
    "                \n",
    "ep1 = clean_eps(stack_all_ep(ep1), prune_first=5)\n",
    "ep2 = clean_eps(stack_all_ep(ep2), prune_first=5)\n",
    "\n",
    "fig, ax = pplt.subplots(ncols=16, nrows=8, wspace=(0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0))\n",
    "\n",
    "for n in range(64):\n",
    "    i = n // 8\n",
    "    j = n % 8\n",
    "    heatmap = gaussian_smooth(ep1['pos'], ep1['activ'][:, n])\n",
    "    ax[i, j].imshow(heatmap, extent=(5, 295, 5, 295))\n",
    "    \n",
    "for n in range(64):\n",
    "    i = n // 8\n",
    "    j = n % 8\n",
    "    heatmap = gaussian_smooth(ep2['pos'], ep2['activ'][:, n])\n",
    "    ax[i, j+8].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad4177b-6abb-40fc-8d6d-c3e6c1950efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_idxs = np.argwhere(np.array(directnesses) < 0.9).squeeze()\n",
    "\n",
    "ep1 = [] #non halluc\n",
    "ep2 = [] #halluc\n",
    "for i in range(len(all_ep_rim64)):\n",
    "    if i in ep_idxs:\n",
    "        ep2.append(all_ep_rim64[i])\n",
    "    else:\n",
    "        ep1.append(all_ep_rim64[i])\n",
    "                \n",
    "ep1 = clean_eps(stack_all_ep(ep1), prune_first=0)\n",
    "ep2 = clean_eps(stack_all_ep(ep2), prune_first=0)\n",
    "\n",
    "fig, ax = pplt.subplots(ncols=16, nrows=8, wspace=(0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0))\n",
    "\n",
    "for n in range(64):\n",
    "    i = n // 8\n",
    "    j = n % 8\n",
    "    heatmap = gaussian_smooth(ep1['pos'], ep1['activ'][:, n])\n",
    "    ax[i, j].imshow(heatmap, extent=(5, 295, 5, 295))\n",
    "    \n",
    "for n in range(64):\n",
    "    i = n // 8\n",
    "    j = n % 8\n",
    "    heatmap = gaussian_smooth(ep2['pos'], ep2['activ'][:, n])\n",
    "    ax[i, j+8].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954292e2-a5a6-41a8-94c3-ac985299fb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_idxs = np.argwhere(np.array(directnesses) < 0.9).squeeze()\n",
    "        \n",
    "        \n",
    "ep1 = [] #non halluc\n",
    "ep2 = [] #halluc\n",
    "for i in range(len(all_ep_rimcopy4)):\n",
    "    if i in ep_idxs:\n",
    "        ep2.append(all_ep_rimcopy4[i])\n",
    "    else:\n",
    "        ep1.append(all_ep_rimcopy4[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce6c7ed-0eb9-4eb5-995d-a3a973c3259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots()\n",
    "ax.format(xlim=[0, 300], ylim=[0, 300])\n",
    "for i in range(len(ep2)):\n",
    "    p = np.vstack(ep2[i]['data']['pos'])\n",
    "    angle = ep2[i]['data']['angle']\n",
    "    draw_character(p[0], angle[0], ax=ax)\n",
    "    ax.plot(p.T[0], p.T[1])\n",
    "    \n",
    "draw_box(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d7602c-1496-400e-91e3-97edb98bfa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b654d4fd-80d3-4420-8030-235cc730e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(nrows=2, ncols=4)\n",
    "ax.format(xlim=[0, 300], ylim=[0, 300])\n",
    "for i in range(len(ep2)):\n",
    "    p = np.vstack(ep2[i]['data']['pos'])\n",
    "    angle = ep2[i]['data']['angle']\n",
    "    for j in range(p.shape[0]):\n",
    "        draw_character(p[j], angle[j], ax=ax[i])\n",
    "    ax[i].plot(p.T[0], p.T[1])\n",
    "    draw_box(ax=ax[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65db7a3e-f292-4d63-915e-54e6f68d4efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "goal_loc = np.array([250, 70])\n",
    "\n",
    "directnesses4 = []\n",
    "for i in range(len(all_ep_rim4)):\n",
    "    p = np.vstack(all_ep_rim4[i]['data']['pos'])\n",
    "    d = p - goal_loc\n",
    "    d = np.sqrt(np.sum(d**2, axis=1))\n",
    "    dist_changes = np.diff(d)\n",
    "    directness = np.sum(dist_changes[:-1] < 0) / np.sum(dist_changes[:-1] != 0)\n",
    "    directnesses4.append(directness)\n",
    "    \n",
    "ep_idxs = np.argwhere(np.array(directnesses4) < 0.9).squeeze()\n",
    "        \n",
    "    \n",
    "ep1 = [] #non halluc\n",
    "ep2 = [] #halluc\n",
    "for i in range(len(all_ep_rimcopy64)):\n",
    "    if i in ep_idxs:\n",
    "        ep2.append(all_ep_rimcopy64[i])\n",
    "    else:\n",
    "        ep1.append(all_ep_rimcopy64[i])\n",
    "        \n",
    "    \n",
    "fig, ax = pplt.subplots(nrows=5, ncols=5)\n",
    "\n",
    "ax.format(xlim=[0, 300], ylim=[0, 300])\n",
    "for i in range(len(ep2)):\n",
    "    p = np.vstack(ep2[i]['data']['pos'])\n",
    "    angle = ep2[i]['data']['angle']\n",
    "    for j in range(p.shape[0]):\n",
    "        draw_character(p[j], angle[j], ax=ax[i])\n",
    "    ax[i].plot(p[:-1].T[0], p[:-1].T[1])\n",
    "    draw_box(ax=ax[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5890eb0e-0ced-41e0-91e9-47290ad67619",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420c97d2-8766-443a-a0c8-ca609541aa61",
   "metadata": {},
   "source": [
    "### Computing hallucination rates in 4 -> 64 forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516a2c24-060e-42e2-966a-95aca43669aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute directedness of trajectories from all_ep_rim64. There are 7 trajectories that do not use the direct approach out of 116\n",
    "\n",
    "goal_loc = np.array([250, 70])\n",
    "\n",
    "directnesses4 = []\n",
    "for i in range(len(all_ep_rim4)):\n",
    "    p = np.vstack(all_ep_rim4[i]['data']['pos'])\n",
    "    d = p - goal_loc\n",
    "    d = np.sqrt(np.sum(d**2, axis=1))\n",
    "    dist_changes = np.diff(d)\n",
    "    directness = np.sum(dist_changes[:-1] < 0) / np.sum(dist_changes[:-1] != 0)\n",
    "    directnesses4.append(directness)\n",
    "    \n",
    "ep_idxs = np.argwhere(np.array(directnesses4) < 0.9).squeeze()\n",
    "        \n",
    "        \n",
    "ep1 = [] #non halluc\n",
    "ep2 = [] #halluc\n",
    "for i in range(len(all_ep_rimcopy64)):\n",
    "    if i in ep_idxs:\n",
    "        ep2.append(all_ep_rimcopy64[i])\n",
    "    else:\n",
    "        ep1.append(all_ep_rimcopy64[i])\n",
    "        \n",
    "ep1 = clean_eps(stack_all_ep(ep1), prune_first=0)\n",
    "ep2 = clean_eps(stack_all_ep(ep2), prune_first=0)\n",
    "\n",
    "fig, ax = pplt.subplots(ncols=2, nrows=3)\n",
    "ax[0].plot(ep1['pos'][:-1].T[0], ep1['pos'][:-1].T[1], alpha=0.2, c='blue2')\n",
    "ax[1].plot(ep2['pos'][:-1].T[0], ep2['pos'][:-1].T[1], alpha=0.2, c='blue2')\n",
    "\n",
    "heatmap1 = gaussian_smooth(ep1['pos'], ep1['activ'][:, 58])\n",
    "ax[2].imshow(heatmap1, extent=(5, 295, 5, 295))\n",
    "heatmap2, hasval2 = gaussian_smooth(ep2['pos'], ep2['activ'][:, 58], ret_hasval=True)\n",
    "ax[3].imshow(heatmap2, extent=(5, 295, 5, 295))\n",
    "\n",
    "heatmap1 = gaussian_smooth(ep1['pos'], ep1['activ'][:, 33])\n",
    "ax[4].imshow(heatmap1, extent=(5, 295, 5, 295))\n",
    "heatmap2, hasval2 = gaussian_smooth(ep2['pos'], ep2['activ'][:, 33], ret_hasval=True)\n",
    "ax[5].imshow(heatmap2, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a23cb9b-7410-46b3-a95d-ab66e0a108b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "halucination_diffs = []\n",
    "for i in range(64):\n",
    "    heatmap1 = gaussian_smooth(ep1['pos'], ep1['activ'][:, i])\n",
    "    heatmap2, hasval2 = gaussian_smooth(ep2['pos'], ep2['activ'][:, i], ret_hasval=True)\n",
    "\n",
    "    idxs = hasval2 == 1\n",
    "    halucination_diffs.append(np.sum(np.abs(heatmap1[idxs] - heatmap2[idxs])) / np.sum(idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a9441e-8e2e-4340-9697-71a7ff7c6884",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(halucination_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198c05a4-4c47-48c4-b055-c616c8dbe070",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(halucination_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8058a50f-47ba-4628-94bc-7ea15d232e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "halucination_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570b79ba-be6c-48cd-bd23-4874bfde1d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(ncols=16, nrows=8, wspace=(0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0))\n",
    "\n",
    "\n",
    "#direct path non forced\n",
    "\n",
    "goal_loc = np.array([250, 70])\n",
    "\n",
    "directnesses = []\n",
    "for i in range(len(all_ep_rim64)):\n",
    "    p = np.vstack(all_ep_rim64[i]['data']['pos'])\n",
    "    d = p - goal_loc\n",
    "    d = np.sqrt(np.sum(d**2, axis=1))\n",
    "    dist_changes = np.diff(d)\n",
    "    directness = np.sum(dist_changes[:-1] < 0) / np.sum(dist_changes[:-1] != 0)\n",
    "    directnesses.append(directness)\n",
    "ep_idxs = np.argwhere(np.array(directnesses) < 0.9).squeeze()\n",
    "\n",
    "ep1 = [] #non halluc\n",
    "ep2 = [] #halluc\n",
    "for i in range(len(all_ep_rim64)):\n",
    "    if i in ep_idxs:\n",
    "        ep2.append(all_ep_rim64[i])\n",
    "    else:\n",
    "        ep1.append(all_ep_rim64[i])\n",
    "                \n",
    "ep1 = clean_eps(stack_all_ep(ep1), prune_first=0)\n",
    "ep2 = clean_eps(stack_all_ep(ep2), prune_first=0)\n",
    "\n",
    "for n in range(64):\n",
    "    i = n // 8\n",
    "    j = n % 8\n",
    "    heatmap = gaussian_smooth(ep1['pos'], ep1['activ'][:, n])\n",
    "    ax[i, j].imshow(heatmap, extent=(5, 295, 5, 295))\n",
    "\n",
    "    \n",
    "    \n",
    "#direct path 4->64 forced    \n",
    "directnesses4 = []\n",
    "for i in range(len(all_ep_rim4)):\n",
    "    p = np.vstack(all_ep_rim4[i]['data']['pos'])\n",
    "    d = p - goal_loc\n",
    "    d = np.sqrt(np.sum(d**2, axis=1))\n",
    "    dist_changes = np.diff(d)\n",
    "    directness = np.sum(dist_changes[:-1] < 0) / np.sum(dist_changes[:-1] != 0)\n",
    "    directnesses4.append(directness)\n",
    "    \n",
    "ep_idxs = np.argwhere(np.array(directnesses4) < 0.9).squeeze()\n",
    "ep1 = [] #non halluc\n",
    "ep2 = [] #halluc\n",
    "for i in range(len(all_ep_rimcopy64)):\n",
    "    if i in ep_idxs:\n",
    "        ep2.append(all_ep_rimcopy64[i])\n",
    "    else:\n",
    "        ep1.append(all_ep_rimcopy64[i])\n",
    "        \n",
    "ep1 = clean_eps(stack_all_ep(ep1), prune_first=0)\n",
    "ep2 = clean_eps(stack_all_ep(ep2), prune_first=0)\n",
    "for n in range(64):\n",
    "    i = n // 8\n",
    "    j = n % 8\n",
    "    heatmap = gaussian_smooth(ep1['pos'], ep1['activ'][:, n])\n",
    "    ax[i, j+8].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c329a-1635-4876-aa76-ecc10cac2db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(ncols=16, nrows=8, wspace=(0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0))\n",
    "\n",
    "\n",
    "#direct path non forced\n",
    "\n",
    "goal_loc = np.array([250, 70])\n",
    "\n",
    "directnesses = []\n",
    "for i in range(len(all_ep_rim64)):\n",
    "    p = np.vstack(all_ep_rim64[i]['data']['pos'])\n",
    "    d = p - goal_loc\n",
    "    d = np.sqrt(np.sum(d**2, axis=1))\n",
    "    dist_changes = np.diff(d)\n",
    "    directness = np.sum(dist_changes[:-1] < 0) / np.sum(dist_changes[:-1] != 0)\n",
    "    directnesses.append(directness)\n",
    "ep_idxs = np.argwhere(np.array(directnesses) < 0.9).squeeze()\n",
    "\n",
    "ep1 = [] #non halluc\n",
    "ep2 = [] #halluc\n",
    "for i in range(len(all_ep_rim64)):\n",
    "    if i in ep_idxs:\n",
    "        ep2.append(all_ep_rim64[i])\n",
    "    else:\n",
    "        ep1.append(all_ep_rim64[i])\n",
    "                \n",
    "ep1 = clean_eps(stack_all_ep(ep1), prune_first=0)\n",
    "ep2 = clean_eps(stack_all_ep(ep2), prune_first=0)\n",
    "\n",
    "for n in range(64):\n",
    "    i = n // 8\n",
    "    j = n % 8\n",
    "    heatmap = np.clip(gaussian_smooth(ep1['pos'], ep1['activ'][:, n]), 0, 1)\n",
    "    ax[i, j].imshow(heatmap, extent=(5, 295, 5, 295), vmin=0, vmax=1)\n",
    "\n",
    "    \n",
    "    \n",
    "#direct path 4->64 forced    \n",
    "directnesses4 = []\n",
    "for i in range(len(all_ep_rim4)):\n",
    "    p = np.vstack(all_ep_rim4[i]['data']['pos'])\n",
    "    d = p - goal_loc\n",
    "    d = np.sqrt(np.sum(d**2, axis=1))\n",
    "    dist_changes = np.diff(d)\n",
    "    directness = np.sum(dist_changes[:-1] < 0) / np.sum(dist_changes[:-1] != 0)\n",
    "    directnesses4.append(directness)\n",
    "    \n",
    "ep_idxs = np.argwhere(np.array(directnesses4) < 0.9).squeeze()\n",
    "ep1 = [] #non halluc\n",
    "ep2 = [] #halluc\n",
    "for i in range(len(all_ep_rimcopy64)):\n",
    "    if i in ep_idxs:\n",
    "        ep2.append(all_ep_rimcopy64[i])\n",
    "    else:\n",
    "        ep1.append(all_ep_rimcopy64[i])\n",
    "        \n",
    "ep1 = clean_eps(stack_all_ep(ep1), prune_first=0)\n",
    "ep2 = clean_eps(stack_all_ep(ep2), prune_first=0)\n",
    "for n in range(64):\n",
    "    i = n // 8\n",
    "    j = n % 8\n",
    "    heatmap = np.clip(gaussian_smooth(ep1['pos'], ep1['activ'][:, n]), 0, 1)\n",
    "    ax[i, j+8].imshow(heatmap, extent=(5, 295, 5, 295), vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bf9b9f-feda-45ec-91e0-720b25fc6165",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'five': 5,  'six': 6}\n",
    "b = {'seven': 7}\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1e2a71-c0bd-4ab1-be9a-1d3b8d3c09d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_idxs = np.argwhere(np.array(directnesses) < 0.9).squeeze()\n",
    "        \n",
    "        \n",
    "ep1 = [] #non halluc\n",
    "ep2 = [] #halluc\n",
    "for i in range(len(all_ep_rimcopy4)):\n",
    "    if i in ep_idxs:\n",
    "        ep2.append(all_ep_rimcopy4[i])\n",
    "    else:\n",
    "        ep1.append(all_ep_rimcopy4[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc540aa2-244b-4832-9989-b9b10f7da10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_activ = [stack_activations(ep['activations'])['shared_activations'] for ep in all_ep_randact64]\n",
    "all_activ = torch.vstack([activ[0, :, :] for activ in all_activ])\n",
    "p = np.vstack([ep['data']['pos'] for ep in all_ep_randact64])\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=8, ncols=8)\n",
    "\n",
    "for i in range(64):\n",
    "    activ = all_activ[:, i]\n",
    "    heatmap = gaussian_smooth(p, activ)\n",
    "    ax[i].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d282d-b918-4e96-8cf4-1bb3042e5f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, obs_rms, kwargs = load_model_and_env(model_name, 0)\n",
    "kw = kwargs.copy()\n",
    "kw['fixed_reset'] = [points[i], angles[i]]\n",
    "ep = forced_action_evaluate(model, obs_rms, forced_actions=action_randomizer, \n",
    "                            seed=i*5, num_episodes=5, env_kwargs=kw, data_callback=poster_data_callback,\n",
    "                            with_activations=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4331a6-00ed-412c-ab30-763053fdd348",
   "metadata": {},
   "source": [
    "# Collect trajectories for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e76f516-5f53-4a41-9e43-2a1949ad136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = compute_directness(all_ep_64)\n",
    "idxs = d > 0.9\n",
    "d_ep = [ep for i, ep in enumerate(all_ep_64) if idxs[i]]\n",
    "cleaned = clean_eps(stack_all_ep(d_ep))\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=8, ncols=8)\n",
    "for i in range(64):\n",
    "    heatmap = gaussian_smooth(cleaned['pos'], cleaned['activ'][:, i])\n",
    "    ax[i].imshow(heatmap, extent=(5, 295, 5, 295))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb070d15-6c90-4d99-ab9b-7a3c877138f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned = clean_eps(stack_all_ep(all_ep_rim64), prune_first=0, save_inview=False,\n",
    "                   save_seen=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669ad7d-56bd-49ab-8e5d-7c8b07bfe63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cleaned, open('data/cleaned', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf69996-e11b-4f03-986c-6c8aedc32275",
   "metadata": {},
   "outputs": [],
   "source": [
    "widths = [2, 3, 4, 8, 16, 32, 64]\n",
    "num_trials = 3\n",
    "\n",
    "#Starting around rim - First generate start points and angles\n",
    "WINDOW_SIZE = (300, 300)\n",
    "step_size = 10.\n",
    "xs = np.arange(0+step_size, WINDOW_SIZE[0], step_size)\n",
    "ys = np.arange(0+step_size, WINDOW_SIZE[1], step_size)\n",
    "# thetas = np.linspace(0, 2*np.pi, 12, endpoint=False)\n",
    "start_points = []\n",
    "start_angles = []\n",
    "for x in xs:\n",
    "    for y in [5., 295.]:\n",
    "        point = np.array([x, y])\n",
    "        angle = np.arctan2(150 - y, 150 - x)\n",
    "        start_points.append(point)\n",
    "        start_angles.append(angle)\n",
    "for y in ys:\n",
    "    for x in [5, 295]:\n",
    "        point = np.array([x, y])\n",
    "        angle = np.arctan2(150 - y, 150 - x)\n",
    "        start_points.append(point)\n",
    "        start_angles.append(angle)\n",
    "        \n",
    "start_points = np.vstack(start_points)\n",
    "\n",
    "\n",
    "def filter_all_ep_directness(all_ep, bound=0.9):\n",
    "    d = compute_directness(all_ep)\n",
    "    idxs = d > 0.9\n",
    "    d_ep = [ep for i, ep in enumerate(all_ep) if idxs[i]]\n",
    "    return d_ep\n",
    "\n",
    "for width in tqdm(widths):\n",
    "    for trial in range(num_trials):\n",
    "        model_name = f'nav_poster_netstructure/nav_pdistal_width{width}batch200'\n",
    "        model, obs_rms, kwargs = load_model_and_env(model_name, trial)\n",
    "\n",
    "        all_ep = []\n",
    "        for i in range(len(start_points)):\n",
    "            kw = kwargs.copy()\n",
    "            kw['fixed_reset'] = [start_points[i].copy(), start_angles[i].copy()]\n",
    "            ep = forced_action_evaluate(model, obs_rms, seed=0, num_episodes=1, \n",
    "                                        env_kwargs=kw, data_callback=poster_data_callback,\n",
    "                                        with_activations=True)\n",
    "            all_ep.append(ep)\n",
    "        \n",
    "        all_ep_f = filter_all_ep_directness(all_ep)\n",
    "        eps_f = clean_eps(stack_all_ep(all_ep_f), prune_first=0, save_inview=False, save_seen=False)\n",
    "        eps = clean_eps(stack_all_ep(all_ep), prune_first=0, save_inview=False, save_seen=False)\n",
    "        \n",
    "        pickle.dump(eps, open(f'data/pdistal_rim_heatmap/width{width}_t{trial}', 'wb'))\n",
    "        pickle.dump(eps_f, open(f'data/pdistal_rim_heatmap/width{width}_filt_t{trial}', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
