{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import gym\n",
    "import gym_nav\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from a2c_ppo_acktr import algo, utils\n",
    "from a2c_ppo_acktr.algo import gail\n",
    "from a2c_ppo_acktr.arguments import get_args\n",
    "from a2c_ppo_acktr.envs import make_vec_envs\n",
    "from a2c_ppo_acktr.model import Policy\n",
    "from a2c_ppo_acktr.storage import RolloutStorage\n",
    "from evaluation import evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andy\\miniconda3\\lib\\site-packages\\gym\\wrappers\\record_video.py:42: UserWarning: \u001b[33mWARN: Overwriting existing videos at C:\\Users\\Andy\\Desktop\\Work\\github\\training-rl-algo\\video folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  f\"Overwriting existing videos at {self.video_folder} folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updates 80, num timesteps 405, FPS 70 \n",
      " Last 2 training episodes: mean/median reward 0.2/0.2, min/max reward 0.1/0.2\n",
      "\n",
      "Updates 90, num timesteps 455, FPS 70 \n",
      " Last 2 training episodes: mean/median reward 0.2/0.2, min/max reward 0.1/0.2\n",
      "\n",
      "Updates 100, num timesteps 505, FPS 66 \n",
      " Last 2 training episodes: mean/median reward 0.2/0.2, min/max reward 0.1/0.2\n",
      "\n",
      "Updates 110, num timesteps 555, FPS 66 \n",
      " Last 2 training episodes: mean/median reward 0.2/0.2, min/max reward 0.1/0.2\n",
      "\n",
      "Updates 120, num timesteps 605, FPS 65 \n",
      " Last 3 training episodes: mean/median reward 0.2/0.1, min/max reward 0.1/0.2\n",
      "\n",
      "Updates 130, num timesteps 655, FPS 66 \n",
      " Last 3 training episodes: mean/median reward 0.2/0.1, min/max reward 0.1/0.2\n",
      "\n",
      "Updates 140, num timesteps 705, FPS 64 \n",
      " Last 3 training episodes: mean/median reward 0.2/0.1, min/max reward 0.1/0.2\n",
      "\n",
      "Updates 150, num timesteps 755, FPS 65 \n",
      " Last 3 training episodes: mean/median reward 0.2/0.1, min/max reward 0.1/0.2\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-91fceb628d54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0malg\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'ppo'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mvalue_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist_entropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapprox_kl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclipfracs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrollouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Work\\github\\training-rl-algo\\a2c_ppo_acktr\\algo\\ppo.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, rollouts)\u001b[0m\n\u001b[0;32m     87\u001b[0m                     \u001b[0mvalue_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mreturn_batch\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m                 (value_loss * self.value_loss_coef + action_loss -\n\u001b[0;32m     91\u001b[0m                  dist_entropy * self.entropy_coef).backward()\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_zero_grad_profile_name\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hook_for_profile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_zero_grad_profile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\autograd\\profiler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    611\u001b[0m         \u001b[1;31m# Stores underlying RecordFunction as a tensor. TODO: move to custom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;31m# class (https://github.com/pytorch/pytorch/issues/35026).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 613\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env_name = 'Gridworld-v0'\n",
    "log_dir = '/tmp/gym'\n",
    "device = torch.device(\"cpu\")\n",
    "alg = 'ppo'\n",
    "log_interval = 10\n",
    "\n",
    "value_loss_coef = 0.5\n",
    "entropy_coef = 0.01\n",
    "gamma = 0.99\n",
    "lr = 7e-4\n",
    "eps = 1e-5\n",
    "alpha = 0.99\n",
    "max_grad_norm = 0.5\n",
    "\n",
    "clip_param = 0.2\n",
    "ppo_epoch = 4\n",
    "num_mini_batch = 1\n",
    "\n",
    "num_env_steps = 10000\n",
    "num_steps = 5\n",
    "num_processes = 1\n",
    "\n",
    "use_gae = False\n",
    "gae_lambda = 0.95\n",
    "use_proper_time_limits = False\n",
    "\n",
    "env = gym.make(env_name)\n",
    "envs = make_vec_envs(env_name, 0, 1, gamma, log_dir, device, False, capture_video=1, \n",
    "                     env_kwargs={'reward_shaping': 2})\n",
    "\n",
    "actor_critic = Policy(\n",
    "    envs.observation_space.shape,\n",
    "    envs.action_space,\n",
    "    base_kwargs={'recurrent': True})\n",
    "actor_critic.to(device)\n",
    "\n",
    "if alg == 'a2c':\n",
    "        agent = algo.A2C_ACKTR(\n",
    "            actor_critic,\n",
    "            value_loss_coef,\n",
    "            entropy_coef,\n",
    "            lr=lr,\n",
    "            eps=eps,\n",
    "            alpha=alpha,\n",
    "            max_grad_norm=max_grad_norm)\n",
    "elif alg == 'ppo':\n",
    "    agent = algo.PPO(\n",
    "        actor_critic,\n",
    "        clip_param,\n",
    "        ppo_epoch,\n",
    "        num_mini_batch,\n",
    "        value_loss_coef,\n",
    "        entropy_coef,\n",
    "        lr=lr,\n",
    "        eps=eps,\n",
    "        max_grad_norm=max_grad_norm)\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "rollouts = RolloutStorage(num_steps, num_processes,\n",
    "                          envs.observation_space.shape, envs.action_space,\n",
    "                          actor_critic.recurrent_hidden_state_size)\n",
    "\n",
    "obs = envs.reset()\n",
    "rollouts.obs[0].copy_(obs)\n",
    "rollouts.to(device)\n",
    "\n",
    "episode_rewards = deque(maxlen=10)\n",
    "\n",
    "start = time.time()\n",
    "num_updates = int(\n",
    "    num_env_steps) // num_steps // num_processes\n",
    "for j in range(num_updates):\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        #Andy: add global step\n",
    "        global_step += 1 * num_processes\n",
    "        # Sample actions\n",
    "        with torch.no_grad():\n",
    "            value, action, action_log_prob, recurrent_hidden_states = actor_critic.act(\n",
    "                rollouts.obs[step], rollouts.recurrent_hidden_states[step],\n",
    "                rollouts.masks[step])\n",
    "\n",
    "        # Obser reward and next obs\n",
    "        obs, reward, done, infos = envs.step(action)\n",
    "\n",
    "        for info in infos:\n",
    "            if 'episode' in info.keys():\n",
    "                episode_rewards.append(info['episode']['r'])\n",
    "\n",
    "        # If done then clean the history of observations.\n",
    "        masks = torch.FloatTensor(\n",
    "            [[0.0] if done_ else [1.0] for done_ in done])\n",
    "        bad_masks = torch.FloatTensor(\n",
    "            [[0.0] if 'bad_transition' in info.keys() else [1.0]\n",
    "             for info in infos])\n",
    "        rollouts.insert(obs, recurrent_hidden_states, action,\n",
    "                        action_log_prob, value, reward, masks, bad_masks)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        next_value = actor_critic.get_value(\n",
    "            rollouts.obs[-1], rollouts.recurrent_hidden_states[-1],\n",
    "            rollouts.masks[-1]).detach()\n",
    "        \n",
    "    rollouts.compute_returns(next_value, use_gae, gamma,\n",
    "                             gae_lambda, use_proper_time_limits)\n",
    "\n",
    "    if alg == 'ppo':\n",
    "        value_loss, action_loss, dist_entropy, approx_kl, clipfracs = \\\n",
    "        agent.update(rollouts)\n",
    "\n",
    "    else:\n",
    "        value_loss, action_loss, dist_entropy = agent.update(rollouts)\n",
    "\n",
    "    rollouts.after_update()\n",
    "\n",
    "    if j % log_interval == 0 and len(episode_rewards) > 1:\n",
    "        total_num_steps = (j + 1) * num_processes * num_steps\n",
    "        end = time.time()\n",
    "        print(\n",
    "            \"Updates {}, num timesteps {}, FPS {} \\n Last {} training episodes: mean/median reward {:.1f}/{:.1f}, min/max reward {:.1f}/{:.1f}\\n\"\n",
    "            .format(j, total_num_steps,\n",
    "                    int(total_num_steps / (end - start)),\n",
    "                    len(episode_rewards), np.mean(episode_rewards),\n",
    "                    np.median(episode_rewards), np.min(episode_rewards),\n",
    "                    np.max(episode_rewards), dist_entropy, value_loss,\n",
    "                    action_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Gridworld-v0', reward_shaping=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 6., 1., 1.]), 1.01, True, {})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.7.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('NavEnv-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.95582287, 0.        , 0.        , 0.9598488 ,\n",
       "       0.        , 0.        , 0.96304543, 0.        , 0.        ,\n",
       "       0.96558575, 0.        , 0.        , 0.96768114, 0.        ,\n",
       "       0.        , 0.96937654, 0.        , 0.        , 0.970787  ,\n",
       "       0.        , 0.        , 0.9719262 , 0.        , 0.        ,\n",
       "       0.97285759, 0.        , 0.        , 0.973612  , 0.        ,\n",
       "       0.        , 0.97419547, 0.        , 0.        , 0.97463541,\n",
       "       0.        , 0.        , 0.97494144, 0.        , 0.        ,\n",
       "       0.97512074, 0.        , 0.        , 0.97517719, 0.        ,\n",
       "       0.        , 0.9751127 , 0.        , 0.        , 0.97492507,\n",
       "       0.        , 0.        , 0.97461037, 0.        , 0.        ,\n",
       "       0.9741612 , 0.        , 0.        , 0.97356778, 0.        ,\n",
       "       0.        , 0.97280149, 0.        , 0.        , 0.97185712,\n",
       "       0.        , 0.        , 0.97070304, 0.        , 0.        ,\n",
       "       0.9692735 , 0.        , 0.        , 0.96755628, 0.        ,\n",
       "       0.        , 0.96543209, 0.        , 0.        , 0.96282361,\n",
       "       0.        , 0.        , 0.95961254, 0.        , 0.        ,\n",
       "       0.95552181, 0.        , 0.        , 0.95020434, 0.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "import math\n",
    "\n",
    "MAX_MARCH = 20\n",
    "EPSILON = 0.1\n",
    "DEG_TO_RAD = 0.0174533\n",
    "WINDOW_SIZE = (200, 300) # Width x Height in pixels\n",
    "MAX_DIST = np.linalg.norm(WINDOW_SIZE)\n",
    "\n",
    "object_to_idx = {\n",
    "    'wall': 1,\n",
    "    'goal': 2\n",
    "}\n",
    "color_to_idx = {\n",
    "    'invisible': 0,\n",
    "    'red': 1,\n",
    "    'green': 2,\n",
    "    'blue': 3,\n",
    "    'yellow': 4,\n",
    "    'purple': 5,\n",
    "    'white': 6\n",
    "}\n",
    "idx_to_rgb = {\n",
    "    1: np.array([230, 0, 0]),\n",
    "    2: np.array([0, 230, 0]),\n",
    "    3: np.array([0, 0, 230]),\n",
    "    4: np.array([230, 230, 0]),\n",
    "    5: np.array([230, 0, 230]),\n",
    "    6: np.array([230, 230, 230])\n",
    "}\n",
    "\n",
    "def generate_box(pos=None, size=[10, 25], inside_window=True, color=1, is_goal=False):\n",
    "    '''\n",
    "    Generate a box with width and height drawn randomly uniformly from size[0] to size[1]\n",
    "    if inside_window is True, we force the box to stay inside the window\n",
    "    '''\n",
    "    box_size = np.random.uniform([size[0], size[0]], [size[1], size[1]])\n",
    "    if pos is None:\n",
    "        if inside_window:\n",
    "            pos = np.random.uniform([box_size[0], box_size[1]], \n",
    "                                     [WINDOW_SIZE[0] - box_size[0], WINDOW_SIZE[1] - box_size[1]])\n",
    "        else:\n",
    "            pos = np.random.uniform(WINDOW_SIZE)\n",
    "            \n",
    "    if inside_window:\n",
    "        return Box(pos, box_size, color=color, is_goal=is_goal)\n",
    "    else:\n",
    "        return Box(pos, box_size, color=color, is_goal=is_goal)\n",
    "\n",
    "def generate_circle(pos=None, radius=[10, 25], inside_window=True, color=1, is_goal=False):\n",
    "    circ_rad = np.random.uniform(radius[0], radius[1])\n",
    "    if pos is None:\n",
    "        if inside_window:\n",
    "            pos = np.random.uniform([circ_rad, circ_rad], [WINDOW_SIZE[0]-circ_rad, WINDOW_SIZE[1]-circ_rad])\n",
    "        else:\n",
    "            pos = np.random.uniform(WINDOW_SIZE)\n",
    "    \n",
    "    if inside_window:\n",
    "        return Circle(pos, circ_rad, color=color, is_goal=is_goal)\n",
    "    else:\n",
    "        return Circle(pos, circ_rad, color=color, is_goal=is_goal)\n",
    "\n",
    "def generate_boxes(num_boxes=5, size=[10, 25], is_goal=False, inside_window=True, color=1):\n",
    "    centers = []\n",
    "    sizes = []\n",
    "    boxes = []\n",
    "    for i in range(num_boxes):\n",
    "        box = generate_box(size=size, color=color, is_goal=is_goal, inside_window=inside_window)\n",
    "        centers.append(box.center)\n",
    "        sizes.append(box.size)\n",
    "        boxes.append(box)\n",
    "        \n",
    "    centers = np.array(centers)\n",
    "    sizes = np.array(sizes)\n",
    "    return boxes, centers, sizes\n",
    "\n",
    "def generate_circles(num_circles=5, radius=[10, 25], is_goal=False, inside_window=True, color=1):\n",
    "    centers = []\n",
    "    radii = []\n",
    "    circles = []\n",
    "    for i in range(num_circles):\n",
    "        circle = generate_circle(radius=radius, color=color, is_goal=is_goal, inside_window=inside_window)\n",
    "        centers.append(circle.center)\n",
    "        radii.append(circle.radius)\n",
    "        circles.append(circle)\n",
    "        \n",
    "    centers = np.array(centers)\n",
    "    radii = np.array(radii)\n",
    "    return circles, centers, radii\n",
    "\n",
    "\n",
    "def reset_objects():\n",
    "    '''reset global object lists to be populated'''\n",
    "    items = ['boxes', 'box_centers', 'box_sizes', 'circles', 'circle_centers',\n",
    "            'circle_radii', 'objects']\n",
    "    \n",
    "    for item in items:\n",
    "        globals()[item] = []\n",
    "    \n",
    "\n",
    "def add_box(box):\n",
    "    '''add box to global boxes object for computation'''\n",
    "    globals()['boxes'].append(box)\n",
    "    \n",
    "    if len(globals()['box_centers']) > 0:\n",
    "        globals()['box_centers'] = np.vstack([box_centers, np.array([box.center])])\n",
    "        globals()['box_sizes'] = np.vstack([box_sizes, np.array([box.size])])\n",
    "    else:\n",
    "        globals()['box_centers'] = np.array([box.center])\n",
    "        globals()['box_sizes'] = np.array([box.size])\n",
    "    globals()['objects'] = globals()['boxes'] + globals()['circles']\n",
    "    \n",
    "    \n",
    "def add_circle(circle):\n",
    "    '''add circle to global circles object for computation'''\n",
    "    globals()['circles'].append(circle)\n",
    "    if len(globals()['circle_centers']) > 0:\n",
    "        globals()['circle_centers'] = np.vstack([circle_centers, np.array([circle.center])])\n",
    "        globals()['circle_radii'] = np.vstack([circle_radii, np.array([circle.radius])])\n",
    "    else:\n",
    "        globals()['circle_centers'] = np.array([circle.center])\n",
    "        globals()['circle_radii'] = np.array([circle.radius])\n",
    "\n",
    "    globals()['objects'] = globals()['boxes'] + globals()['circles']\n",
    "    \n",
    "    \n",
    "def add_walls():\n",
    "    add_box(Box(np.array([0, 0]), np.array([1, WINDOW_SIZE[1]]), color=1))\n",
    "    add_box(Box(np.array([0, 0]), np.array([WINDOW_SIZE[0], 1]), color=1))\n",
    "    add_box(Box(np.array([0, WINDOW_SIZE[1]]), np.array([WINDOW_SIZE[0], 1]), color=1))\n",
    "    add_box(Box(np.array([WINDOW_SIZE[0], 0]), np.array([1, WINDOW_SIZE[1]]), color=1))\n",
    "\n",
    "    \n",
    "\n",
    "def spaced_random_pos(sep=5):\n",
    "    '''\n",
    "    Find a spot that has a minimum separation from other objects in the scene\n",
    "    '''\n",
    "    while True:\n",
    "        pos = np.random.uniform(WINDOW_SIZE)\n",
    "        if scene_sdf(pos)[0] > sep:\n",
    "            return pos\n",
    "\n",
    "\n",
    "\n",
    "def generate_world(num_objects=5, min_goal_sep=15, color=1):\n",
    "    reset_objects()\n",
    "    '''generate obstacles'''\n",
    "    boxes, box_centers, box_sizes = generate_boxes(num_objects, inside_window=False, color=color)\n",
    "    circles, circle_centers, circle_radii = generate_circles(num_objects, inside_window=False, color=color)\n",
    "    \n",
    "    globals()['boxes'] = boxes\n",
    "    globals()['box_centers'] = box_centers\n",
    "    globals()['box_sizes'] = box_sizes\n",
    "    globals()['circles'] = circles\n",
    "    globals()['circle_centers'] = circle_centers\n",
    "    globals()['circle_radii'] = circle_radii\n",
    "    globals()['objects'] = boxes + circles\n",
    "    \n",
    "    #create walls around screen:\n",
    "    add_walls()\n",
    "\n",
    "    #create a goal, require it to be at least 30 units away from player\n",
    "    searching = True\n",
    "    while searching:\n",
    "        pos = np.random.uniform(WINDOW_SIZE)\n",
    "        if scene_sdf(pos)[0] > min_goal_sep:\n",
    "            #position is okay\n",
    "            searching = False\n",
    "            \n",
    "#     pos = np.array([500, 500])\n",
    "    goal = generate_box(pos=pos, size=[15, 15], is_goal=True, color=6)\n",
    "    globals()['goal'] = goal\n",
    "    add_box(goal)\n",
    "\n",
    "\n",
    "    \n",
    "def block_view_world(character, block_size=25, randomize_heading=0):\n",
    "    '''\n",
    "    Create a setting where the goal is perfectly blocked by a block\n",
    "    randomize_heading:\n",
    "        0 - always fixed\n",
    "        1 - randomize headings but point agent in the right direction\n",
    "        2 - randomize headings and point agent in random direction\n",
    "    '''\n",
    "#     print('call block view world')\n",
    "    \n",
    "    reset_objects()\n",
    "    \n",
    "    boxes, box_centers, box_sizes = generate_boxes(0)\n",
    "    circles, circle_centers, circle_radii = generate_circles(0)\n",
    "    \n",
    "    #add a single block in the center of the screen\n",
    "    add_box(Box(np.array([WINDOW_SIZE[0]/2, WINDOW_SIZE[1]/2]),\n",
    "               np.array([block_size, block_size]), color=2))\n",
    "    add_walls()\n",
    "    \n",
    "    base_size = 15\n",
    "    base_x = 150\n",
    "    base_y = 100\n",
    "    base_radius = 88\n",
    "    if randomize_heading > 0:\n",
    "        angle = np.random.uniform(6.28)\n",
    "        x = np.cos(angle) * base_radius\n",
    "        y = np.sin(angle) * base_radius\n",
    "        goal = Box(np.array([x + base_x, y + base_y]), np.array([base_size, base_size]), \n",
    "            is_goal=True, color=6)\n",
    "        globals()['goal'] = goal\n",
    "        add_box(goal)\n",
    "        \n",
    "        angle2 = angle + 3.14\n",
    "        x = np.cos(angle2) * base_radius\n",
    "        y = np.sin(angle2) * base_radius\n",
    "        character.pos = np.array([x + base_x, y + base_y])\n",
    "        \n",
    "        if randomize_heading > 1:\n",
    "            character.angle = np.random.uniform(6.28)\n",
    "        else:\n",
    "            character.angle = angle\n",
    "            \n",
    "        character.update_rays()\n",
    "        \n",
    "    else:\n",
    "        #add the goal\n",
    "        goal = Box(np.array([WINDOW_SIZE[0] - 50, WINDOW_SIZE[1]/2]),\n",
    "                   np.array([base_size, base_size]),\n",
    "                   is_goal=True, color=6)\n",
    "        globals()['goal'] = goal\n",
    "        add_box(goal)\n",
    "\n",
    "        #set the agent position\n",
    "        character.pos = np.array([50, WINDOW_SIZE[1]/2])\n",
    "        character.angle = 0\n",
    "        \n",
    "        character.update_rays()\n",
    "\n",
    "def dist(v):\n",
    "    '''calculate length of vector'''\n",
    "    return np.linalg.norm(v)\n",
    "\n",
    "def scene_sdf(p):\n",
    "#     closest_sdf = np.inf\n",
    "#     closest = None\n",
    "#     for obj in objects:\n",
    "#         obj.draw()\n",
    "        \n",
    "#         sdf = obj.sdf(p)\n",
    "#         if sdf < closest_sdf:\n",
    "#             closest_sdf = sdf\n",
    "#             closest = obj\n",
    "#     return closest_sdf, closest\n",
    "    box_dists = box_sdfs(p)\n",
    "    circle_dists = circle_sdfs(p)\n",
    "    \n",
    "    dists = np.append(box_dists, circle_dists)\n",
    "    min_dist = np.min(dists)\n",
    "    obj_index = np.argmin(dists)\n",
    "    \n",
    "    #find which object sdf was closest to\n",
    "    \n",
    "    \n",
    "    return np.min(dists), (boxes + circles)[obj_index]\n",
    "#     return box_dists, circle_dists\n",
    "\n",
    "\n",
    "def box_sdfs(p):\n",
    "    '''\n",
    "    compute all the sdf functions for boxes using global variables\n",
    "    box_centers\n",
    "    box_sizes\n",
    "    both are m x 2 arrays with each row representing a box\n",
    "    '''\n",
    "    if len(box_centers) > 0:\n",
    "        offset = np.abs(p - box_centers) - box_sizes\n",
    "        unsigned_dist = np.linalg.norm(np.clip(offset, 0, np.inf), axis=1)\n",
    "        dist_inside_box = np.max(np.clip(offset, -np.inf, 0), axis=1)\n",
    "        dists = unsigned_dist + dist_inside_box\n",
    "        return dists\n",
    "    else:\n",
    "        return np.array([])\n",
    "\n",
    "\n",
    "def circle_sdfs(p):\n",
    "    '''\n",
    "    compute all the sdf functions for circles using global variables\n",
    "    circle_centers (m x 2 array)\n",
    "    circle_radii   (m x 1 array)\n",
    "    both arrays are 2 dimensional\n",
    "    '''\n",
    "    if len(circle_centers) > 0:\n",
    "        return np.linalg.norm((circle_centers - p), axis=1) - circle_radii\n",
    "    else:\n",
    "        return np.array([])\n",
    "    \n",
    "\n",
    "class Circle():\n",
    "    def __init__(self, center, radius, color=1, is_goal=False):\n",
    "        self.center = center\n",
    "        self.radius = radius\n",
    "        self.color = color\n",
    "        self.is_goal = is_goal\n",
    "    \n",
    "    def sdf(self, p):\n",
    "        return dist(self.center - p) - self.radius\n",
    "    \n",
    "    def draw(self):\n",
    "        draw_color = idx_to_rgb[self.color]\n",
    "        pygame.draw.circle(display, draw_color, self.center, self.radius)\n",
    "        \n",
    "\n",
    "class Box():\n",
    "    def __init__(self, center, size, color=1, is_goal=False):\n",
    "        self.center = center\n",
    "        self.size = size #this is a size 2 array for length and height\n",
    "        self.color = color\n",
    "        self.rect = pygame.Rect(center-size, size*2)\n",
    "        self.is_goal = is_goal\n",
    "        \n",
    "    def sdf(self, p):\n",
    "        offset = np.abs(p-self.center) - self.size\n",
    "        unsigned_dist = dist(np.clip(offset, 0, np.inf))\n",
    "        dist_inside_box = np.max(np.clip(offset, -np.inf, 0))\n",
    "        return unsigned_dist + dist_inside_box\n",
    "    \n",
    "    def draw(self):\n",
    "        draw_color = idx_to_rgb[self.color]\n",
    "        pygame.draw.rect(display, draw_color, self.rect)\n",
    "        \n",
    "        \n",
    "class Ray():\n",
    "    def __init__(self, start, angle, color=6, render_march=False):\n",
    "        '''\n",
    "        Ray for ray marching\n",
    "        if render_march is True, then we render the sdf circles used to calculate march \n",
    "        '''\n",
    "        self.start = start\n",
    "        self.angle = angle\n",
    "        self.color = color\n",
    "        self.render_march = render_march\n",
    "        self.touched_obj = None\n",
    "        self.obj_dist = np.inf\n",
    "        \n",
    "    def update(self, start=None, angle=None):\n",
    "        '''\n",
    "        update position and angle, perform march, determine object and distance\n",
    "        '''\n",
    "        if start is not None:\n",
    "            self.start = start\n",
    "        if angle is not None:\n",
    "            self.angle = angle\n",
    "        self.march()\n",
    "        \n",
    "    def march(self):\n",
    "        '''\n",
    "        perform ray march, find collision with object\n",
    "        '''\n",
    "        depth = 0\n",
    "        p = self.start\n",
    "        for i in range(MAX_MARCH):\n",
    "            dist, obj = scene_sdf(p)\n",
    "            depth += dist\n",
    "            \n",
    "            if self.render_march:\n",
    "                pygame.draw.circle(display, (255, 255, 255, 0.3), p, dist, width=1)\n",
    "\n",
    "            if dist < EPSILON:\n",
    "                self.touched_obj = obj\n",
    "                self.obj_dist = depth\n",
    "                return depth, obj\n",
    "            else:\n",
    "                p = p + np.array([np.cos(self.angle), np.sin(self.angle)]) * dist\n",
    "                \n",
    "        self.touched_obj = obj\n",
    "        self.obj_dist = depth\n",
    "        return depth, obj\n",
    "    \n",
    "    def draw(self):\n",
    "        end = self.start + np.array([np.cos(self.angle), np.sin(self.angle)]) * self.obj_dist\n",
    "        draw_color = idx_to_rgb[self.color]\n",
    "        pygame.draw.line(display, draw_color, self.start, end)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "class Character:\n",
    "    def __init__(self, pos=[WINDOW_SIZE[0]/2, WINDOW_SIZE[1]/2], angle=0, color=4, size=5,\n",
    "                fov=120*DEG_TO_RAD, num_rays=30, render_rays=True):\n",
    "        '''\n",
    "        Generate a character that can move through the window\n",
    "        pos: starting position\n",
    "        angle: starting angle (radians) angle always takes on values from -pi to pi\n",
    "        color: color\n",
    "        size: size\n",
    "        fov: range of angles character can see using rays\n",
    "        num_rays: fidelity of depth perception\n",
    "        draw_rays: whether or not to draw the characters rays\n",
    "        '''\n",
    "        self.pos = pos\n",
    "        self.angle = (angle + np.pi) % (2*np.pi) - np.pi\n",
    "        self.color = color\n",
    "        self.size = size\n",
    "        self.fov = fov\n",
    "        self.ray_splits = fov / num_rays\n",
    "        self.render_rays = render_rays\n",
    "        self.num_rays = num_rays\n",
    "        \n",
    "        self.rays = []\n",
    "        \n",
    "        fov_start = self.angle - self.fov/2\n",
    "        for i in range(num_rays):\n",
    "            self.rays.append(Ray(self.pos, fov_start + i*self.ray_splits))\n",
    "            \n",
    "#         print(len(self.rays))\n",
    "#         print(self.num_rays)\n",
    "    \n",
    "    \n",
    "    def update_rays(self):\n",
    "        '''\n",
    "        update the angle of the rays using own position and angle\n",
    "        '''\n",
    "        fov_start = self.angle - self.fov/2\n",
    "        for i in range(self.num_rays):\n",
    "            self.rays[i].update(start=self.pos, angle=fov_start + i*self.ray_splits)\n",
    "            \n",
    "            \n",
    "    def draw_rays(self):\n",
    "        '''\n",
    "        draw the rays coming from character\n",
    "        '''\n",
    "        for ray in self.rays:\n",
    "            ray.draw()\n",
    "        \n",
    "    \n",
    "    def draw(self):\n",
    "        '''\n",
    "        draw the character\n",
    "        '''\n",
    "        point1 = [self.pos[0] - (math.cos(self.angle+0.3))*self.size, \n",
    "                  self.pos[1] - (math.sin(self.angle+0.3))*self.size]\n",
    "        point2 = [self.pos[0] - math.cos(self.angle)*self.size*.8, self.pos[1] - math.sin(self.angle)*self.size*.8]\n",
    "        point3 = [self.pos[0] - (math.cos(self.angle-0.3))*self.size, \n",
    "                  self.pos[1] - (math.sin(self.angle-0.3))*self.size]\n",
    "\n",
    "        draw_color = idx_to_rgb[self.color]\n",
    "        pygame.draw.polygon(\n",
    "            display,\n",
    "            draw_color,\n",
    "            [self.pos, point1, point2, point3, self.pos]\n",
    "        )\n",
    "        if self.render_rays:\n",
    "            self.draw_rays()\n",
    "        \n",
    "        \n",
    "    def move(self, speed=0.5):\n",
    "        '''\n",
    "        move in the faced direction with number of pixels of speed\n",
    "        collision detection uses the same ray marching algorithm\n",
    "        after moving, update the rays\n",
    "        '''\n",
    "        collide_with_object = self.march_collision_detection(speed)\n",
    "        if collide_with_object is False:\n",
    "            self.pos[0] += math.cos(self.angle) * speed\n",
    "            self.pos[1] += math.sin(self.angle) * speed\n",
    "            \n",
    "        else:\n",
    "            #collided with object, move with the given depth\n",
    "            dist_to_obj = collide_with_object[0]\n",
    "            self.pos[0] += math.cos(self.angle) * dist_to_obj\n",
    "            self.pos[1] += math.sin(self.angle) * dist_to_obj\n",
    "\n",
    "        self.update_rays()\n",
    "        return collide_with_object\n",
    "            \n",
    "            \n",
    "    def march_collision_detection(self, max_dist):\n",
    "        '''\n",
    "        perform ray march, used for collision detection. The max_dist is the speed we are\n",
    "        moving at. If the max_dist exceeds the sdf (i.e., we are colliding with an object), \n",
    "        then return the distance to the collided object\n",
    "        \n",
    "        If sdf exceeds max_dist, then we have not collided on our path, so return False \n",
    "        (i.e., no object hit)\n",
    "        \n",
    "        returns:\n",
    "            False - if no object collided with\n",
    "            dist, obj - if colliding with an object, return the distance that we are allowed to \n",
    "                travel and the object\n",
    "        '''\n",
    "        depth = 0\n",
    "        p = self.pos\n",
    "        for i in range(MAX_MARCH):\n",
    "            dist, obj = scene_sdf(p)\n",
    "            \n",
    "            if dist < EPSILON:    \n",
    "                #we have collided before passing the requisite distance\n",
    "                return depth-2*EPSILON, obj\n",
    "            \n",
    "            if depth + dist > max_dist:\n",
    "                #we have enough room to move on the desired path\n",
    "                return False\n",
    "            \n",
    "            else:\n",
    "                #we continue the march\n",
    "                depth += dist\n",
    "                p = p + np.array([np.cos(self.angle), np.sin(self.angle)]) * dist\n",
    "            \n",
    "        return depth, obj\n",
    "    \n",
    "        \n",
    "    def rotate(self, angle=0.05):\n",
    "        self.angle += angle\n",
    "        self.angle = (self.angle + np.pi) % (2*np.pi) - np.pi\n",
    "        self.update_rays()\n",
    "        \n",
    "    \n",
    "    def ray_obs(self, max_depth=MAX_DIST):\n",
    "        '''\n",
    "        Get all rays and their distances to objects\n",
    "        normalize_depth: divide depth readings by value \n",
    "        '''\n",
    "        ray_colors = []\n",
    "        ray_depths = []\n",
    "        for ray in self.rays:\n",
    "#             ray_colors.append(colors_dict[ray.touched_obj.color])\n",
    "            ray_colors.append(ray.touched_obj.color)\n",
    "            ray_depths.append(ray.obj_dist)\n",
    "            \n",
    "#         if normalize_depth:\n",
    "#             ray_depths = np.array(ray_depths) / normalize_depth\n",
    "#         else:\n",
    "#             ray_depths = np.array(ray_depths)\n",
    "            \n",
    "        # ray_colors = np.array(ray_colors)\n",
    "        ray_colors = np.array(ray_colors) / 6\n",
    "        ray_depths = np.array(ray_depths) / max_depth\n",
    "        visual = np.append(ray_colors, ray_depths)\n",
    "#         background_colors = np.full(ray_colors.shape, 0)\n",
    "        # ray_depths = np.clip(ray_depths, 0, max_depth) / 1000\n",
    "        # visual = (1 - ray_depths.reshape(-1, 1)) * ray_colors / 255\n",
    "        \n",
    "#         return ray_depths, ray_colors\n",
    "        return visual\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def randomize_location_and_angle(character, sep=True):\n",
    "    '''\n",
    "    create a random location and start direction for the character\n",
    "    noting that we do not allow spawning into objects\n",
    "    sep: if set to True, we will make sure character has a minimum distance away\n",
    "        from the goal that is at least half the max distance possible from goal\n",
    "        to end of window\n",
    "    '''\n",
    "\n",
    "    #max distance from goal to end of window\n",
    "    max_goal_sep = dist(np.max([np.array(WINDOW_SIZE) - goal.center, goal.center], axis=0)) \n",
    "    sep = True\n",
    "    searching = True\n",
    "    while searching:\n",
    "        pos = np.random.uniform(WINDOW_SIZE)\n",
    "        goal_sep = dist(globals()['goal'].center - pos)\n",
    "\n",
    "        if scene_sdf(pos)[0] > 0 and (not sep or goal_sep > max_goal_sep / 2):\n",
    "            #position is okay\n",
    "            searching = False\n",
    "            \n",
    "    character.pos = pos\n",
    "    character.angle = np.random.uniform(6.28)\n",
    "#     character.pos = np.array([100, 100])\n",
    "#     character.angle = 0\n",
    "\n",
    "    character.update_rays()\n",
    "\n",
    "\n",
    "class NavEnv(gym.Env):\n",
    "    metadata = {\"render.modes\": ['rgb_array', 'human'], 'video.frames_per_second': 24}\n",
    "    def __init__(self, num_rays=30, max_steps=200, num_objects=5,\n",
    "                rew_structure='dist', give_heading=0, verbose=0,\n",
    "                world_gen_func=None, world_gen_params={}, give_dist=True,\n",
    "                give_time=False, collission_penalty=0, default_reward=0,\n",
    "                sub_goal_reward=0.01):\n",
    "        '''\n",
    "        rew_structure: 'dist' - reward given based on distance to goal\n",
    "                        'goal' - reward only given when goal reached\n",
    "        give_heading: whether to additionally give a distance and direction to goal\n",
    "        flat: whether to give observations in a flattened state\n",
    "        world_gen_func: a function can be passed to manually create a world\n",
    "            using some other rules. Note that it needs to generate objects, a goal, and\n",
    "            set the agent position and heading\n",
    "            The character will be passed as the argument\n",
    "        '''\n",
    "        super(NavEnv, self).__init__()\n",
    "\n",
    "        if 'pygame' not in globals():\n",
    "            global pygame\n",
    "            import pygame\n",
    "\n",
    "\n",
    "        self.total_rewards = 0\n",
    "        self.give_dist = give_dist\n",
    "        self.give_heading = give_heading\n",
    "        self.give_time = give_time\n",
    "        self.collission_penalty = collission_penalty\n",
    "        self.default_reward = default_reward\n",
    "        self.sub_goal_reward = sub_goal_reward\n",
    "        observation_width = num_rays\n",
    "        if give_dist:\n",
    "            observation_width = observation_width * 2\n",
    "        if give_heading:\n",
    "            observation_width += 1\n",
    "        if give_time:\n",
    "            observation_width += 1\n",
    "\n",
    "        self.observation_space = spaces.Box(low=0, high=6, shape=(observation_width,))\n",
    "        self.action_space = spaces.Discrete(4) #turn left, forward, right as actions\n",
    "        \n",
    "        self.max_steps = max_steps\n",
    "        self.current_steps = 0\n",
    "        \n",
    "        self.character = Character()\n",
    "        \n",
    "        self.num_objects = num_objects\n",
    "        \n",
    "        self.rew_structure = rew_structure\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.world_gen_func = world_gen_func\n",
    "        self.world_gen_params = world_gen_params\n",
    "        \n",
    "        if self.world_gen_func is None:\n",
    "            generate_world(self.num_objects)\n",
    "            randomize_location_and_angle(self.character)\n",
    "        else:\n",
    "            self.world_gen_func(self.character, **self.world_gen_params)\n",
    "        \n",
    "        \n",
    "    def step(self, action):\n",
    "        reward = self.default_reward\n",
    "        collide_with_object = False\n",
    "        done = False\n",
    "        info = {}\n",
    "        \n",
    "        if action == 0:\n",
    "            self.character.rotate(-0.2)\n",
    "        if action == 1:\n",
    "            collide_with_object = self.character.move(10)\n",
    "        if action == 2:\n",
    "            self.character.rotate(0.2)\n",
    "        if action == 3:\n",
    "            pass\n",
    "\n",
    "        if self.rew_structure == 'dist':\n",
    "            goal = objects[-1]\n",
    "            dist_to_goal = self.sub_goal_reward * \\\n",
    "                (MAX_DIST-dist(goal.center - self.character.pos)) / MAX_DIST\n",
    "            reward = float(dist_to_goal)\n",
    "\n",
    "            \n",
    "        if collide_with_object is not False:\n",
    "            obj = collide_with_object[1]\n",
    "            if obj.is_goal:\n",
    "                if self.verbose:\n",
    "                    print('goal reached!')\n",
    "                reward = float(1)\n",
    "                done = True\n",
    "            else:\n",
    "#                 reward = -10\n",
    "                reward = float(self.collission_penalty)\n",
    "        \n",
    "        \n",
    "        observation = self.get_observation()\n",
    "        \n",
    "        if self.current_steps > self.max_steps:\n",
    "            done = True\n",
    "        \n",
    "        self.current_steps += 1\n",
    "        self.total_rewards += reward\n",
    "        if done and self.verbose:\n",
    "            print('done, total_reward:{}'.format(self.total_rewards))\n",
    "        return observation, reward, done, info\n",
    "    \n",
    "    def reset(self):\n",
    "        if self.world_gen_func is None:\n",
    "            generate_world(self.num_objects)\n",
    "            randomize_location_and_angle(self.character)\n",
    "        else:\n",
    "            self.world_gen_func(self.character, **self.world_gen_params)\n",
    "        \n",
    "        observation = self.get_observation()\n",
    "        self.current_steps = 0\n",
    "        self.total_rewards = 0\n",
    "        return observation\n",
    "    \n",
    "    def render(self, mode='rgb_array'):\n",
    "        if 'screen' not in globals() or str(screen) == '<Surface(Dead Display)>':\n",
    "            pygame.init()\n",
    "            if mode == 'human':\n",
    "                globals()['screen'] = pygame.display.set_mode(WINDOW_SIZE)\n",
    "            globals()['display'] = pygame.Surface(WINDOW_SIZE)\n",
    "\n",
    "        display.fill((0, 0, 0))\n",
    "        \n",
    "        self.character.draw()\n",
    "        for obj in objects:\n",
    "            obj.draw()\n",
    "\n",
    "        if mode == 'human':\n",
    "            screen.blit(display, (0, 0))\n",
    "            pygame.display.update()\n",
    "            \n",
    "        if mode == 'rgb_array':\n",
    "            return pygame.surfarray.pixels3d(display)\n",
    "        \n",
    "    def close(self):\n",
    "        pygame.quit()\n",
    "        \n",
    "    def get_observation(self):\n",
    "#         ray_depths, ray_colors = self.character.ray_obs()\n",
    "#         return np.append(ray_depths, ray_colors)\n",
    "\n",
    "        if self.give_heading > 0:\n",
    "            raise NotImplementedError('Have not adjusted give_heading code')\n",
    "            #tell where the goal is distance and heading\n",
    "            ray_obs = self.character.ray_obs()\n",
    "            goal = objects[-1]\n",
    "            dist_to_goal = np.clip(dist(goal.center - self.character.pos), 0, 1000) / 1000\n",
    "            heading = goal.center - self.character.pos\n",
    "            heading = np.arctan2(heading[1], heading[0])\n",
    "\n",
    "            if self.give_heading == 1:\n",
    "                #only give distance to goal\n",
    "                obs = np.vstack([ray_obs, [dist_to_goal, 0, 0]])\n",
    "            elif self.give_heading == 2:\n",
    "                #give distance and angle to goal\n",
    "                obs = np.vstack([ray_obs, [dist_to_goal, heading/3.14, 0]])\n",
    "            elif self.give_heading == 3:\n",
    "                #give distance and angle to goal and current agent angle\n",
    "                obs = np.vstack([ray_obs, [dist_to_goal, heading/3.14, self.character.angle]])\n",
    "            \n",
    "                        \n",
    "            return np.array(obs.reshape(-1), dtype='float')\n",
    "            \n",
    "        else:\n",
    "            obs = self.character.ray_obs()\n",
    "            if not self.give_dist:\n",
    "                obs = obs[:self.num_rays]\n",
    "\n",
    "            return np.array(self.character.ray_obs().reshape(-1), dtype='float')\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = NavEnv(max_steps=400, num_objects=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.7.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('NavEnv-v0', num_objects=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.02707118, 0.02721037, 0.0274874 , 0.02790592, 0.02847622,\n",
       "       0.02921031, 0.03015199, 0.03129686, 0.03268758, 0.03436222,\n",
       "       0.03648832, 0.0389935 , 0.04219157, 0.04617605, 0.05124423,\n",
       "       0.05784866, 0.06672085, 0.07959162, 0.09889656, 0.13120415,\n",
       "       0.1890837 , 0.30574502, 0.42723422, 0.42839614, 0.43167386,\n",
       "       0.43714719, 0.44495105, 0.45529545, 0.46848417, 0.48486797])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.66666667e-01, 1.66666667e-01, 1.66666667e-01, 1.66666667e-01,\n",
       "        1.66666667e-01, 1.66666667e-01, 1.66666667e-01, 1.66666667e-01,\n",
       "        1.66666667e-01, 1.66666667e-01, 1.66666667e-01, 1.66666667e-01,\n",
       "        1.66666667e-01, 1.66666667e-01, 1.66666667e-01, 1.66666667e-01,\n",
       "        1.66666667e-01, 1.66666667e-01, 1.66666667e-01, 1.66666667e-01,\n",
       "        1.66666667e-01, 1.66666667e-01, 1.66666667e-01, 1.66666667e-01,\n",
       "        1.66666667e-01, 1.66666667e-01, 1.66666667e-01, 1.66666667e-01,\n",
       "        1.66666667e-01, 1.66666667e-01, 5.51159293e-01, 5.26293949e-01,\n",
       "        5.05889556e-01, 4.88860036e-01, 3.79023313e-01, 1.69084818e-01,\n",
       "        7.40370401e-02, 3.25489080e-02, 1.48684355e-02, 7.36463094e-03,\n",
       "        1.97503722e-03, 1.27857964e-03, 9.58782697e-04, 8.91235260e-04,\n",
       "        6.59780110e-04, 6.33990854e-04, 6.09009711e-04, 5.84958387e-04,\n",
       "        5.61954058e-04, 5.40108799e-04, 5.19529037e-04, 5.00315035e-04,\n",
       "        4.82560402e-04, 4.66351636e-04, 4.51767706e-04, 4.38879663e-04,\n",
       "        4.27750296e-04, 4.18433827e-04, 4.10975643e-04, 4.05412082e-04]),\n",
       " 0.0,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27093ae0d08>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(env.render('rgb_array'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[230,   0,   0],\n",
       "        [230,   0,   0],\n",
       "        [230,   0,   0],\n",
       "        ...,\n",
       "        [230,   0,   0],\n",
       "        [230,   0,   0],\n",
       "        [230,   0,   0]],\n",
       "\n",
       "       [[230,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [230,   0,   0]],\n",
       "\n",
       "       [[230,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [230,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[230,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [230,   0,   0]],\n",
       "\n",
       "       [[230,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [230,   0,   0]],\n",
       "\n",
       "       [[230,   0,   0],\n",
       "        [230,   0,   0],\n",
       "        [230,   0,   0],\n",
       "        ...,\n",
       "        [230,   0,   0],\n",
       "        [230,   0,   0],\n",
       "        [230,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.render('rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'human'\n",
    "if 'screen' not in globals() or str(screen) == '<Surface(Dead Display)>':\n",
    "    pygame.init()\n",
    "    if mode == 'human':\n",
    "        globals()['screen'] = pygame.display.set_mode(WINDOW_SIZE)\n",
    "    globals()['display'] = pygame.Surface(WINDOW_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "       98.64370723, 97.26853498, 96.39374863, 95.99860189, 96.07072341,\n",
       "       58.05068572, 39.08013016, 28.75914627, 22.80238769, 18.91153736,\n",
       "       16.28422912, 14.3462254 , 12.86950078, 11.71465436, 10.79097765,\n",
       "       10.07365134,  9.4618022 ,  8.98366215,  8.58577818,  8.24702462,\n",
       "        7.98516018,  7.77277992,  7.6058523 ,  7.48093676,  7.39478317,\n",
       "        7.34688928,  7.33466526,  7.35817069,  7.41729104,  7.51603498])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22e85b75308>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbPElEQVR4nO3de7hVdZ3H8feXI3C8oICgIpBcolTKQWP0YQjC0lQqsUjC0UTHojR8lCkVdZzUsMkUzceywlSYqVDGMWNGazS7OE6iYJJCRxQEh1tcRFIDuX7nj986ssV99j7svS577f15Pc9+zj5rr/Vb38U6fM46v7XWb5m7IyIi+dEh6wJERGTvKLhFRHJGwS0ikjMKbhGRnFFwi4jkjIJbRCRnEgtuMzvVzBab2RIzm5LUekREGo0lcR23mTUBLwInAyuBecBZ7v6n2FcmItJgkjriPh5Y4u4vu/s24F5gTELrEhFpKPsk1G5vYEXB9yuBE9qauauZ90qoEBGRPFoDbHK3Yp8lFdzFVvaOPhkzmwhMBDgMWA1sTagYEalNvwI6Zl1EzO4A7quyjc7A4SU+Tyq4VwJ9C77vQ8jmt7n7dGA6wFFm/hoKbhHJvx1Un2VFD7MLJNXHPQ8YZGb9zawTMB6Yk9C6REQaSiJH3O6+w8wmAf8NNAF3u/uiJNYlItJokuoqwd0fBh5Oqn0RkUalOydFRHJGwS0ikjMKbhGRnFFwi4jkjIJbRCRnFNwiIjmj4BYRyZnEruMWyZPbgGOLTH8d+GTKtYiUo+CWhvWfhNt6AbpQfLCj7rzzLrLPApsTrkukHAW3NJT9iEY2A3rQvsF8uhd8/yNgF3A94UkhIllQH7c0jB7At4D3Rq9yoV3MgGjZy4Hj4itNZK/U5BH32LFjGThwYKY13HzzzezatSvTGiQeRxP6qfcnPJopDh8AzgdOAp4DfhlTuyLtUZPBPWzYMD784Q9nWsMtt9yi4K4DHwTGER5+Gre/jV5HAtuBxxJYh0gxNRncko5OwIisi2iHucBfK1z2b0kmtAsdTXigqoJb0qLgbmAHADdkXUQ7jKey4O4NHBpzLW05ABgEvJTS+qSx6eSk1KXuwEWEI+E0HA18k/R+UUhj0xG31KXrgaEpr7MvMAM4LeX15tlm6i+Etqewjnr7NxOp6DK/uNfvGdeQF6dkXUBOVdxVYmZ9zew3ZtZiZovM7JJo+rVmtsrMFkSv0fGVK1LeLOBDGa27K/C7jNYtjaOaI+4dwFfd/Q9m1gV4xswejT671d1vrr48kcpkddSd9dG+NIaKg9vd1wBrovdvmFkL4US+iNSonxMuA93T/wJTU65FKhdLH7eZ9SMMrvYUMByYZGbnAvMJR+WvxbEekXKmA4dnXENHQnfN35N9X3c34I6C73tSvH/0RGBw9P4twl2hUruqvhzQzA4A/gO41N1fB74PDASGEI7Ip7Wx3EQzm29m8zdVW4RI5AiKH1GmyYB+ZN9t0odwiWL/gldb/+H3L5jnfcB3UqhPKldVcJtZR0Jo/8TdHwBw97XuvtPddwF30sbwEO4+3d2HuvvQrtUUISLvMgiYRPExxstpAk4AprB72FupLdVcVWLAXUCLu99SML1XwWyfBhZWXp6I7K2jCN00o6pow4AzgAlAc/UlScyq6eMeDnweeN7MFkTTrgLOMrMhhO695cCXqliHiOyF9wNnEt9NQBOB14BHgTdjalOqV81VJU9QvBvv4SLTRCRhRxCOpE6Kud0rCCcsnwDeiLltqYzGKpG6soZ0bjkuxYHVpHtFSU/gH4k/tFt9HfgI4QlCkj0Ft9SV84BVGdewHRhLusF9E+GEYpL+Cd2iXisU3CIiOaPgFhHJGQW31J2zgWcyWvcm4KMpr/MBwtUkafgacGFK65K2Kbil7uwku1vNnTD6Wpr2Ib27NJtQaNQC7QOpS98AfpvyOlcCX0x5ndKYFNxSl9YCPwD+K6X1vUC4ZG5lSuuTxqbglrq1nHA9dRpeBxaltC4RBbfUtWdJvstkMfCLhNchUkjPnJS69izhZOFmwtClH4mx7QWEI/pnyTa4fwOcChyUwroWErqFJFsKbql7z0evnoQHCxwTQ5svEobGnBdDW9W6Ffgb0gnuh4DHUliPlKauEmkY64HJwIroVcklg6uiZW+gNkJbGpOOuKWh/JUw7CmE7o3W/wD7Uvw/g/PO4UzPjdqoNZsJY6R0TGEdkj0FtzSswjGrb6f402JeB0anU05VLiI8pmwUyfwZvZMw2P7cBNqWvafgFgEuzrqAGFwFXAqMT6Dtc4GlCbQrlVEft0gduY34H/T7KRTataYmj7ivueYampqyfUzpjh1pjzghUj0nPL17I3B9DO2NJjy6TGpLTQb3li1bsi5BJLe2A/8DXA58u8I2dgGfI/wCkNpTVXCb2XLCY+h2AjvcfaiZdQfuA/oR7joe5+76pV2DXicM0WnA90hmhLmthH7Xavw5hjoazRbC5YpXAv+yl8u27rMVMdck8TH3ygfAjIJ7qLtvKJj2bWCju3/LzKYA3dz9ilLtHGXmywg/MJKN35PMCY/NpD8+tezWmXf++19F8UsGW4DZ0fsdhKe6S3aaCUe+Le5Fj6eS6CoZQ7gqCWAmYaiIksEtIsnYyjtvxz+EMKb2nl5Bd0TmSbXB7cAjZubAD919OnCou68BcPc1ZnZIsQXNbCIwEeCwKosQkfaZmXUBEotqg3u4u6+OwvlRM2v3+DNRyE+H0FWiTnARkfapqlvT3VdHX9cBPwOOB9aaWS+A6Ou6aosUEZHdKg5uM9vfzLq0vgc+Thj1cQ4wIZptAvDzaosUEZHdqukqORT4mZm1tvNTd/+lmc0DZpvZBcD/sXtMHxERiUHFwe3uLxOGAd5z+qvAx6opSkRE2qaxSkREckbBLSKSMwpuEZGcUXCLiOSMgltEJGcU3CIiOaPgFhHJGQW3iEjOKLhFRHJGwS0ikjMKbhGRnFFwi4jkjIJbRCRnFNwiIjmTxMOCRSTHOgOzyszzv8C0FGqR4hTcIgJAP+Bqwp/hh5eZ9+PAkcCrwJRky5IiFNwiDW44cBpwIPDBdi5zUDTvFmAq4MA1iVQnxSi4RRrUJwhH2UcDH6qwjX2BkwjB/edo2l3AW9UWJyVVHNxm9n7gvoJJA4B/BroCXwTWR9OvcveHK12PiMTvo8BZwHtjas+Az0fvNxGeGP5GTG3Lu1XzzMnFwBAAM2sCVgE/A84HbnX3m+MoUETidRzwFaB3Qu1fDLwJ/Bb4S0LraHRxdZV8DFjq7q9ET30XkRrUH7gB6Jbweq6Mvv4aHXknIa7gHs87ryCaZGbnAvOBr7r7a3suYGYTgYkAh8VUhFTuNcKfu3FTX2ft6AbMIFzul4Yrgf2ABwknMSU+5u7VNWDWCVgNDHb3tWZ2KLCBcL7iG0Avd/+HUm0cZebLgK1VVSIipTxJMr+cy5kB/CCD9eZZM+HEcYt70V0Wx52TpwF/cPe1AO6+1t13uvsu4E7g+BjWISJVyLIDU52n8YsjuM+ioJvEzHoVfPZpYGEM6xCRCjUT7nTMKkDPBa7LaN31qqo+bjPbDzgZ+FLB5G+b2RBCV8nyPT4TkQxkOSiRoaPuuFXdxx0H9XGLJKM7cA9waMZ1bAHmsvtqEyktjT5uEalRTWQf2hDusOyedRF1RMEtUqcOp7YGgDoC+FrWRdQJBbdInepCGECqVnQFhmVdRJ1QcIuI1JDm5mbOOOOMkvMouEVEakiXLl249JJLSs6j4BYRqRGdO3emb9++LFmypOR8Go9bRKRG9OvXj2uvvZZxp59OvxLz6YhbRCRnFNwiIjmj4BYRqQEjRoxgypQpfOELX+DXv/51yXkV3CJ16kXgs1kXUeB54O+zLqLGmRnuTocyD6RRcIvUKae2xv/ZRW3VU4sGDhzItGnT+OyZZ5acT8EtUsdeIzy5O2tPEh6ZJsWdfPLJjBw5kqlTp9K1a1c2bNhQcn4Ft0gd2wG8lHURhOdO/l/WRdSwbt26MWzYMIYOHcrtt9/O1KlTS86v4Bapc9uB7xC6TrLwNPCLjNadJz169GD48OEceeSRLFiwoOS8Cm6ROrcTuDfD9f+J0FUixQ0ZMoRjjz2WVatWMX/+fE4++WTuv//+kssouEUaxOOEEE/Ti4THYEnbRo0axYknnsimTZt4+umnWbBgAcOHlx7XUcEt0iCuABYR+r3TsAK4C/hlSuvLu8GDB3POOecwZ84cJkyYUHLessFtZneb2TozW1gwrbuZPWpmL0VfuxV8dqWZLTGzxWZ2SlVbIg2lA9CzjVfHDOuqJxOBpSQf3hsJV5H8LuH15N2BBx7IvvvuC8DWrVs56KCDuO6667jqqqtKLteeI+4ZwKl7TJsCPObug4DHou8xs6OB8cDgaJk7zKxpL7ZDGlAHwjP2+gL/2cbr+GgejYpWvQlAC8l1m7wFXAgsSKj9enL11VczZswYAObNm8fll19O9+7d+fGPf1xyubLB7e6PE36BFhoDzIzezwTOKJh+r7tvdfdlwBLC/zmRogz4KPBb4L4S802L5vkiemJ4HL4I/J5wU0wcV5t41NYuQhi8EkObjcTdGT58OHfeeSfr16/ntNNOKzl/pX3ch7r7mmiFa4BDoum9CV1brVZG00Te5TJCeHxjL5Y5N1rmB4lU1FguA/4OuD2Gtjxq6++ATTG01wjuueceRo4cCcDs2bO54oorAOjZs2fqY5UUOxgq+gvdzCaa2Xwzm78p5iKk9t1IODIz9u4IunX+Y4BZ8ZfVkO4DPgJ8qYJl/xwte2KsFTUGM8OiMUnGjh3LDTeEe0s3bNjAKaeUPj1YaXCvNbNe0cp7Aeui6SsJXZWt+gCrizXg7tPdfai7D+1aYRGST98lPDS2mpMfHYD3ULp7RdpnJ2EMkUXAJ4Cx7Vjmf6J5z4+W1Rgk1dlnn33o2LEjS5YsYfLkycyaVfqwpNJzPXMI5zi+FX39ecH0n5rZLcDhwCDCjVMiQPiz/INApxjaaiIcGcwAzouhvUa3A3iV8BfN58vM+0Y0r1Tmtttuo1+/fu+a3qdPH66//noO7t695PJlg9vMZgGjgB5mthL4OiGwZ5vZBYQhCM4EcPdFZjabcLPUDuAr7p72Nf9SwwYAnWNsr4lwdCDxcWpjfJN61r9/f5qbm981vbm5mQEDBsCWLSWXLxvc7n5WGx99rI35b0ADgUkRlwL7J9CuAV8FbiVc1SCSZ2+88QZ3fe97JefRnZOSms8QrsWOWwfCn3z6YZY8GDduHPvtt1/RzzZu3MiDDz5Ip06lOxP1sy6p+AjJ/7CNRDfoSO278MILOeCAA4p+tmXLFlasWMFFF15Ysg0FtyTOCCdFkg7VbwLFj2NE8qF3795lb3cHBbeISGoOOeSQt6/drob+shQRScmDDz5Ihw7VHy/riFtEJGcU3CIiOaOuEhGRGF10EYwfv+fUTsCvYunfBh1xSwocGA1sS3g9nyLcii2SpXvugR/9CDp12vPVScEt+fJaSuvI6knmIq22bIHNm985bdu27Zxzzjm4x/MTquCW1FwGvJ5Au7uAyaT/IFyRYk4/HT7zmfB+1SqYPBkuu8zfHvlv27bq//ZUH7ek5ilgewLtOvBkAu2KVOLll+Hf/z28/8tf4MmCH865c+dy8803c/HFF9OlS5eK16HgllTdD4wDupWbsZ22oQcqSG1ZuDC82jJnzhy6devGuHHjOPjggytah7pKJFX3AA8BG2JoazPwCPD9GNoSSdPMmTN56KGHWLduXfmZi1BwS+q+CzxKdQPx/xWYC0yNpSKR9N1xxx20tLRUtKyCWzJxG+FxSavZuytO3oyWeQooPxSPSG3buHEjb7755tvfb9++nbVr15ZdTsEtmfkhYYzuGwlH0KWe+fFWNM+saBmFttSDG2+8kQceeODtK02WLVvGpEmT2FzmCTgW13WF1TjKzJehB442usOAB9r47BJgXoq1iKTpzDPPZPLkyXTo0IH169cz7vTTOcKdFveid+yUDW4zuxv4JLDO3T8QTbuJcKPaNmApcL67bzKzfkALsDhafK67f7lc0QpuEWl0I0aM4Kabbgo36bz1FuefeGKbwd2erpIZwKl7THsU+IC7HwO8CFxZ8NlSdx8SvcqGtoiIwBNPPMEFF1yAmVHuxviywe3ujwMb95j2iLvviL6dC/SprFQREQFwd1544QXOPvvssvPGcXLyH4BfFHzf38yeNbPfmdmIGNoXEWkIO3fuZPny5Uw477yS81V156SZXQ3sAH4STVoDvMfdXzWzDwEPmtlgd3/XEBVmNhGYCOGklIiIhPB+5ZVX6FdinoqPuM1sAuGk5dkeneF0963u/mr0/hnCicv3FVve3ae7+1B3H9q10iJERBpQRcFtZqcCVwCnu/vmguk9zawpej8AGAS8HEehIiISlO0qMbNZwCigh5mtBL5OuIqkM/BoNDB462V/I4HrzWwHYZTNL7v7xqINi4hIRXQDjohIjWkG+kFV13GLiEgNUXCLiOSMgltEJGcU3CIiOaPgFhHJGQW3iEjOKLhFRHJGwS0ikjMKbhGRnFFwi4jkjIJbRCRnFNwiIjmj4BYRyZmqnoAjItLIDkio3eYynyu4RUQq9AjJdVucV+IzdZWIiOSMgltEJGcU3CIiOVM2uM3sbjNbZ2YLC6Zda2arzGxB9Bpd8NmVZrbEzBab2SlJFS4i0qjac8Q9Azi1yPRb3X1I9HoYwMyOBsYDg6Nl7mh96ruIiMSjbHC7++NAe5/UPga41923uvsyYAlwfBX1iYjIHqrp455kZs9FXSndomm9gRUF86yMpomISEwqDe7vAwOBIcAaYFo0vdij5L1YA2Y20czmm9n8TRUWISLSiCoKbndf6+473X0XcCe7u0NWAn0LZu0DrG6jjenuPtTdh3atpAgRkQZVUXCbWa+Cbz8NtF5xMgcYb2adzaw/MAh4uroSRUSkUNlb3s1sFjAK6GFmK4GvA6PMbAihG2Q58CUAd19kZrOBPwE7gK+4+85EKhcRaVDmXrQLOlVHmfkyYGvWhYiI7IXfk+xYJS3uxc4b6s5JEZG8UXCLiOSMgltEJGcU3CIiOaPgFhHJGQW3iEjOKLhFRHJGwS0ikjMKbhGRnFFwi4jkjIJbRCRnFNwiIjmj4BYRyRkFt4hIzpQdj1tERIo7KaF2m4FDSnyu4BYRqdDmhNrdVeZzdZWIiOSMjrjb6TPAcWXmuQHYkkItItLY2vPMybuBTwLr3P0D0bT7gPdHs3QFNrn7EDPrB7QAi6PP5rr7l+MuOi0XEPqaAIYB7y0z/6vAtuj9r9j9jyAiEqf2HHHPAL4L/GvrBHf/XOt7M5sG/KVg/qXuPiSm+lJnwBnR+3OAffdi2c8VvO8OLAReAf4QS2UiIkHZ4Hb3x6Mj6XcxMwPGAR+Nua5MNAEnAJcTArwan4heTxG6T1qqbE9EpFW1JydHAGvd/aWCaf3N7Fkz+52Zjaiy/dTsAxwF3EL1oV3oBOBrQN8Y2xSRxlZtcJ8FzCr4fg3wHnc/FvhH4KdmdmCxBc1sopnNN7P5m6osolr7AIOAHyXU/mDCL4SuCbUvIo2l4uA2s30IF1vc1zrN3be6+6vR+2eApcD7ii3v7tPdfai7D+1aaREx6AAcA9yT8Hr6ArOBjgmvR0TqXzVH3CcBL7j7ytYJZtbTzJqi9wMIB7IvV1disk4C7khpXQcCv0lpXSJSv8oGt5nNAp4E3m9mK83sguij8byzmwRgJPCcmf0RuB/4srtvjLPgOJ0LXJfyOpuA36M7n0SkcubuWdfAUWa+DNia4jq/SrjsL6uuiy2Ei+P/mtH6RaR2NQP9gBb3otdKNOSB37WES/Wy7G/eF/gpcGiGNYhIPjXkLe/dgf2yLoIQ2k1ZFyGSsNHA2KyLaMNq4Jqsi6hAwwX3pZS/dT1NlwHfIdxhKVKPehIuia1FtXAAV4mG6yo5gXDEXSuGAQdlXYSI5ErDBbeISN41VHAfz94NGpWWYwh/ToqItEdDBfd1wGFZF1HEJODYrIsQkdxoqOAWEakHCm4RkZxRcIuI5IyCW0QkZxTcIiI5o+AWEckZBbeISM40VHBfB6zNuogivgc8m3URIpIbDRXcc4HNWRdRxB+B9VkXISK50VDBLSJSDxouuOcDr2VdRIGngdezLkJEcqXhgnsa8FLWRRT4FrA86yJEJFcaLrgBNhGe+Zi1DcDOrIsQkdypmSfgdAaKPhUzAd8kPCz4Uymtry0TCA8Lbs64DpEk1UzIFGHU5v+/zmU+r5mnvM/IuggRkRpyHm0/5b0mgtvM1hMOPjdkXUsCelCf2wX1u23arvypx207wt2LPmOlJoIbwMzmu/vQrOuIW71uF9Tvtmm78qeet62Yhjw5KSKSZwpuEZGcqaXgnp51AQmp1+2C+t02bVf+1PO2vUvN9HGLiEj71NIRt4iItEPmwW1mp5rZYjNbYmZTsq6nWma23MyeN7MFZjY/mtbdzB41s5eir92yrrMcM7vbzNaZ2cKCaW1uh5ldGe3DxWZ2SjZVt08b23atma2K9tsCMxtd8FnNb5uZ9TWz35hZi5ktMrNLoum532clti3X+6wq7p7ZC2gClgIDgE6EEU6PzrKmGLZpOdBjj2nfBqZE76cAN2ZdZzu2YyRwHLCw3HYAR0f7rjPQP9qnTVlvw15u27XA14rMm4ttA3oBx0XvuwAvRrXnfp+V2LZc77NqXlkfcR8PLHH3l919G3AvMCbjmpIwBpgZvZ8JnJFdKe3j7o8DG/eY3NZ2jAHudfet7r4MWELYtzWpjW1rSy62zd3XuPsfovdvAC1Ab+pgn5XYtrbkZtsqlXVw9wZWFHy/ktI7JA8ceMTMnjGzidG0Q919DYQfQuCQzKqrTlvbUS/7cZKZPRd1pbR2KeRu28ysH3As8BR1ts/22Daok322t7IO7mL34ef9Mpfh7n4ccBrwFTMbmXVBKaiH/fh9YCAwBFhDGAEYcrZtZnYA8B/Ape5eaqj3XG0XFN22uthnlcg6uFcCfQu+7wOszqiWWLj76ujrOuBnhD/R1ppZL4Do67rsKqxKW9uR+/3o7mvdfae77wLuZPef1rnZNjPrSAi2n7j7A9HkuthnxbatHvZZpbIO7nnAIDPrb2adgPHAnIxrqpiZ7W9mXVrfAx8HFhK2aUI02wTg59lUWLW2tmMOMN7MOptZf2AQ4eE+udEabpFPE/Yb5GTbzMyAu4AWd7+l4KPc77O2ti3v+6wqWZ8dBUYTzhIvBa7Oup4qt2UA4Wz2H4FFrdsDHAw8Rnj4zmNA96xrbce2zCL8+bmdcARzQantAK6O9uFi4LSs669g2/4NeB54jvAfv1eetg34MKE74DlgQfQaXQ/7rMS25XqfVfPSnZMiIjmTdVeJiIjsJQW3iEjOKLhFRHJGwS0ikjMKbhGRnFFwi4jkjIJbRCRnFNwiIjnz/8FcGXPgKnm8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "rgb = env.render()\n",
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360.5551275463989"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist(WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [5, 6, 7]\n",
    "b = np.array([3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7, 3, 4, 5])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(a, b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
