{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x246ac19b708>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "For some reason need to plot before finishing imports or else can't plot without crashing\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(1,1))\n",
    "plt.plot([1],[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.optim import Adam\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([-1, 4, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected parameter probs (Tensor of shape (3,)) of distribution Categorical(probs: torch.Size([3])) to satisfy the constraint Simplex(), but found invalid values:\ntensor([-0.1111,  0.4444,  0.6667])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3044/3063414632.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mCategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\distributions\\categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_events\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mbatch_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\distributions\\distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                     raise ValueError(\n\u001b[1;32m---> 56\u001b[1;33m                         \u001b[1;34mf\"Expected parameter {param} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m                         \u001b[1;34mf\"({type(value).__name__} of shape {tuple(value.shape)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m                         \u001b[1;34mf\"of distribution {repr(self)} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected parameter probs (Tensor of shape (3,)) of distribution Categorical(probs: torch.Size([3])) to satisfy the constraint Simplex(), but found invalid values:\ntensor([-0.1111,  0.4444,  0.6667])"
     ]
    }
   ],
   "source": [
    "Categorical(x).probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.nn.init.constant_(tensor: torch.Tensor, val: float) -> torch.Tensor>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init.constant_("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanditsEnv(gym.Env, utils.EzPickle):    \n",
    "    def __init__(self, num_timesteps=100, num_arms=2, reward_probabilities=np.array([0.25, 0.75]),\n",
    "                require_central_saccade=False, changing_reward_probabilities=False):\n",
    "        '''\n",
    "        Configure the multi-arm bandit environment\n",
    "        \n",
    "        num_trials: How many trials the environment should be run for\n",
    "        num_arms: How many arms there are for the bandit\n",
    "        reward_probabilities: Probability of rewarding when arm is pulled\n",
    "        require_central_saccade: At each trial, we will require a central saccade before\n",
    "            an arm can be pulled (agent must produced a central action)\n",
    "            NOT IMPLEMENTED\n",
    "        changing_reward_probabilities: If set to True, the arms may change their output\n",
    "            probabilities over time. Then reward_probabilities should be a size\n",
    "            (num_timesteps, num_arms) array, so at each timestep the reward probabiliies\n",
    "            are given by reward_probabilities[self.timestep]\n",
    "            \n",
    "        observation_space: 2 with central saccade, 1 without\n",
    "        action_space: num_arms + 2 for central saccade, num_arms + 1 without\n",
    "            (additional action for Noop)\n",
    "            Actions are\n",
    "            [ARM1, ARM2,..., ARMN, CENTER]\n",
    "        '''\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.current_trial = 0\n",
    "        self.timestep = 0\n",
    "        self.num_arms = num_arms\n",
    "        self.reward_probabilities = reward_probabilities\n",
    "        if changing_reward_probabilities:\n",
    "            assert reward_probabilities.shape == (num_timesteps, num_arms), \\\n",
    "                f\"Reward probabilities should be of shape ({num_timesteps}, {num_arms})\"\n",
    "        else:\n",
    "            assert reward_probabilities.shape == (num_arms,), \\\n",
    "                f\"Reward probabilities should be of shape ({num_arms},)\"\n",
    "        self.changing_reward_probabilities = changing_reward_probabilities\n",
    "        self.require_central_saccade = require_central_saccade\n",
    "        \n",
    "        self.NOOP = num_arms + 2\n",
    "        if require_central_saccade:\n",
    "            self.observation_space = spaces.Discrete(2)\n",
    "            self.action_space = spaces.Discrete(num_arms + 2)\n",
    "            self.CENTER = num_arms\n",
    "        else:\n",
    "            self.observation_space = spaces.Discrete(1)\n",
    "            self.action_space = spaces.Discrete(num_arms + 1)\n",
    "        \n",
    "        self.saccade_completed = False #keeps track of whether a central saccade was performed\n",
    "        \n",
    "    \n",
    "    def step(self, action):\n",
    "        '''\n",
    "        Take an action, update the state\n",
    "        returns: observation, reward, done, None\n",
    "            observation: the state being given (0 if central saccade not required, 1 if required)\n",
    "            reward: reward received at this timestep\n",
    "            done: whether experiment is completed\n",
    "            None: this is where info would go\n",
    "        '''\n",
    "        reward = self.perform_action(action)\n",
    "        \n",
    "        \n",
    "        self.timestep += 1\n",
    "        done = False\n",
    "        if self.timestep >= self.num_timesteps:\n",
    "            done = True\n",
    "\n",
    "        obs = self.next_observation()\n",
    "        \n",
    "        return obs, reward, done, None\n",
    "        \n",
    "        \n",
    "    def next_observation(self):\n",
    "        '''\n",
    "        Return the observation, which will be a 0 if an arm pull is requested and 1 if\n",
    "        a central saccade is requested\n",
    "        '''\n",
    "        if self.require_central_saccade and not self.saccade_completed:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "        \n",
    "    def perform_action(self, action):\n",
    "        '''\n",
    "        Perform the action and determine result\n",
    "        Returns the reward received\n",
    "        If a saccade is required and performed, we will set self.saccade_complete to True   \n",
    "        '''\n",
    "        if self.require_central_saccade:\n",
    "            if not self.saccade_completed:\n",
    "                if action == self.CENTER:\n",
    "                    self.saccade_completed = True\n",
    "                    return 0\n",
    "                else:\n",
    "                    return -1\n",
    "            else:\n",
    "                if action == self.NOOP:\n",
    "                    return 0\n",
    "                if action == self.CENTER:\n",
    "                    self.saccade_completed = False\n",
    "                    return -1\n",
    "                else:\n",
    "                    self.saccade_completed = False\n",
    "                    return self.pull_arm(action)\n",
    "        \n",
    "        else:\n",
    "            #central saccade not required\n",
    "            if action == self.NOOP:\n",
    "                return 0\n",
    "            else:\n",
    "                return self.pull_arm(action)\n",
    "    \n",
    "    \n",
    "    def pull_arm(self, arm):\n",
    "        '''\n",
    "        Pull bandit arm to check what reward is received\n",
    "        '''\n",
    "        #Get the reward probability of the arm being pulled\n",
    "        if self.changing_reward_probabilities:\n",
    "            reward_probability = self.reward_probabilities[self.timestep][arm]\n",
    "        else:\n",
    "            reward_probability = self.reward_probabilities[arm]\n",
    "        \n",
    "        if(np.random.random() < reward_probability):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def reset(self):\n",
    "        '''\n",
    "        Reset state\n",
    "        '''\n",
    "        self.saccade_completed = False\n",
    "        self.timestep = 0\n",
    "        self.current_trial = 0\n",
    "        \n",
    "        return self.next_observation()\n",
    "    \n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def generate_bandit_env(require_central_saccade=False):\n",
    "    '''\n",
    "    Generate a random bandit environment with two arms of random reward probability\n",
    "    '''\n",
    "    arm1 = np.random.uniform()\n",
    "    arm2 = 1 - arm1\n",
    "    \n",
    "    env = BanditsEnv(reward_probabilities=np.array([arm1, arm2]), require_central_saccade=require_central_saccade)\n",
    "    return env\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 0: Correlated 2 bandit arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.FloatTensor but found type torch.LongTensor for argument #2 'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9844/3331504955.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_epi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m5\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_advantage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9844/3331504955.py\u001b[0m in \u001b[0;36mcalc_advantage\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[0mv_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_prime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                 \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                 \u001b[0mtd_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mv_prime\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdone_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m                 \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtd_target\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of type torch.FloatTensor but found type torch.LongTensor for argument #2 'other'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "import numpy as np\n",
    "\n",
    "#Hyperparameters\n",
    "learning_rate  = 0.0003\n",
    "gamma           = 0.9\n",
    "lmbda           = 0.9\n",
    "eps_clip        = 0.2\n",
    "K_epoch         = 4\n",
    "rollout_len    = 1\n",
    "buffer_size    = 30\n",
    "minibatch_size = 32\n",
    "action_space_size = 2\n",
    "input_size = action_space_size + 2\n",
    "hidden_size = 128\n",
    "require_saccade = False\n",
    "\n",
    "def format_input(previous_action=None, previous_reward=0, timestep=0, observation=False):\n",
    "    '''\n",
    "    If observation is False, we are not expecting an observation\n",
    "    If it is an input, we are probably requiring a saccade in the environment\n",
    "    '''\n",
    "    inp = np.zeros(input_size)\n",
    "    if(previous_action is not None):\n",
    "        inp[previous_action] = 1\n",
    "    inp[action_space_size] = previous_reward\n",
    "    inp[action_space_size + 1] = timestep\n",
    "    if observation is not False:\n",
    "        inp[-1] = observation\n",
    "    inp = torch.tensor(inp, dtype=torch.float).view(1, 1, -1)\n",
    "    return inp\n",
    "\n",
    "class PPO(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PPO, self).__init__()\n",
    "        self.data = []\n",
    "        \n",
    "#         self.fc1   = nn.Linear(3,128)\n",
    "#         self.fc_mu = nn.Linear(128,1)\n",
    "#         self.fc_std  = nn.Linear(128,1)\n",
    "#         self.fc_v = nn.Linear(128,1)\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size, hidden_size)\n",
    "        self.fc_pi = nn.Linear(hidden_size, action_space_size)\n",
    "        self.fc_v = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        self.optimization_step = 0\n",
    "\n",
    "    def pi(self, x, hidden):\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         mu = 2.0*torch.tanh(self.fc_mu(x))\n",
    "#         std = F.softplus(self.fc_std(x))\n",
    "#         return mu, std\n",
    "#         x = F.relu(self.rnn())\n",
    "        x, hidden = self.rnn(x, hidden)\n",
    "        logits = self.fc_pi(x).squeeze()\n",
    "        return Categorical(logits=logits), hidden\n",
    "    \n",
    "    def v(self, x, hidden):\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         v = self.fc_v(x)\n",
    "        x, hidden = self.rnn(x, hidden)\n",
    "        v = self.fc_v(x).squeeze()\n",
    "        return v, hidden\n",
    "      \n",
    "    def put_data(self, transition):\n",
    "        self.data.append(transition)\n",
    "        \n",
    "    def make_batch(self):\n",
    "        s_batch, a_batch, r_batch, s_prime_batch, prob_a_batch, done_batch, hidden_batch = [], [], [], [], [], [], []\n",
    "        data = []\n",
    "\n",
    "        for j in range(buffer_size):\n",
    "            for i in range(minibatch_size):\n",
    "                rollout = self.data.pop()\n",
    "                s_lst, a_lst, r_lst, s_prime_lst, prob_a_lst, done_lst, hidden_lst = [], [], [], [], [], [], []\n",
    "\n",
    "                for transition in rollout:\n",
    "                    s, a, r, s_prime, prob_a, done, hidden = transition\n",
    "                    \n",
    "                    s_lst.append(s)\n",
    "                    a_lst.append([a])\n",
    "                    r_lst.append([r])\n",
    "                    s_prime_lst.append(s_prime)\n",
    "                    prob_a_lst.append([prob_a])\n",
    "                    done_mask = 0 if done else 1\n",
    "                    done_lst.append([done_mask])\n",
    "                    hidden_lst.append([hidden])\n",
    "\n",
    "                s_batch.append(s_lst)\n",
    "                a_batch.append(a_lst)\n",
    "                r_batch.append(r_lst)\n",
    "                s_prime_batch.append(s_prime_lst)\n",
    "                prob_a_batch.append(prob_a_lst)\n",
    "                done_batch.append(done_lst)\n",
    "                hidden_batch.append(hidden_lst)\n",
    "                    \n",
    "            mini_batch = torch.tensor(s_batch, dtype=torch.float), torch.tensor(a_batch, dtype=torch.float), \\\n",
    "                          torch.tensor(r_batch, dtype=torch.float), torch.tensor(s_prime_batch, dtype=torch.float), \\\n",
    "                          torch.tensor(done_batch, dtype=torch.float), torch.tensor(prob_a_batch, dtype=torch.float), \\\n",
    "                          torch.tensor(hidden_batch, dtype=torch.float)\n",
    "            data.append(mini_batch)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def calc_advantage(self, data):\n",
    "        data_with_adv = []\n",
    "        init_hidden = (torch.zeros(1, 1, hidden_size), torch.zeros(1, 1, hidden_size))\n",
    "        for mini_batch in data:\n",
    "            s, a, r, s_prime, done_mask, old_log_prob, hidden_prime = mini_batch\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                v_prime, _ = self.v(s_prime, hidden_prime)\n",
    "                v, _ = self.v(s, init_hidden)\n",
    "                td_target = r + gamma * v_prime * done_mask\n",
    "                delta = td_target - v\n",
    "            delta = delta.numpy()\n",
    "\n",
    "            advantage_lst = []\n",
    "            advantage = 0.0\n",
    "            for delta_t in delta[::-1]:\n",
    "                advantage = gamma * lmbda * advantage + delta_t\n",
    "                advantage_lst.append([advantage])\n",
    "            advantage_lst.reverse()\n",
    "            advantage = torch.tensor(advantage_lst, dtype=torch.float).view(-1)\n",
    "            data_with_adv.append((s, a, r, s_prime, done_mask, old_log_prob, td_target, advantage))\n",
    "\n",
    "        return data_with_adv\n",
    "\n",
    "        \n",
    "    def train_net(self, data):\n",
    "        init_hidden = (torch.zeros(1, 1, hidden_size), torch.zeros(1, 1, hidden_size))\n",
    "        pg_losses = []\n",
    "        v_losses = []\n",
    "        for i in range(K_epoch):\n",
    "            for mini_batch in data:\n",
    "                s, a, r, s_prime, done_mask, old_log_prob, td_target, advantage = mini_batch\n",
    "                v, _ = self.v(s, init_hidden)\n",
    "                dist, _ = self.pi(s, init_hidden)\n",
    "                log_prob = dist.log_prob(a)\n",
    "                ratio = torch.exp(log_prob - old_log_prob)  # a/b == exp(log(a)-log(b))\n",
    "\n",
    "                surr1 = ratio * advantage\n",
    "                surr2 = torch.clamp(ratio, 1-eps_clip, 1+eps_clip) * advantage\n",
    "                \n",
    "                pg_loss = -torch.min(surr1, surr2).mean()\n",
    "                v_loss = F.smooth_l1_loss(v, td_target)\n",
    "                \n",
    "                loss = pg_loss + v_loss\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.mean().backward()\n",
    "                nn.utils.clip_grad_norm_(self.parameters(), 1.0)\n",
    "                self.optimizer.step()\n",
    "                self.optimization_step += 1\n",
    "                \n",
    "                pg_losses.append(pg_loss)\n",
    "                v_losses.append(v_loss)\n",
    "        return pg_losses, v_losses\n",
    "                \n",
    "        \n",
    "# def main():\n",
    "model = PPO()\n",
    "# score = 0.0\n",
    "print_interval = 20\n",
    "# rollout = []\n",
    "\n",
    "def run_episode(env):\n",
    "    '''\n",
    "    Run an episode with the given environment\n",
    "    return (s, a, r, s', done, log_prob, second_hidden) from episode\n",
    "    '''\n",
    "#     env = generate_bandit_env()\n",
    "    s = env.reset()\n",
    "#     print(env.reward_probabilities)\n",
    "    score = 0\n",
    "    a = None\n",
    "    r = 0\n",
    "    t = 0\n",
    "    hidden = (torch.zeros(1, 1, hidden_size), torch.zeros(1, 1, hidden_size))\n",
    "    done = False\n",
    "    \n",
    "    ep_s = []\n",
    "    ep_s_prime = []\n",
    "    ep_r = []\n",
    "    ep_a = []\n",
    "    ep_done = []\n",
    "    ep_hidden = []\n",
    "    ep_log_prob = []\n",
    "\n",
    "    while not done:\n",
    "        s = format_input(a, r, t)\n",
    "#             mu, std = model.pi(torch.from_numpy(s).float())\n",
    "        dist, hidden = model.pi(s, hidden)\n",
    "        a = dist.sample()\n",
    "        log_prob = dist.log_prob(a)\n",
    "        s_prime, r, done, info = env.step(a.item())\n",
    "        t = t + 1\n",
    "        r = r\n",
    "\n",
    "        s_prime = format_input(a, r, t)\n",
    "#             rollout.append((s, a, r, s_prime, log_prob.item(), done, (hidden[0].detach(), hidden[1].detach())))\n",
    "\n",
    "        ep_s.append(s.squeeze())\n",
    "        ep_s_prime.append(s_prime.squeeze())\n",
    "        ep_a.append(a)\n",
    "        ep_r.append(r)\n",
    "        ep_done.append(done)\n",
    "        ep_hidden.append(hidden)\n",
    "        ep_log_prob.append(log_prob)\n",
    "\n",
    "        s = s_prime\n",
    "        score += r\n",
    "        if done:\n",
    "            batch_s = torch.stack(ep_s).view(-1, 1, input_size)\n",
    "            batch_s_prime = torch.stack(ep_s_prime).view(-1, 1, input_size)\n",
    "            batch_r = torch.tensor(ep_r)\n",
    "            batch_a = torch.tensor(ep_a)\n",
    "            ep_done_mask = [0 if done else 1 for done in ep_done]\n",
    "            batch_done = torch.tensor(ep_done_mask)\n",
    "            batch_log_prob = torch.tensor(ep_log_prob)\n",
    "            batch_hidden_prime = ep_hidden[1]\n",
    "            data = (batch_s, batch_a, batch_r, batch_s_prime, batch_done, batch_log_prob, batch_hidden_prime)\n",
    "#             batch.append(data)\n",
    "            return data, score\n",
    "\n",
    "batch = []\n",
    "score = 0\n",
    "reward_probability_options = [np.array([0.25, 0.75]), np.array([0.75, 0.25])]\n",
    "for n_epi in range(300):\n",
    "#     env = generate_bandit_env()\n",
    "#     env = BanditsEnv(num_timesteps=10, reward_probabilities=np.array([0.75, 0.25]))\n",
    "    reward_probability = reward_probability_options[np.random.choice([0, 1])]\n",
    "    env = BanditsEnv(num_timesteps=100, reward_probabilities=reward_probability)\n",
    "    data, ep_score = run_episode(env)\n",
    "    batch.append(data)\n",
    "    score += ep_score\n",
    "        \n",
    "    if n_epi%5 == 4:\n",
    "        batch = model.calc_advantage(batch)\n",
    "        model.train_net(batch)\n",
    "        batch = []\n",
    "    if n_epi%print_interval==0 and n_epi!=0:\n",
    "        print(\"# of episode :{}, avg score : {:.1f}, opt step: {}\".format(n_epi, score/print_interval, model.optimization_step))\n",
    "        score = 0.0\n",
    "\n",
    "env.close()\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'v_prime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9844/67201395.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mv_prime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'v_prime' is not defined"
     ]
    }
   ],
   "source": [
    "v_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, reward, done, info = env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_input(action, reward, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# reward_probability = reward_probability_options[np.random.choice([0, 1])]\n",
    "reward_probability = np.array([0.25, 0.75])\n",
    "env = BanditsEnv(num_timesteps=20, reward_probabilities=reward_probability)\n",
    "data, score = run_episode(env)\n",
    "print(score)\n",
    "batch = [data]\n",
    "batch_adv = model.calc_advantage(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[[ 0.,  0.,  0.,  0.]],\n",
       "  \n",
       "          [[ 0.,  1.,  0.,  1.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0.,  2.]],\n",
       "  \n",
       "          [[ 0.,  1.,  1.,  3.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0.,  4.]],\n",
       "  \n",
       "          [[ 1.,  0.,  1.,  5.]],\n",
       "  \n",
       "          [[ 0.,  1.,  1.,  6.]],\n",
       "  \n",
       "          [[ 0.,  1.,  1.,  7.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0.,  8.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0.,  9.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0., 10.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0., 11.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0., 12.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0., 13.]],\n",
       "  \n",
       "          [[ 1.,  0.,  1., 14.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0., 15.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0., 16.]],\n",
       "  \n",
       "          [[ 0.,  1.,  1., 17.]],\n",
       "  \n",
       "          [[ 1.,  0.,  1., 18.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0., 19.]]]),\n",
       "  tensor([1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]),\n",
       "  tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1]),\n",
       "  tensor([[[ 0.,  1.,  0.,  1.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0.,  2.]],\n",
       "  \n",
       "          [[ 0.,  1.,  1.,  3.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0.,  4.]],\n",
       "  \n",
       "          [[ 1.,  0.,  1.,  5.]],\n",
       "  \n",
       "          [[ 0.,  1.,  1.,  6.]],\n",
       "  \n",
       "          [[ 0.,  1.,  1.,  7.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0.,  8.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0.,  9.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0., 10.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0., 11.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0., 12.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0., 13.]],\n",
       "  \n",
       "          [[ 1.,  0.,  1., 14.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0., 15.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0., 16.]],\n",
       "  \n",
       "          [[ 0.,  1.,  1., 17.]],\n",
       "  \n",
       "          [[ 1.,  0.,  1., 18.]],\n",
       "  \n",
       "          [[ 1.,  0.,  0., 19.]],\n",
       "  \n",
       "          [[ 1.,  0.,  1., 20.]]]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]),\n",
       "  tensor([-0.9080, -0.2845, -1.5909, -0.1462, -0.1233, -2.3186, -2.4344, -0.0873,\n",
       "          -0.0942, -0.0966, -0.0990, -0.1018, -0.1053, -0.1102, -0.1114, -0.1231,\n",
       "          -2.0565, -0.1446, -0.1688, -0.2041]),\n",
       "  tensor([3.8834, 3.6255, 4.7489, 3.6039, 4.5415, 4.4387, 4.3374, 3.1107, 2.9629,\n",
       "          2.8434, 2.7299, 2.6131, 2.4815, 3.4065, 2.1570, 1.8838, 2.6052, 2.1811,\n",
       "          0.6711, 1.0000]),\n",
       "  tensor([ 1.7781, -0.3718,  0.5426, -0.0242,  0.4650, -0.1656, -0.8576, -1.7160,\n",
       "          -1.3900, -1.1146, -0.8318, -0.5084, -0.1228,  0.3519, -0.3908,  0.1240,\n",
       "           0.7413,  0.2176, -0.3111,  0.3119]))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train_net(batch_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([2.9879, 3.1356, 2.6249, 2.2081, 1.7936, 1.4282, 1.1225, 0.8632, 0.6328,\n",
       "          0.4185], grad_fn=<NegBackward>),\n",
       "  tensor([2.9869, 3.1344, 2.6231, 2.2057, 1.7912, 1.4261, 1.1209, 0.8620, 0.6320,\n",
       "          0.4180], grad_fn=<NegBackward>),\n",
       "  tensor([2.9852, 3.1319, 2.6200, 2.2019, 1.7874, 1.4227, 1.1182, 0.8600, 0.6305,\n",
       "          0.4171], grad_fn=<NegBackward>),\n",
       "  tensor([2.9829, 3.1282, 2.6155, 2.1968, 1.7823, 1.4183, 1.1145, 0.8572, 0.6285,\n",
       "          0.4158], grad_fn=<NegBackward>)],\n",
       " [tensor(0.1864, grad_fn=<SmoothL1LossBackward>),\n",
       "  tensor(0.1810, grad_fn=<SmoothL1LossBackward>),\n",
       "  tensor(0.1724, grad_fn=<SmoothL1LossBackward>),\n",
       "  tensor(0.1612, grad_fn=<SmoothL1LossBackward>)])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_hidden = (torch.zeros(1, 1, hidden_size), torch.zeros(1, 1, hidden_size))\n",
    "v, _ = model.v(batch_adv[0][0], init_hidden)\n",
    "td_target = batch_adv[0][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1482, grad_fn=<SmoothL1LossBackward>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.smooth_l1_loss(v, td_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4408, 0.9673, 0.7576, 0.6540, 0.5311, 0.4207, 0.3372, 0.2762, 0.2289,\n",
       "        0.3611], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v - td_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x196ef895e08>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_setups = [np.array([0.25, 0.75]), np.array([0.75, 0.25])]\n",
    "test_results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for rew_prob in test_setups:\n",
    "        env = BanditsEnv(reward_probabilities=rew_prob, num_timesteps=20)\n",
    "        data, score = run_episode(env)\n",
    "        test_results.append(data[1])\n",
    "        print(score)               \n",
    "\n",
    "\n",
    "for i, res in enumerate(test_results):\n",
    "    plt.scatter(np.arange(0, len(res)), res, label=f'arm1={test_setups[i][0]}', alpha=0.7)\n",
    "    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35000000000000014\n",
      "0.7600000000000005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21b30582b48>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_setups = [np.array([0.25, 0.75]), np.array([0.75, 0.25])]\n",
    "test_results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for rew_prob in test_setups:\n",
    "        env = BanditsEnv(reward_probabilities=rew_prob)\n",
    "        data, score = run_episode(env)\n",
    "        test_results.append(data[1])\n",
    "        print(score)               \n",
    "\n",
    "\n",
    "for i, res in enumerate(test_results):\n",
    "    plt.scatter(np.arange(0, len(res)), res, label=f'arm1={test_setups[i][0]}', alpha=0.7)\n",
    "    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'episode': 2000,\n",
    "    'optimization_steps': 20000,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': model.optimizer.state_dict()\n",
    "}, 'saves/metalearner_experiment0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 0b: Central saccade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO()\n",
    "checkpoint = torch.load('saves/metalearner_experiment0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.FloatTensor but found type torch.LongTensor for argument #2 'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9844/1531486850.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_epi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m5\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_advantage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9844/3331504955.py\u001b[0m in \u001b[0;36mcalc_advantage\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[0mv_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_prime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                 \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                 \u001b[0mtd_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mv_prime\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdone_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m                 \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtd_target\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of type torch.FloatTensor but found type torch.LongTensor for argument #2 'other'"
     ]
    }
   ],
   "source": [
    "action_space_size = 3\n",
    "input_size = action_space_size + 3 #+3 is observation, previous reward, and timestep,\n",
    "require_saccade = True\n",
    "model = PPO()\n",
    "\n",
    "env = BanditsEnv(require_central_saccade=require_saccade)\n",
    "# data, score = run_episode(env)\n",
    "\n",
    "\n",
    "batch = []\n",
    "score = 0\n",
    "print_interval = 20\n",
    "\n",
    "for n_epi in range(2000):\n",
    "    env = generate_bandit_env(require_central_saccade=True)\n",
    "    data, ep_score = run_episode(env)\n",
    "    batch.append(data)\n",
    "    score += ep_score\n",
    "        \n",
    "    if n_epi%5 == 4:\n",
    "        batch = model.calc_advantage(batch)\n",
    "        model.train_net(batch)\n",
    "        batch = []\n",
    "    if n_epi%print_interval==0 and n_epi!=0:\n",
    "        print(\"# of episode :{}, avg score : {:.1f}, opt step: {}\".format(n_epi, score/print_interval, model.optimization_step))\n",
    "        score = 0.0\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'episode': 2000,\n",
    "    'optimization_steps': 20000,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': model.optimizer.state_dict()\n",
    "}, 'saves/metalearner_experiment0b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b69006f248>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_setups = [np.array([0.25, 0.75]), np.array([0.75, 0.25])]\n",
    "test_results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for rew_prob in test_setups:\n",
    "        env = BanditsEnv(reward_probabilities=rew_prob, require_central_saccade=True)\n",
    "        data, score = run_episode(env)\n",
    "        test_results.append(data[1])\n",
    "        print(score)               \n",
    "\n",
    "\n",
    "for i, res in enumerate(test_results):\n",
    "    plt.scatter(np.arange(0, len(res)), res, label=f'arm1={test_setups[i][0]}', alpha=0.7)\n",
    "    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
