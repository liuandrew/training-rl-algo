{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "import gym\n",
    "import gym_nav\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from a2c_ppo_acktr import algo, utils\n",
    "from a2c_ppo_acktr.algo import gail\n",
    "from a2c_ppo_acktr.arguments import get_args\n",
    "from a2c_ppo_acktr.envs import make_vec_envs\n",
    "from a2c_ppo_acktr.model import Policy\n",
    "from a2c_ppo_acktr.storage import RolloutStorage\n",
    "from evaluation import evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andy\\miniconda3\\lib\\site-packages\\gym\\wrappers\\record_video.py:42: UserWarning: \u001b[33mWARN: Overwriting existing videos at C:\\Users\\Andy\\Desktop\\Work\\github\\training-rl-algo\\video folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  f\"Overwriting existing videos at {self.video_folder} folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updates 80, num timesteps 405, FPS 75 \n",
      " Last 2 training episodes: mean/median reward -200.0/-200.0, min/max reward -200.0/-200.0\n",
      "\n",
      "Updates 90, num timesteps 455, FPS 77 \n",
      " Last 2 training episodes: mean/median reward -200.0/-200.0, min/max reward -200.0/-200.0\n",
      "\n",
      "Updates 100, num timesteps 505, FPS 78 \n",
      " Last 2 training episodes: mean/median reward -200.0/-200.0, min/max reward -200.0/-200.0\n",
      "\n",
      "Updates 110, num timesteps 555, FPS 77 \n",
      " Last 3 training episodes: mean/median reward -170.0/-200.0, min/max reward -200.0/-110.0\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7a7c83dcbf2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;31m# Obser reward and next obs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minfos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \"\"\"\n\u001b[0;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Work\\github\\training-rl-algo\\a2c_ppo_acktr\\envs.py\u001b[0m in \u001b[0;36mstep_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_normalize.py\u001b[0m in \u001b[0;36mstep_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mwhere\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mboolean\u001b[0m \u001b[0mvector\u001b[0m \u001b[0mindicating\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0meach\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \"\"\"\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mold_obs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mold_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[1;32m---> 44\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             )\n\u001b[0;32m     46\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\stable_baselines3\\common\\monitor.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\gym\\wrappers\\record_video.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecording\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvideo_recorder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecorded_frames\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvideo_length\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\gym\\wrappers\\monitoring\\video_recorder.py\u001b[0m in \u001b[0;36mcapture_frame\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mrender_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"ansi\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mansi_mode\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"rgb_array\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrender_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"human\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andy\\desktop\\work\\github\\training-rl-algo\\env\\gym_nav\\envs\\gridworld_env.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;31m#draw grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcolor_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env_name = 'Gridworld-v0'\n",
    "log_dir = '/tmp/gym'\n",
    "device = torch.device(\"cpu\")\n",
    "alg = 'ppo'\n",
    "log_interval = 10\n",
    "\n",
    "value_loss_coef = 0.5\n",
    "entropy_coef = 0.01\n",
    "gamma = 0.99\n",
    "lr = 7e-4\n",
    "eps = 1e-5\n",
    "alpha = 0.99\n",
    "max_grad_norm = 0.5\n",
    "\n",
    "clip_param = 0.2\n",
    "ppo_epoch = 4\n",
    "num_mini_batch = 1\n",
    "\n",
    "num_env_steps = 10000\n",
    "num_steps = 5\n",
    "num_processes = 1\n",
    "\n",
    "use_gae = False\n",
    "gae_lambda = 0.95\n",
    "use_proper_time_limits = False\n",
    "\n",
    "env = gym.make(env_name)\n",
    "envs = make_vec_envs(env_name, 0, 1, gamma, log_dir, device, False, capture_video=1, env_kwargs={})\n",
    "\n",
    "actor_critic = Policy(\n",
    "    envs.observation_space.shape,\n",
    "    envs.action_space,\n",
    "    base_kwargs={'recurrent': True})\n",
    "actor_critic.to(device)\n",
    "\n",
    "if alg == 'a2c':\n",
    "        agent = algo.A2C_ACKTR(\n",
    "            actor_critic,\n",
    "            value_loss_coef,\n",
    "            entropy_coef,\n",
    "            lr=lr,\n",
    "            eps=eps,\n",
    "            alpha=alpha,\n",
    "            max_grad_norm=max_grad_norm)\n",
    "elif alg == 'ppo':\n",
    "    agent = algo.PPO(\n",
    "        actor_critic,\n",
    "        clip_param,\n",
    "        ppo_epoch,\n",
    "        num_mini_batch,\n",
    "        value_loss_coef,\n",
    "        entropy_coef,\n",
    "        lr=lr,\n",
    "        eps=eps,\n",
    "        max_grad_norm=max_grad_norm)\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "rollouts = RolloutStorage(num_steps, num_processes,\n",
    "                          envs.observation_space.shape, envs.action_space,\n",
    "                          actor_critic.recurrent_hidden_state_size)\n",
    "\n",
    "obs = envs.reset()\n",
    "rollouts.obs[0].copy_(obs)\n",
    "rollouts.to(device)\n",
    "\n",
    "episode_rewards = deque(maxlen=10)\n",
    "\n",
    "start = time.time()\n",
    "num_updates = int(\n",
    "    num_env_steps) // num_steps // num_processes\n",
    "for j in range(num_updates):\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        #Andy: add global step\n",
    "        global_step += 1 * num_processes\n",
    "        # Sample actions\n",
    "        with torch.no_grad():\n",
    "            value, action, action_log_prob, recurrent_hidden_states = actor_critic.act(\n",
    "                rollouts.obs[step], rollouts.recurrent_hidden_states[step],\n",
    "                rollouts.masks[step])\n",
    "\n",
    "        # Obser reward and next obs\n",
    "        obs, reward, done, infos = envs.step(action)\n",
    "\n",
    "        for info in infos:\n",
    "            if 'episode' in info.keys():\n",
    "                episode_rewards.append(info['episode']['r'])\n",
    "\n",
    "        # If done then clean the history of observations.\n",
    "        masks = torch.FloatTensor(\n",
    "            [[0.0] if done_ else [1.0] for done_ in done])\n",
    "        bad_masks = torch.FloatTensor(\n",
    "            [[0.0] if 'bad_transition' in info.keys() else [1.0]\n",
    "             for info in infos])\n",
    "        rollouts.insert(obs, recurrent_hidden_states, action,\n",
    "                        action_log_prob, value, reward, masks, bad_masks)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        next_value = actor_critic.get_value(\n",
    "            rollouts.obs[-1], rollouts.recurrent_hidden_states[-1],\n",
    "            rollouts.masks[-1]).detach()\n",
    "        \n",
    "    rollouts.compute_returns(next_value, use_gae, gamma,\n",
    "                             gae_lambda, use_proper_time_limits)\n",
    "\n",
    "    if alg == 'ppo':\n",
    "        value_loss, action_loss, dist_entropy, approx_kl, clipfracs = \\\n",
    "        agent.update(rollouts)\n",
    "\n",
    "    else:\n",
    "        value_loss, action_loss, dist_entropy = agent.update(rollouts)\n",
    "\n",
    "    rollouts.after_update()\n",
    "\n",
    "    if j % log_interval == 0 and len(episode_rewards) > 1:\n",
    "        total_num_steps = (j + 1) * num_processes * num_steps\n",
    "        end = time.time()\n",
    "        print(\n",
    "            \"Updates {}, num timesteps {}, FPS {} \\n Last {} training episodes: mean/median reward {:.1f}/{:.1f}, min/max reward {:.1f}/{:.1f}\\n\"\n",
    "            .format(j, total_num_steps,\n",
    "                    int(total_num_steps / (end - start)),\n",
    "                    len(episode_rewards), np.mean(episode_rewards),\n",
    "                    np.median(episode_rewards), np.min(episode_rewards),\n",
    "                    np.max(episode_rewards), dist_entropy, value_loss,\n",
    "                    action_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render('human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = env.render('rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2339f1d8308>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from gym import spaces\n",
    "\n",
    "class GridworldNav(gym.Env):\n",
    "    metadata = {\"render.modes\": ['rgb_array', 'human'], 'video.frames_per_second': 24}\n",
    "    def __init__(self, view_width=2, max_steps=200, give_direction=0, world_gen_func={}, \n",
    "                world_size=[20, 20], give_dist=False, num_obstacles=10, goal_size=1,\n",
    "                skeleton=True, goal_reward=10):\n",
    "        '''\n",
    "        General gridworld with 2d rays of vision. Agent gets to rotate or move forward\n",
    "        '''\n",
    "        super(GridworldNav, self).__init__()\n",
    "        \n",
    "        self.object_to_idx = {\n",
    "            'wall': 1,\n",
    "            'goal': 2\n",
    "        }\n",
    "        self.color_to_idx = {\n",
    "            'invisible': 0,\n",
    "            'red': 1,\n",
    "            'green': 2,\n",
    "            'blue': 3,\n",
    "            'purple': 4,\n",
    "            'yellow': 5,\n",
    "            'white': 6\n",
    "        }\n",
    "        self.idx_to_rgb = {\n",
    "            1: np.array([0.9, 0, 0]),\n",
    "            2: np.array([0, 0.9, 0]),\n",
    "            3: np.array([0, 0, 0.9]),\n",
    "            4: np.array([0.9, 0, 0.9]),\n",
    "            5: np.array([0.9, 0.9, 0]),\n",
    "            6: np.array([0.9, 0.9, 0.9])\n",
    "        }\n",
    "        self.action_keys = {\n",
    "            0: 'left',\n",
    "            1: 'forward',\n",
    "            2: 'right',\n",
    "            3: 'nothing'\n",
    "        }\n",
    "        \n",
    "        self.current_steps = 0\n",
    "        \n",
    "        #generate the character icon\n",
    "        self.char_icon = np.zeros([15, 15, 3])\n",
    "        self.char_icon[2:14, 2:4] = [1, 1, 0]\n",
    "        self.char_icon[3:13, 4:6] = [1, 1, 0]\n",
    "        self.char_icon[4:12, 6:8] = [1, 1, 0]\n",
    "        self.char_icon[5:11, 8:10] = [1, 1, 0]\n",
    "        self.char_icon[6:10, 10:12] = [1, 1, 0]\n",
    "        self.char_icon[7:9, 12:14] = [1, 1, 0]\n",
    "        \n",
    "        # if skeleton is False:\n",
    "        #convention of world:\n",
    "        # first index is y position (down is +1, up is -1)\n",
    "        # second index is x position (left is -1, right is +1)\n",
    "        self.world_size = world_size\n",
    "        self.objects = np.zeros(self.world_size)\n",
    "        self.visible = np.zeros(self.world_size)\n",
    "        self.obstacles = np.zeros(self.world_size)\n",
    "        self.num_obstacles = num_obstacles\n",
    "        # self.goal_size = goal_size\n",
    "        self.goal_reward = goal_reward\n",
    "\n",
    "        self.agent = [[0, 0], 0] #agent has a position and direction\n",
    "        #direction is 0: right, 1: up, 2: left, 3: down\n",
    "        self.view_width = view_width\n",
    "        self.max_steps = max_steps\n",
    "        self.give_direction = give_direction\n",
    "        self.give_dist = give_dist\n",
    "\n",
    "        total_width = view_width * 2 + 1\n",
    "        if give_dist:\n",
    "            self.observation_space = spaces.Box(0, 6, shape=(total_width * 2,))\n",
    "        else:\n",
    "            self.observation_space = spaces.Box(0, 6, shape=(total_width,))\n",
    "\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "\n",
    "        self.generate_world()\n",
    "        self.randomize_agent_pos()\n",
    "\n",
    "        \n",
    "    def step(self, action):\n",
    "        collision = False\n",
    "        done = False\n",
    "        reward = -1\n",
    "        \n",
    "        if action == 0:\n",
    "            self.agent[1] = (self.agent[1] + 1) % 4\n",
    "        elif action == 2:\n",
    "            self.agent[1] = (self.agent[1] - 1) % 4\n",
    "        elif action == 1:\n",
    "            pos = self.agent[0].copy()\n",
    "            if self.agent[1] == 0:\n",
    "                pos[1] += 1\n",
    "            elif self.agent[1] == 1:\n",
    "                pos[0] -= 1\n",
    "            elif self.agent[1] == 2:\n",
    "                pos[1] -= 1\n",
    "            elif self.agent[1] == 3:\n",
    "                pos[0] += 1\n",
    "                \n",
    "            if pos[0] < 0 or pos[0] >= self.world_size[0] or \\\n",
    "                pos[1] < 0 or pos[1] >= self.world_size[1]:\n",
    "                #cannot walk off edge of world\n",
    "                pass\n",
    "            elif self.obstacles[pos[0], pos[1]] == 0:\n",
    "                self.agent[0] = pos\n",
    "            else:\n",
    "                collision = pos\n",
    "        \n",
    "            #check if reaching a goal\n",
    "            if self.objects[pos[0], pos[1]] == 2:\n",
    "                reward = self.goal_reward\n",
    "                done = True\n",
    "        \n",
    "        self.current_steps += 1\n",
    "\n",
    "        if self.current_steps >= self.max_steps:\n",
    "            done = True\n",
    "\n",
    "        observation = self.get_observation()\n",
    "        return observation, reward, done, {}\n",
    "        \n",
    "                \n",
    "    def get_observation(self):\n",
    "        '''\n",
    "        Get observations based on vision lines. The agent sees to the left and right\n",
    "        of where it is facing in a straight line. If the vision collides with an object (we assume\n",
    "        it always does because there are walls, but without walls we would have to change it slightly)\n",
    "        then we get a dist to the object and the color of the object\n",
    "        '''\n",
    "        #vision lines\n",
    "        if self.agent[1] == 0:\n",
    "            start = self.agent[0][1]\n",
    "            end = self.world_size[1]\n",
    "            left = self.agent[0][0] - self.view_width\n",
    "            right = self.agent[0][0] + self.view_width\n",
    "            left_idx = np.clip(left, 0, self.world_size[0])\n",
    "            right_idx = np.clip(right, 0, self.world_size[0])\n",
    "            left_right_idx = 0\n",
    "            vis = self.visible[left_idx:right_idx+1, start:end] \n",
    "        elif self.agent[1] == 1:\n",
    "            start = 0\n",
    "            end = self.agent[0][0]\n",
    "            left = self.agent[0][1] - self.view_width\n",
    "            right = self.agent[0][1] + self.view_width\n",
    "            left_idx = np.clip(left, 0, self.world_size[1])\n",
    "            right_idx = np.clip(right, 0, self.world_size[1])\n",
    "            left_right_idx = 1\n",
    "            vis = np.rot90(self.visible[start:end+1, left_idx:right_idx+1], k=3)\n",
    "        elif self.agent[1] == 2:\n",
    "            start = 0\n",
    "            end = self.agent[0][1]\n",
    "            left = self.agent[0][0] + self.view_width\n",
    "            right = self.agent[0][0] - self.view_width\n",
    "            left_idx = np.clip(left, 0, self.world_size[0])\n",
    "            right_idx = np.clip(right, 0, self.world_size[0])\n",
    "            left_right_idx = 0\n",
    "            vis = np.rot90(self.visible[right_idx:left_idx+1, start:end+1], k=2)\n",
    "        elif self.agent[1] == 3:\n",
    "            start = self.agent[0][0]\n",
    "            end = self.world_size[0]\n",
    "            left = self.agent[0][1] + self.view_width\n",
    "            right = self.agent[0][1] - self.view_width\n",
    "            left_idx = np.clip(left, 0, self.world_size[1])\n",
    "            right_idx = np.clip(right, 0, self.world_size[1])\n",
    "            left_right_idx = 1\n",
    "            vis = np.rot90(self.visible[start:end, right_idx:left_idx+1], k=1)\n",
    "\n",
    "        dists = np.argmax(vis > 0, axis=1)\n",
    "        colors = vis[np.arange(vis.shape[0]), dists]\n",
    "\n",
    "        if left < 0:\n",
    "            dists = np.append([0]*-left, dists)\n",
    "            colors = np.append([0]*-left, colors)\n",
    "        if left >= self.world_size[left_right_idx]:\n",
    "            dists = np.append([0]*(self.world_size[left_right_idx] + 1 - left), dists)\n",
    "            colors = np.append([0]*(self.world_size[left_right_idx] + 1 - left), colors)\n",
    "        if right < 0:\n",
    "            dists = np.append(dists, [0]*-right)\n",
    "            colors = np.append(colors, [0]*-right)\n",
    "        if right >= self.world_size[left_right_idx]:\n",
    "            dists = np.append(dists, [0]*(self.world_size[left_right_idx] + 1 - right))\n",
    "            colors = np.append(colors, [0]*(self.world_size[left_right_idx] + 1 - right))\n",
    "        \n",
    "        if self.give_dist:\n",
    "            return np.append(colors, dists)\n",
    "        else:\n",
    "            return colors\n",
    "\n",
    "\n",
    "    def find_empty_space(self):\n",
    "        '''\n",
    "        Search for an empty space uniformly at random to populate with\n",
    "        '''\n",
    "        while True:\n",
    "            y = np.random.randint(0, self.world_size[0])\n",
    "            x = np.random.randint(0, self.world_size[1])\n",
    "            if self.obstacles[y, x] == 0:\n",
    "                return y, x\n",
    "\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_steps = 0\n",
    "        self.generate_world()\n",
    "        self.randomize_agent_pos()\n",
    "        return self.get_observation()\n",
    "    \n",
    "    def generate_world(self):\n",
    "        '''\n",
    "        Reset the world\n",
    "        '''\n",
    "        self.objects = np.zeros(self.world_size)\n",
    "        self.visible = np.zeros(self.world_size)\n",
    "        self.obstacles = np.zeros(self.world_size)\n",
    "        \n",
    "        self.generate_walls()\n",
    "        \n",
    "        #generate random obstacles\n",
    "        for i in range(self.num_obstacles):\n",
    "            y, x = self.find_empty_space()\n",
    "            self.objects[y, x] = 1\n",
    "            self.obstacles[y, x] = 1\n",
    "            self.visible[y, x] = np.random.randint(1, 6)\n",
    "            \n",
    "        #generate a goal\n",
    "        y, x = self.find_empty_space()\n",
    "        self.objects[y, x] = 2\n",
    "        self.obstacles[y, x] = 0\n",
    "        self.visible[y, x] = 6\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def generate_walls(self):\n",
    "        '''\n",
    "        Set walls to red color\n",
    "        '''\n",
    "        #generate walls\n",
    "        self.objects[:, 0] = self.object_to_idx['wall']\n",
    "        self.objects[0, :] = self.object_to_idx['wall']\n",
    "        self.objects[self.world_size[0]-1, :] = self.object_to_idx['wall']\n",
    "        self.objects[:, self.world_size[1]-1] = self.object_to_idx['wall']\n",
    "        \n",
    "        #color walls red\n",
    "        self.visible[:, 0] = self.color_to_idx['red']\n",
    "        self.visible[0, :] = self.color_to_idx['red']\n",
    "        self.visible[self.world_size[0]-1, :] = self.color_to_idx['red']\n",
    "        self.visible[:, self.world_size[1]-1] = self.color_to_idx['red']\n",
    "        \n",
    "        self.visible[0, 0] = self.color_to_idx['green']\n",
    "        self.visible[0, -1] = self.color_to_idx['yellow']\n",
    "        \n",
    "        #set walls as obstacles\n",
    "        self.obstacles[:, 0] = 1\n",
    "        self.obstacles[0, :] = 1\n",
    "        self.obstacles[self.world_size[0]-1, :] = 1\n",
    "        self.obstacles[:, self.world_size[1]-1] = 1\n",
    "        \n",
    "        \n",
    "        \n",
    "    def randomize_agent_pos(self, heading=True):\n",
    "        '''\n",
    "        Randomize position of agent to position that is not an obstacle\n",
    "        '''\n",
    "        y, x = self.find_empty_space()\n",
    "\n",
    "        self.agent[0] = [y, x]\n",
    "        self.agent[1] = np.random.randint(0, 4)\n",
    "        \n",
    "        \n",
    "    def render(self, mode='rgb_array'):\n",
    "        window_size = [(self.world_size[0]) * 16, (self.world_size[1]) * 16]\n",
    "        \n",
    "        img = np.zeros(window_size + [3])\n",
    "\n",
    "        #draw grid\n",
    "        img[np.arange(0, window_size[0], 16), :, :] = 1\n",
    "        img[:, np.arange(0, window_size[1], 16), :] = 1\n",
    "        \n",
    "        def color_block(x, y, rgb, img):\n",
    "            img[y*16+1:(y+1)*16, x*16+1:(x+1)*16] = rgb\n",
    "            return img\n",
    "        \n",
    "        #draw solid objects\n",
    "        for i in range(self.world_size[0]):\n",
    "            for j in range(self.world_size[1]):\n",
    "                if self.visible[i, j] != 0:\n",
    "                    # print(i)\n",
    "                    # img[i*16+1:(i+1)*16, j*16+1:(j+1)*16] = self.idx_to_rgb[self.visible[i, j]]\n",
    "                    img = color_block(j, i, self.idx_to_rgb[self.visible[i, j]], img)\n",
    "                    \n",
    "        #draw agent\n",
    "        y = self.agent[0][0]\n",
    "        x = self.agent[0][1]\n",
    "        img[y*16+1:(y+1)*16, x*16+1:(x+1)*16, :] = np.rot90(self.char_icon, k=self.agent[1])\n",
    "        \n",
    "        if mode == 'rgb_array':\n",
    "            # return img.astype('uint8') * 255\n",
    "            return img.astype('uint8')\n",
    "        elif mode == 'human':\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.imshow(img)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GridworldNav()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render('human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2339f69fa88>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(env.render('rgb_array'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1]],\n",
       "\n",
       "       [[1, 1, 1],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[1, 1, 1],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1, 1, 1],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[1, 1, 1],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[1, 1, 1],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.render('rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = env.render('rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 4.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render('human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 320, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.render('rgb_array').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.7.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "env2 = gym.make('NavEnv-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.95658165, 0.        , 0.        , 0.96899061,\n",
       "       0.        , 0.        , 0.97603581, 0.        , 0.        ,\n",
       "       0.98041614, 0.        , 0.        , 0.98337007, 0.        ,\n",
       "       0.        , 0.98546209, 0.        , 0.        , 0.9870404 ,\n",
       "       0.        , 0.        , 0.98826549, 0.        , 0.        ,\n",
       "       0.98924045, 0.        , 0.        , 0.98998788, 0.        ,\n",
       "       0.        , 0.99060511, 0.        , 0.        , 0.99112619,\n",
       "       0.        , 0.        , 0.9915399 , 0.        , 0.        ,\n",
       "       0.99188256, 0.        , 0.        , 0.99216928, 0.        ,\n",
       "       0.        , 0.99239276, 0.        , 0.        , 0.99257076,\n",
       "       0.        , 0.        , 0.99270686, 0.        , 0.        ,\n",
       "       0.99280499, 0.        , 0.        , 0.99286441, 0.        ,\n",
       "       0.        , 0.99288931, 0.        , 0.        , 0.99287957,\n",
       "       0.        , 0.        , 0.99283525, 0.        , 0.        ,\n",
       "       0.99275405, 0.        , 0.        , 0.99263535, 0.        ,\n",
       "       0.        , 0.9924761 , 0.        , 0.        , 0.99227302,\n",
       "       0.        , 0.        , 0.99202222, 0.        , 0.        ,\n",
       "       0.99169815, 0.        , 0.        , 0.99131683, 0.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env2.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 300, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env2.render('rgb_array').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Gridworld-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_observation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render('human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tried to reset an environment before done. If you want to allow early resets, wrap your env with Monitor(env, path, allow_early_resets=True)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-78e3b0548361>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Work\\github\\training-rl-algo\\a2c_ppo_acktr\\envs.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m         \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m         \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_normalize.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfirst\u001b[0m \u001b[0mobservation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mepisode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \"\"\"\n\u001b[1;32m--> 220\u001b[1;33m         \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mold_obs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mVecEnvObs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_obs_from_buf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\stable_baselines3\\common\\monitor.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_early_resets\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             raise RuntimeError(\n\u001b[1;32m---> 76\u001b[1;33m                 \u001b[1;34m\"Tried to reset an environment before done. If you want to allow early resets, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m                 \u001b[1;34m\"wrap your env with Monitor(env, path, allow_early_resets=True)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tried to reset an environment before done. If you want to allow early resets, wrap your env with Monitor(env, path, allow_early_resets=True)"
     ]
    }
   ],
   "source": [
    "envs.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recurrent_hidden_states' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-a4a9ca40804d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrecurrent_hidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'recurrent_hidden_states' is not defined"
     ]
    }
   ],
   "source": [
    "recurrent_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 3 required positional arguments: 'inputs', 'rnn_hxs', and 'masks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-383b2c2fa2bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mactor_critic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 3 required positional arguments: 'inputs', 'rnn_hxs', and 'masks'"
     ]
    }
   ],
   "source": [
    "actor_critic()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
